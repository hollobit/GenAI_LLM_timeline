# ChatGPT, GenerativeAI and LLMs Timeline 

This repository organizes a timeline of key events (products, services, papers, GitHub, blog posts and news) that occurred before and after the ChatGPT announcement. 

It's curating a variety of information in this timeline, with a particular focus on LLM and Generative AI. 

Maybe it's a scene from the hottest history, so I thought it would be important to keep those memories well, so I organized them.

## Statistics 

These diagrams were generated by ChatGPT's Code Interpreter.

<img src="statistics-0710-01.png">
<img src="statistics-0710-02.png">

## Contributing

Issues and Pull Requests are greatly appreciated. If you've never contributed to an open source project before I'm more than happy to walk you through how to create a pull request.

You can start by [opening an issue](https://github.com/hollobit/BCAC_timeline/issues/new) describing the problem that you're looking to resolve and we'll go from there.

## Emoji 

arXiv :x:, PDF :paperclip:, arxiv-vanity :orange_book:, paper page :house:, papers with code :eight_spoked_asterisk:, Github :octocat:

## License

This document is licensed under the [MIT license](https://opensource.org/licenses/mit-license.php) ¬© Jonghong Jeon

|	Date	|	Announcement	|
|:-:|:--|
| 8.9 | Could a Large Language Model Be Conscious? ([news](https://www.bostonreview.net/articles/could-a-large-language-model-be-conscious/)) |
| 8.9 | üöÄExciting news! Stability AI has launched StableCode, the revolutionary generative AI LLM for coding! ([tweet](https://twitter.com/StabilityAI/status/1688931312122675200)), ([blog](https://stability.ai/blog/stablecode-llm-generative-ai-coding?utm_source=twitter&utm_medium=website&utm_campaign=announcement)) |
| 8.9 | New research visualizes the political bias of all major AI language models ([tweet](https://twitter.com/AiBreakfast/status/1688939983468453888)) |
| 8.8 | OpenAI launches webcrawler [GPTBot](https://platform.openai.com/docs/gptbot), and instructions on how to block it (mashable [news](https://mashable.com/article/open-ai-gptbot-crawler-block)) |
| 8.8 | FLIRT: Feedback Loop In-context Red Teaming ([:x:](https://arxiv.org/abs/2308.04265)), ([:paperclip:](https://arxiv.org/pdf/2308.04265.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2308.04265)), ([:house:](https://huggingface.co/papers/2308.04265)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/flirt-feedback-loop-in-context-red-teaming)) |
| 8.8 | SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore ([:x:](https://arxiv.org/abs/2308.04430)), ([:paperclip:](https://arxiv.org/pdf/2308.04430.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2308.04430)), ([:house:](https://huggingface.co/papers/2308.04430)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/silo-language-models-isolating-legal-risk-in)) |
| 8.8 | Study Tests Large Language Models‚Äô Ability to Answer Clinical Questions (JAMA. 2023;330(6):496. [doi:10.1001/jama.2023.12553](https://jamanetwork.com/journals/jama/fullarticle/2807649)) |
| 8.8 | Why Are So Many Organizations Banning ChatGPT? (BlackBerry [Blog](https://blogs.blackberry.com/en/2023/08/why-companies-ban-chatgpt-ai)) |
| 8.7 | RecycleGPT: An Autoregressive Language Model with Recyclable Module ([:x:](https://arxiv.org/abs/2308.03421)), ([:paperclip:](https://arxiv.org/pdf/2308.03421.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2308.03421)), ([:house:](https://huggingface.co/papers/2308.03421)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/recyclegpt-an-autoregressive-language-model)) |
| 8.7 | AgentBench: Evaluating LLMs as Agents ([:x:](https://arxiv.org/abs/2308.03688)), ([:paperclip:](https://arxiv.org/pdf/2308.03688.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2308.03688)), ([:house:](https://huggingface.co/papers/2308.03688)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/agentbench-evaluating-llms-as-agents)), ([:octocat:](https://github.com/thudm/agentbench)![GitHub Repo stars](https://img.shields.io/github/stars/thudm/agentbench?style=social)) |
| 8.7 | Simple synthetic data reduces sycophancy in large language models  ([:x:](https://arxiv.org/abs/2308.03958)), ([:paperclip:](https://arxiv.org/pdf/2308.03958.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2308.03958)), ([:house:](https://huggingface.co/papers/2308.03958)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/simple-synthetic-data-reduces-sycophancy-in)) |
| 8.7 | Creation and Adoption of Large Language Models in Medicine (Jama [doi:10.1001/jama.2023.14217](https://jamanetwork.com/journals/jama/fullarticle/2808296)) |
| 8.7 | Doctors Vs. ChatGPT: Which Is More Empathetic? (Forbes [news](https://www.forbes.com/sites/robertpearl/2023/08/07/doctors-vs-chatgpt-which-is-more-empathetic)) |
| 8.7 | Criminals Have Created Their Own ChatGPT Clones (Wired [news](https://www.wired.com/story/chatgpt-scams-fraudgpt-wormgpt-crime/)) |
| 8.7 | Large Language Models Answer Medical Questions Accurately, but Can‚Äôt Match Clinicians‚Äô Knowledge (Jama [doi:10.1001/jama.2023.14311](https://jamanetwork.com/journals/jama/fullarticle/2808297)) |
| 8.6 | Pre-Trained Large Language Models for Industrial Control ([:x:](https://arxiv.org/abs/2308.03028)), ([:paperclip:](https://arxiv.org/pdf/2308.03028.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2308.03028)), ([:house:](https://huggingface.co/papers/2308.03028)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/pre-trained-large-language-models-for)) |
| 8.6 | Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies ([:x:](https://arxiv.org/abs/2308.03188)), ([:paperclip:](https://arxiv.org/pdf/2308.03188.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2308.03188)), ([:house:](https://huggingface.co/papers/2308.03188)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/automatically-correcting-large-language)), ([:octocat:](https://github.com/teacherpeterpan/self-correction-llm-papers)![GitHub Repo stars](https://img.shields.io/github/stars/teacherpeterpan/self-correction-llm-papers?style=social)) |
| 8.6 | A Simple AI Governance Framework In The Age Of ChatGPT (Forbes [news](https://www.forbes.com/sites/glenngow/2023/08/06/a-simple-ai-governance-framework-in-the-age-of-chatgpt)) |
| 8.5 | ReCLIP: Refine Contrastive Language Image Pre-Training with Source Free Domain Adaptation ([:x:](https://arxiv.org/abs/2308.03793)), ([:paperclip:](https://arxiv.org/pdf/2308.03793.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2308.03793)), ([:house:](https://huggingface.co/papers/2308.03793)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/reclip-refine-contrastive-language-image-pre)) |
| 8.4 | Towards Generalist Foundation Model for Radiology ([:x:](https://arxiv.org/abs/2308.02463)), ([:paperclip:](https://arxiv.org/pdf/2308.02463.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2308.02463)), ([:house:](https://huggingface.co/papers/2308.02463)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/towards-generalist-foundation-model-for)), ([:octocat:](https://github.com/chaoyi-wu/radfm)![GitHub Repo stars](https://img.shields.io/github/stars/chaoyi-wu/radfm?style=social)) |
| 8.3 | Huge set of ChatGPT updates ([tweet](https://twitter.com/OfficialLoganK/status/1687151401523089408)) |
| 8.3 | Accuracy of Vitreoretinal Disease Information From an Artificial Intelligence Chatbot (JAMA Ophthalmology [doi: 10.1001/jamaophthalmol.2023.3314](https://jamanetwork.com/journals/jamaophthalmology/article-abstract/2807968)) |
| 8.2 | Do Multilingual Language Models Think Better in English? ([:x:](https://arxiv.org/abs/2308.01223)), ([:paperclip:](https://arxiv.org/pdf/2308.01223.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2308.01223)), ([:house:](https://huggingface.co/papers/2308.01223)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/do-multilingual-language-models-think-better)), ([:octocat:](https://github.com/juletx/self-translate)![GitHub Repo stars](https://img.shields.io/github/stars/juletx/self-translate?style=social)) |
| 8.2 | Exploring the psychology of GPT-4's Moral and Legal Reasoning ([:x:](https://arxiv.org/abs/2308.01264)), ([:paperclip:](https://arxiv.org/pdf/2308.01264.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2308.01264)), ([:house:](https://huggingface.co/papers/2308.01264)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/exploring-the-psychology-of-gpt-4-s-moral-and)) |
| 8.2 | DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales ([:x:](https://arxiv.org/abs/2308.01320)), ([:paperclip:](https://arxiv.org/pdf/2308.01320.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2308.01320)), ([:house:](https://huggingface.co/papers/2308.01320)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/deepspeed-chat-easy-fast-and-affordable-rlhf)) |
| 8.2 | Flows: Building Blocks of Reasoning and Collaborating AI ([:x:](https://arxiv.org/abs/2308.01285)), ([:paperclip:](https://arxiv.org/pdf/2308.01285.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2308.01285)), ([:house:](https://huggingface.co/papers/2308.01285)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/flows-building-blocks-of-reasoning-and)) |
| 8.1 | MetaGPT: Meta Programming for Multi-Agent Collaborative Framework ([:x:](https://arxiv.org/abs/2308.00352)), ([:paperclip:](https://arxiv.org/pdf/2308.00352.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2308.00352)), ([:house:](https://huggingface.co/papers/2308.00352)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/metagpt-meta-programming-for-multi-agent)), ([:octocat:](https://github.com/geekan/metagpt)![GitHub Repo stars](https://img.shields.io/github/stars/geekan/metagpt?style=social))  |
| 8.1 | Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models ([:x:](https://arxiv.org/abs/2308.00675)), ([:paperclip:](https://arxiv.org/pdf/2308.00675.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2308.00675)), ([:house:](https://huggingface.co/papers/2308.00675)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/tool-documentation-enables-zero-shot-tool)) |
| 8.1 | Upstage LLM #1 in Open LLM Leaderboard ([Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)) |
| 8.1 | ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs ([:x:](https://arxiv.org/abs/2307.16789)), ([:paperclip:](https://arxiv.org/pdf/2307.16789.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.16789)), ([:house:](https://huggingface.co/papers/2307.16789)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/toolllm-facilitating-large-language-models-to)), ([:octocat:](https://github.com/openbmb/toolbench)![GitHub Repo stars](https://img.shields.io/github/stars/openbmb/toolbench?style=social)) |
| 8.1 | ChatGPT app for Android is now available in all countries and regions ([tweet](https://twitter.com/OpenAI/status/1686046214519947264)), ([blog](https://help.openai.com/en/articles/7947663-chatgpt-supported-countries)) |
| 7.31 | Learning to Model the World with Language ([:x:](https://arxiv.org/abs/2308.01399)), ([:paperclip:](https://arxiv.org/pdf/2308.01399.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2308.01399)), ([:house:](https://huggingface.co/papers/2308.01399)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/learning-to-model-the-world-with-language)) |
| 7.30 | Do LLMs Possess a Personality? Making the MBTI Test an Amazing Evaluation for Large Language Models ([:x:](https://arxiv.org/abs/2307.16180)), ([:paperclip:](https://arxiv.org/pdf/2307.16180.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.16180)), ([:house:](https://huggingface.co/papers/2307.16180)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/do-llms-possess-a-personality-making-the-mbti)), ([:octocat:](https://github.com/harderthenharder/transformers_tasks)![GitHub Repo stars](https://img.shields.io/github/stars/harderthenharder/transformers_tasks?style=social)) |
| 7.30 | Unified Model for Image, Video, Audio and Language Tasks ([:x:](https://arxiv.org/abs/2307.16184)), ([:paperclip:](https://arxiv.org/pdf/2307.16184.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.16184)), ([:house:](https://huggingface.co/papers/2307.16184)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/unified-model-for-image-video-audio-and)) |
| 7.29 | The shaky foundations of large language models and foundation models for electronic health records (npj digital medicine, [https://doi.org/10.1038/s41746-023-00879-8](https://www.nature.com/articles/s41746-023-00879-8)), ([PDF](https://www.nature.com/articles/s41746-023-00879-8.pdf)) |
| 7.29 | Uncertainty in Natural Language Generation: From Theory to Applications ([:x:](https://arxiv.org/abs/2307.15703)), ([:paperclip:](https://arxiv.org/pdf/2307.15703.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.15703)), ([:house:](https://huggingface.co/papers/2307.15703)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/uncertainty-in-natural-language-generation)) |
| 7.28 | Exploring Format Consistency for Instruction Tuning ([:x:](https://arxiv.org/abs/2307.15504)), ([:paperclip:](https://arxiv.org/pdf/2307.15504.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.15504)), ([:house:](https://huggingface.co/papers/2307.15504)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/exploring-format-consistency-for-instruction)) |
| 7.28 | ‚≠ê Med-HALT: Medical Domain Hallucination Test for Large Language Models  ([:x:](https://arxiv.org/abs/2307.15343)), ([:paperclip:](https://arxiv.org/pdf/2307.15343.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.15343)), ([:house:](https://huggingface.co/papers/2307.15343)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/med-halt-medical-domain-hallucination-test)) |
| 7.28 | Med-Flamingo: a Multimodal Medical Few-shot Learner  ([:x:](https://arxiv.org/abs/2307.15189)), ([:paperclip:](https://arxiv.org/pdf/2307.15189.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.15189)), ([:house:](https://huggingface.co/papers/2307.15189)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/med-flamingo-a-multimodal-medical-few-shot)) |
| 7.28 | Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding ([:x:](https://arxiv.org/abs/2307.15337)), ([:paperclip:](https://arxiv.org/pdf/2307.15337.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.15337)), ([:house:](https://huggingface.co/papers/2307.15337)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/skeleton-of-thought-large-language-models-can)) |
| 7.28 | How Good is Google Bard's Visual Understanding? An Empirical Study on Open Challenges ([:x:](https://arxiv.org/abs/2307.15016)), ([:paperclip:](https://arxiv.org/pdf/2307.15016.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.15016)), ([:house:](https://huggingface.co/papers/2307.15016)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/how-good-is-google-bard-s-visual)) |
| 7.27 | Generative AI for Medical Imaging: extending the MONAI Framework ([:x:](https://arxiv.org/abs/2307.15208)), ([:paperclip:](https://arxiv.org/pdf/2307.15208.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.15208)), ([:house:](https://huggingface.co/papers/2307.15208)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/generative-ai-for-medical-imaging-extending)), ([:octocat:](https://github.com/warvito/generative_monai)![GitHub Repo stars](https://img.shields.io/github/stars/warvito/generative_monai?style=social))  |
| 7.27 | Guidance for Authors, Peer Reviewers, and Editors on Use of AI, Language Models, and Chatbots (Jama [doi:10.1001/jama.2023.12500](https://jamanetwork.com/journals/jama/fullarticle/2807956)) |
| 7.27 | Chatbots, Artificial Intelligence, and the Future of Scientific Reporting (JAMA Ophthalmology [doi: 10.1001/jamaophthalmol.2023.3344](https://jamanetwork.com/journals/jamaophthalmology/article-abstract/2807443)) |
| 7.27 | Matching Patients to Clinical Trials with Large Language Models ([:x:](https://arxiv.org/abs/2307.15051)), ([:paperclip:](https://arxiv.org/pdf/2307.15051.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.15051)), ([:house:](https://huggingface.co/papers/2307.15051)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/matching-patients-to-clinical-trials-with)) |
| 7.27 | Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback  ([:x:](https://arxiv.org/abs/2307.15217)), ([:paperclip:](https://arxiv.org/pdf/2307.15217.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.15217)), ([:house:](https://huggingface.co/papers/2307.15217)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/open-problems-and-fundamental-limitations-of)) |
| 7.27 | Scaling Up and Distilling Down: Language-Guided Robot Skill Acquisition ([:x:](https://arxiv.org/abs/2307.14535)), ([:paperclip:](https://arxiv.org/pdf/2307.14535.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.14535)), ([:house:](https://huggingface.co/papers/2307.14535)), ([:eight_spoked_asterisk:]()) |
| 7.27 | NeurIPS 2023 Large Language Model Efficiency Challenge: 1 LLM + 1GPU + 1Day ([site](https://llm-efficiency-challenge.github.io/)) |
| 7.27 | Google DeepMind RT-2: Vision-Language-Action Models ([tweet](https://twitter.com/GoogleDeepMind/status/1684903412834447360)), ([blog](https://www.deepmind.com/blog/rt-2-new-model-translates-vision-and-language-into-action)), ([project](https://robotics-transformer2.github.io/)), ([PDF](https://robotics-transformer2.github.io/assets/rt2.pdf)) |
| 7.27 | Multilingual Code Co-Evolution Using Large Language Models ([:x:](https://arxiv.org/abs/2307.14991)), ([:paperclip:](https://arxiv.org/pdf/2307.14991.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.14991)), ([:house:](https://huggingface.co/papers/2307.14991)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/multilingual-code-co-evolution-using-large)) |
| 7.27 | The Guardian's updated editorial code guidance now includes a section on generative AI ([PDF](https://uploads.guim.co.uk/2023/07/27/GNM_editorial_code_of_practice_and_guidance_2023.pdf)) |
| 7.27 | Training Data Extraction From Pre-trained Language Models: A Survey ([report](https://aclanthology.org/2023.trustnlp-1.23/)), ([PDF](https://aclanthology.org/2023.trustnlp-1.23.pdf)) |
| 7.27 | ‚≠ê Universal and Transferable Adversarial Attacks on Aligned Language Models ([project](https://llm-attacks.org/)), ([:x:](https://arxiv.org/abs/2307.15043)), ([:paperclip:](https://arxiv.org/pdf/2307.15043.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.15043)), ([:house:](https://huggingface.co/papers/2307.15043)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/universal-and-transferable-adversarial)), ([:octocat:](https://github.com/llm-attacks/llm-attacks)![GitHub Repo stars](https://img.shields.io/github/stars/llm-attacks/llm-attacks?style=social)), ([SS](https://www.semanticscholar.org/paper/Universal-and-Transferable-Adversarial-Attacks-on-Zou-Wang/47030369e97cc44d4b2e3cf1be85da0fd134904a)) |
| 7.27 | NeRF-Det: Learning Geometry-Aware Volumetric Representation for Multi-View 3D Object Detection ([:x:](https://arxiv.org/abs/2307.14620)), ([:paperclip:](https://arxiv.org/pdf/2307.14620.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.14620)), ([:house:](https://huggingface.co/papers/2307.14620)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/nerf-det-learning-geometry-aware-volumetric)) |
| 7.27 | PanGu-Coder2: Boosting Large Language Models for Code with Ranking Feedback ([:x:](https://arxiv.org/abs/2307.14936)), ([:paperclip:](https://arxiv.org/pdf/2307.14936.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.14936)), ([:house:](https://huggingface.co/papers/2307.14936)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/pangu-coder2-boosting-large-language-models)) |
| 7.27 | WavJourney: Compositional Audio Creation with Large Language Models ([:x:](https://arxiv.org/abs/2307.14335)), ([:paperclip:](https://arxiv.org/pdf/2307.14335.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.14335)), ([:house:](https://huggingface.co/papers/2307.14335)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/wavjourney-compositional-audio-creation-with)), ([:octocat:](https://github.com/audio-agi/wavjourney)![GitHub Repo stars](https://img.shields.io/github/stars/audio-agi/wavjourney?style=social)) |
| 7.26 | Supporting Open Source and Open Science in the EU AI Act ([Blog](https://creativecommons.org/2023/07/26/supporting-open-source-and-open-science-in-the-eu-ai-act/)), ([PDF](https://creativecommons.org/wp-content/uploads/2023/07/SupportingOpenSourceAndOpenScienceInTheEUAIAct.pdf)) |
| 7.26 | Points-to-3D: Bridging the Gap between Sparse Points and Shape-Controllable Text-to-3D Generation ([:x:](https://arxiv.org/abs/2307.13908)), ([:paperclip:](https://arxiv.org/pdf/2307.13908.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.13908)), ([:house:](https://huggingface.co/papers/2307.13908)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/points-to-3d-bridging-the-gap-between-sparse)) |
| 7.26 | Tracking Anything in High Quality ([:x:](https://arxiv.org/abs/2307.13974)), ([:paperclip:](https://arxiv.org/pdf/2307.13974.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.13974)), ([:house:](https://huggingface.co/papers/2307.13974)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/tracking-anything-in-high-quality)), ([:octocat:](https://github.com/jiawen-zhu/hqtrack)![GitHub Repo stars](https://img.shields.io/github/stars/jiawen-zhu/hqtrack?style=social)) |
| 7.26 | Stability AI Announces Stable Diffusion XL 1.0, Featured on Amazon Bedrock ([blog](https://stability.ai/press-articles/stable-diffusion-xl-1-featured-amazon-aws-bedrock)), ([SD-XL 1.0-base Model Card](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)), ([SD-XL 1.0-refiner Model Card](https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0)), ([:octocat:](https://github.com/Stability-AI/generative-models)![GitHub Repo stars](https://img.shields.io/github/stars/Stability-AI/generative-models?style=social)) |
| 7.26 | Towards Generalist Biomedical AI  ([:x:](https://arxiv.org/abs/2307.14334)), ([:paperclip:](https://arxiv.org/pdf/2307.14334.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.14334)), ([:house:](https://huggingface.co/papers/2307.14334)), ([:eight_spoked_asterisk:]()) |
| 7.26 | ‚≠ê Microsoft, Anthropic, Google, and OpenAI launch Frontier Model Forum ([Microsoft](https://blogs.microsoft.com/on-the-issues/2023/07/26/anthropic-google-microsoft-openai-launch-frontier-model-forum/?fbclid=IwAR3-9xKx9lLczutZ5q7ZDyXjGXYfLqM8FvZ_7saCI-EqLIl97w--ETcpKV8)), [Google](https://blog.google/outreach-initiatives/public-policy/google-microsoft-openai-anthropic-frontier-model-forum/?fbclid=IwAR3lv1xCrjWbkyetFYTdYQuZEbJ0yfqGWybIuY5v9rN0EW2cPC7jj6WrhKg), [OpenAI](https://openai.com/blog/frontier-model-forum?fbclid=IwAR3PMnEemOsvJm2loxHbI90ZO5R-_GdKVJ0lS8nEuOFCSf5cVeip-EpNI-4), [anthropic](https://www.anthropic.com/index/frontier-threats-red-teaming-for-ai-safety)) | 
| 7.26 | Evaluating the Moral Beliefs Encoded in LLMs ([:x:](https://arxiv.org/abs/2307.14324)), ([:paperclip:](https://arxiv.org/pdf/2307.14324.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.14324)), ([:house:](https://huggingface.co/papers/2307.14324)), ([:eight_spoked_asterisk:]()) |
| 7.26 | WebArena: A Realistic Web Environment for Building Autonomous Agents ([project](https://webarena.dev/)),  ([:paperclip:](https://webarena.dev/static/paper.pdf)), ([:octocat:](https://github.com/web-arena-x/webarena)![GitHub Repo stars](https://img.shields.io/github/stars/web-arena-x/webarena?style=social) |
| 7.26 | ARB: Advanced Reasoning Benchmark for Large Language Models  ([:x:](https://arxiv.org/abs/2307.13692)), ([:paperclip:](https://arxiv.org/pdf/2307.13692.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.13692)), ([:house:](https://huggingface.co/papers/2307.13692)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/arb-advanced-reasoning-benchmark-for-large)) |
| 7.26 | OpenAI scuttles AI-written text detector over ‚Äòlow rate of accuracy‚Äô ([news](https://techcrunch.com/2023/07/25/openai-scuttles-ai-written-text-detector-over-low-rate-of-accuracy/)) |
| 7.25 | LLM-Rec: Personalized Recommendation via Prompting Large Language Models ([:x:](https://arxiv.org/abs/2307.15780)), ([:paperclip:](https://arxiv.org/pdf/2307.15780.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.15780)), ([:house:](https://huggingface.co/papers/2307.15780)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/llm-rec-personalized-recommendation-via)) |
| 7.25 | How Can Large Language Models Help Humans in Design and Manufacturing? ([:x:](https://arxiv.org/abs/2307.14377)), ([:paperclip:](https://arxiv.org/pdf/2307.14377.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.14377)), ([:house:](https://huggingface.co/papers/2307.14377)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/how-can-large-language-models-help-humans-in)) |
| 7.25 | UK House of Lords Announces Inquiry into Large Language Models ([news](https://www.lexology.com/library/detail.aspx?g=ae522c40-cdb5-48ca-aa5d-58c6f5b32c1f)) |
| 7.25 | FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios ([:x:](https://arxiv.org/abs/2307.13528)), ([:paperclip:](https://arxiv.org/pdf/2307.13528.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.13528)), ([:house:](https://huggingface.co/papers/2307.13528)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/factool-factuality-detection-in-generative-ai)), ([:octocat:](https://github.com/gair-nlp/factool)![GitHub Repo stars](https://img.shields.io/github/stars/gair-nlp/factool?style=social)) |
| 7.25 | LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition ([:x:](https://arxiv.org/abs/2307.13269)), ([:paperclip:](https://arxiv.org/pdf/2307.13269.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.13269)), ([:house:](https://huggingface.co/papers/2307.13269)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/lorahub-efficient-cross-task-generalization)) |
| 7.25 | ChatGPT is a black box: how AI research can break it open (Nature [doi: https://doi.org/10.1038/d41586-023-02366-2](https://www.nature.com/articles/d41586-023-02366-2)) |
| 7.25 | ChatGPT broke the Turing test ‚Äî the race is on for new ways to assess AI (Nature [doi: https://doi.org/10.1038/d41586-023-02361-7](https://www.nature.com/articles/d41586-023-02361-7)), ([PDF](https://www.nature.com/articles/d41586-023-02361-7.pdf?pdf=button%20sticky)) |
| 7.25 | Evaluating the Ripple Effects of Knowledge Editing in Language Models ([:x:](https://arxiv.org/abs/2307.12976)), ([:paperclip:](https://arxiv.org/pdf/2307.12976.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.12976)), ([:house:](https://huggingface.co/papers/2307.12976)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/evaluating-the-ripple-effects-of-knowledge)) |
| 7.25 | 3D-LLM: Injecting the 3D World into Large Language Models ([:x:](https://arxiv.org/abs/2307.12981)), ([:paperclip:](https://arxiv.org/pdf/2307.12981.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.12981)), ([:house:](https://huggingface.co/papers/2307.12981)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/3d-llm-injecting-the-3d-world-into-large)) |
| 7.25 | RLCD: Reinforcement Learning from Contrast Distillation for Language Model Alignment ([:x:](https://arxiv.org/abs/2307.12950)), ([:paperclip:](https://arxiv.org/pdf/2307.12950.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.12950)), ([:house:](https://huggingface.co/papers/2307.12950)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/rlcd-reinforcement-learning-from-contrast)) |
| 7.24 | ‚≠ê Aligning Large Language Models with Human: A Survey  ([:x:](https://arxiv.org/abs/2307.12966)), ([:paperclip:](https://arxiv.org/pdf/2307.12966.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.12966)), ([:house:](https://huggingface.co/papers/2307.12966)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/aligning-large-language-models-with-human-a)), ([:octocat:](https://github.com/garyyufei/alignllmhumansurvey)![GitHub Repo stars](https://img.shields.io/github/stars/garyyufei/alignllmhumansurvey?style=social)) |
| 7.24 | A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis  ([:x:](https://arxiv.org/abs/2307.12856)), ([:paperclip:](https://arxiv.org/pdf/2307.12856.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.12856)), ([:house:](https://huggingface.co/papers/2307.12856)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-real-world-webagent-with-planning-long)) |
| 7.24 | LLMs get a medical education (Nature [DOI: 10.1038/d41591-023-00064-0](https://www.nature.com/articles/d41591-023-00064-0)) |
| 7.24 | MC-JEPA: A Joint-Embedding Predictive Architecture for Self-Supervised Learning of Motion and Content Features ([:x:](https://arxiv.org/abs/2307.12698)), ([:paperclip:](https://arxiv.org/pdf/2307.12698.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.12698)), ([:house:](https://huggingface.co/papers/2307.12698)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/mc-jepa-a-joint-embedding-predictive)) |
| 7.24 | Interpolating between Images with Diffusion Models ([:x:](https://arxiv.org/abs/2307.12560)), ([:paperclip:](https://arxiv.org/pdf/2307.12560.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.12560)), ([:house:](https://huggingface.co/papers/2307.12560)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/interpolating-between-images-with-diffusion))  |
| 7.24 | PUMA: Secure Inference of LLaMA-7B in Five Minutes  ([:x:](https://arxiv.org/abs/2307.12533)), ([:paperclip:](https://arxiv.org/pdf/2307.12533.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.12533)), ([:house:](https://huggingface.co/papers/2307.12533)), ([:eight_spoked_asterisk:](https://cs.paperswithcode.com/paper/puma-secure-inference-of-llama-7b-in-five)), ([:octocat:](https://github.com/secretflow/spu)![GitHub Repo stars](https://img.shields.io/github/stars/secretflow/spu?style=social))  |
| 7.24 | A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis ([:x:](https://arxiv.org/abs/2307.12856)), ([:paperclip:](https://arxiv.org/pdf/2307.12856.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.12856)), ([:house:](https://huggingface.co/papers/2307.12856)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-real-world-webagent-with-planning-long)) |
| 7.23 | Optimized Network Architectures for Large Language Model Training with Billions of Parameters ([:x:](https://arxiv.org/abs/2307.12169)), ([:paperclip:](https://arxiv.org/pdf/2307.12169.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.12169)), ([:house:](https://huggingface.co/papers/2307.12169)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/optimized-network-architectures-for-large)) |
| 7.22 | Introducing FreeWilly1 and FreeWilly2 - The latest groundbreaking LLMs from Stability AI's and  @carperai lab! ‚≠ê ([tweet](https://twitter.com/StabilityAI/status/1682474968393609216)) |
| 7.22 | llama2-webui: Run Llama 2 locally with gradio UI on GPU or CPU from anywhere (Linux/Windows/Mac) ([:octocat:](https://github.com/liltom-eth/llama2-webui)![GitHub Repo stars](https://img.shields.io/github/stars/liltom-eth/llama2-webui?style=social)) |
| 7.22 | ChatGPT for Android launches next week ([news](https://www.theverge.com/2023/7/21/23803482/chatgpt-android-artificial-intelligence-chatbot-app)) |
| 7.22 | Expedia launches ChatGPT travel planning tool ([news](https://globetrender.com/2023/07/22/expedia-launches-chatgpt-travel-planning-tool/)) |
| 7.21 | FACT SHEET: Biden-‚Å†Harris Administration Secures Voluntary Commitments from Leading Artificial Intelligence Companies to Manage the Risks Posed by AI (White House [news](https://www.whitehouse.gov/briefing-room/statements-releases/2023/07/21/fact-sheet-biden-harris-administration-secures-voluntary-commitments-from-leading-artificial-intelligence-companies-to-manage-the-risks-posed-by-ai/)) |
| 7.21 | Prompting Large Language Models with Speech Recognition Abilities  ([:x:](https://arxiv.org/abs/2307.11795)), ([:paperclip:](https://arxiv.org/pdf/2307.11795.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.11795)), ([:house:](https://huggingface.co/papers/2307.11795)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/prompting-large-language-models-with-speech)) |
| 7.21 | L-Eval: Instituting Standardized Evaluation for Long Context Language Models  ([:x:](https://arxiv.org/abs/2307.11088)), ([:paperclip:](https://arxiv.org/pdf/2307.11088.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.11088)), ([:house:](https://huggingface.co/papers/2307.11088)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/evaluating-superhuman-models-with-consistency)) |
| 7.21 | CopyRNeRF: Protecting the CopyRight of Neural Radiance Fields ([:x:](https://arxiv.org/abs/2307.11526)), ([:paperclip:](https://arxiv.org/pdf/2307.11526.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.11526)), ([:house:](https://huggingface.co/papers/2307.11526)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/copyrnerf-protecting-the-copyright-of-neural)) |
| 7.21 | FaceCLIPNeRF: Text-driven 3D Face Manipulation using Deformable Neural Radiance Fields ([:x:](https://arxiv.org/abs/2307.11418)), ([:paperclip:](https://arxiv.org/pdf/2307.11418.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.11418)), ([:house:](https://huggingface.co/papers/2307.11418)), ([:eight_spoked_asterisk:]()) |
| 7.21 | Subject-Diffusion:Open Domain Personalized Text-to-Image Generation without Test-time Fine-tuning ([:x:](https://arxiv.org/abs/2307.11410)), ([:paperclip:](https://arxiv.org/pdf/2307.11410.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.11410)), ([:house:](https://huggingface.co/papers/2307.11410)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/subject-diffusion-open-domain-personalized)), ([:octocat:](https://github.com/OPPO-Mente-Lab/Subject-Diffusion)![GitHub Repo stars](https://img.shields.io/github/stars/OPPO-Mente-Lab/Subject-Diffusion?style=social)) |
| 7.21 | Meet FreeWilly, Our Large And Mighty Instruction Fine-Tuned Models (stability.ai [announcement](https://stability.ai/blog/freewilly-large-instruction-fine-tuned-models)) |
| 7.21 | WormGPT: ChatGPT For Cybercriminals ([news](https://medium.datadriveninvestor.com/wormgpt-chatgpt-for-cybercriminals-db81d2b0a1fc)) |
| 7.21 | Brain2Music: Reconstructing Music from Human Brain Activity ([:x:](https://arxiv.org/abs/2307.11078)), ([:paperclip:](https://arxiv.org/pdf/2307.11078.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.11078)), ([:house:](https://huggingface.co/papers/2307.11078)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/brain2music-reconstructing-music-from-human)) |
| 7.21 | OpenAI launches customized instructions for ChatGPT ([news](https://techcrunch.com/2023/07/20/openai-launches-customized-instructions-for-chatgpt/)) |
| 7.20 | L-Eval: Instituting Standardized Evaluation for Long Context Language Models  ([:x:](https://arxiv.org/abs/2307.11088)), ([:paperclip:](https://arxiv.org/pdf/2307.11088.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.11088)), ([:house:](https://huggingface.co/papers/2307.11088)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/l-eval-instituting-standardized-evaluation)), ([:octocat:](https://github.com/openlmlab/leval)![GitHub Repo stars](https://img.shields.io/github/stars/openlmlab/leval?style=social)) |
| 7.20 | DNA-Rendering: A Diverse Neural Actor Repository for High-Fidelity Human-centric Rendering ([:x:](https://arxiv.org/abs/2307.10173)), ([:paperclip:](https://arxiv.org/pdf/2307.10173.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.10173)), ([:house:](https://huggingface.co/papers/2307.10173)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/dna-rendering-a-diverse-neural-actor)), ([:octocat:](https://github.com/DNA-Rendering/DNA-Rendering)![GitHub Repo stars](https://img.shields.io/github/stars/DNA-Rendering/DNA-Rendering?style=social))  |
| 7.20 | LLMs as Workers in Human-Computational Algorithms? Replicating Crowdsourcing Pipelines with LLMs ([:x:](https://arxiv.org/abs/2307.10168)), ([:paperclip:](https://arxiv.org/pdf/2307.10168.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.10168)), ([:house:](https://huggingface.co/papers/2307.10168)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/llms-as-workers-in-human-computational)) |
| 7.20 | DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection for Conversational AI ([:x:](https://arxiv.org/abs/2307.10172)), ([:paperclip:](https://arxiv.org/pdf/2307.10172.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.10172)), ([:house:](https://huggingface.co/papers/2307.10172)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/dialogstudio-towards-richest-and-most-diverse)), ([:octocat:](https://github.com/salesforce/DialogStudio)![GitHub Repo stars](https://img.shields.io/github/stars/salesforce/DialogStudio?style=social)) |
| 7.20 | FABRIC: Personalizing Diffusion Models with Iterative Feedback  ([:x:](https://arxiv.org/abs/2307.10159)), ([:paperclip:](https://arxiv.org/pdf/2307.10159.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.10159)), ([:house:](https://huggingface.co/papers/2307.10159)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/fabric-personalizing-diffusion-models-with)), ([:octocat:](https://github.com/sd-fabric/fabric)![GitHub Repo stars](https://img.shields.io/github/stars/sd-fabric/fabric?style=social)) |
| 7.20 | ‚≠ê FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets ([:x:](https://arxiv.org/abs/2307.10928)), ([:paperclip:](https://arxiv.org/pdf/2307.10928.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.10928)), ([:house:](https://huggingface.co/papers/2307.10928)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/flask-fine-grained-language-model-evaluation)) |
| 7.20 | Instruction-following Evaluation through Verbalizer Manipulation ([:x:](https://arxiv.org/abs/2307.10558)), ([:paperclip:](https://arxiv.org/pdf/2307.10558.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.10558)), ([:house:](https://huggingface.co/papers/2307.10558)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/instruction-following-evaluation-through)) |
| 7.20 | PASTA: Pretrained Action-State Transformer Agents ([:x:](https://arxiv.org/abs/2307.10936)), ([:paperclip:](https://arxiv.org/pdf/2307.10936.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.10936)), ([:house:](https://huggingface.co/papers/2307.10936)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/pasta-pretrained-action-state-transformer)) |
| 7.20 | TokenFlow: Consistent Diffusion Features for Consistent Video Editing ([:x:](https://arxiv.org/abs/2307.10373)), ([:paperclip:](https://arxiv.org/pdf/2307.10373.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.10373)), ([:house:](https://huggingface.co/papers/2307.10373)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/tokenflow-consistent-diffusion-features-for)) |
| 7.20 | ‚≠ê SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models ([:x:](https://arxiv.org/abs/2307.10635)), ([:paperclip:](https://arxiv.org/pdf/2307.10635.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.10635)), ([:house:](https://huggingface.co/papers/2307.10635)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/scibench-evaluating-college-level-scientific)), ([:octocat:](https://github.com/mandyyyyii/scibench)![GitHub Repo stars](https://img.shields.io/github/stars/mandyyyyii/scibench?style=social)) |
| 7.20 | Artificial intelligence is making the union movement‚Äôs case‚Äìand even ChatGPT knows it ([news](https://fortune.com/2023/07/20/artificial-intelligence-making-union-movements-caseand-even-chatgpt-labor-strikes-edward-smith/)) |
| 7.20 | Apple is testing a ChatGPT-like AI chatbot ([news](https://techcrunch.com/2023/07/19/apple-is-testing-chatgpt-like-ai-chatbot/)) |
| 7.20 | Someone Used ChatGPT to Finish the Game of Thrones Book Series ([news](https://www.ign.com/articles/someone-used-chatgpt-to-finish-the-game-of-thrones-book-series)) |
| 7.20 | ‚≠ê Meta-Transformer: A Unified Framework for Multimodal Learning ([:x:](https://arxiv.org/abs/2307.10802)), ([:paperclip:](https://arxiv.org/pdf/2307.10802.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.10802)), ([:house:](https://huggingface.co/papers/2307.10802)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/meta-transformer-a-unified-framework-for)), ([:octocat:](https://github.com/invictus717/MetaTransformer)![GitHub Repo stars](https://img.shields.io/github/stars/invictus717/MetaTransformer?style=social)) |
| 7.19 | Study Tests Large Language Models‚Äô Ability to Answer Clinical Questions (Jama [doi: 10.1001/jama.2023.12553](https://jamanetwork.com/journals/jama/fullarticle/2807649)) |
| 7.19 | (Ab)using Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs ([:x:](https://arxiv.org/abs/2307.10490)), ([:paperclip:](https://arxiv.org/pdf/2307.10490.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.10490)), ([:house:](https://huggingface.co/papers/2307.10490)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/ab-using-images-and-sounds-for-indirect)), ([:octocat:](https://github.com/ebagdasa/multimodal_injection)![GitHub Repo stars](https://img.shields.io/github/stars/ebagdasa/multimodal_injection?style=social)) |
| 7.19 | Text2Layer: Layered Image Generation using Latent Diffusion Model ([:x:](https://arxiv.org/abs/2307.09781)), ([:paperclip:](https://arxiv.org/pdf/2307.09781.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.09781)), ([:house:](https://huggingface.co/papers/2307.09781)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/text2layer-layered-image-generation-using)) |
| 7.19 | Towards A Unified Agent with Foundation Models ([:x:](https://arxiv.org/abs/2307.09668)), ([:paperclip:](https://arxiv.org/pdf/2307.09668.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.09668)), ([:house:](https://huggingface.co/papers/2307.09668)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/towards-a-unified-agent-with-foundation)) |
| 7.19 | ‚≠ê Challenges and Applications of Large Language Models ([:x:](https://arxiv.org/abs/2307.10169)), ([:paperclip:](https://arxiv.org/pdf/2307.10169.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.10169)), ([:house:](https://huggingface.co/papers/2307.10169)), ([:eight_spoked_asterisk:]()) |
| 7.19 | On the Origin of LLMs: An Evolutionary Tree and Graph for 15,821 Large Language Models ([:x:](https://arxiv.org/abs/2307.09793)), ([:paperclip:](https://arxiv.org/pdf/2307.09793.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.09793)), ([:house:](https://huggingface.co/papers/2307.09793)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/on-the-origin-of-llms-an-evolutionary-tree)), ([Constellation](https://constellation.sites.stanford.edu/)) |
| 7.18 | Augmenting CLIP with Improved Visio-Linguistic Reasoning  ([:x:](https://arxiv.org/abs/2307.09233)), ([:paperclip:](https://arxiv.org/pdf/2307.09233.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.09233)), ([:house:](https://huggingface.co/papers/2307.09233)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/augmenting-clip-with-improved-visio)) |
| 7.18 | How generative AI will reshape the enterprise ([report](https://www.databricks.com/resources/ebook/mit-cio-generative-ai-report?utm_source=mit&utm_medium=press-release&utm_campaign=7018Y000001FhXLQA0)) |
| 7.18 | How is ChatGPT's behavior changing over time? ([:x:](https://arxiv.org/abs/2307.09009)), ([:paperclip:](https://arxiv.org/pdf/2307.09009.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.09009)), ([:house:](https://huggingface.co/papers/2307.09009)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/how-is-chatgpt-s-behavior-changing-over-time)), ([:octocat:](https://github.com/lchen001/llmdrift)![GitHub Repo stars](https://img.shields.io/github/stars/lchen001/llmdrift?style=social)) |
| 7.18 | NU-MCC: Multiview Compressive Coding with Neighborhood Decoder and Repulsive UDF ([:x:](https://arxiv.org/abs/2307.09112)), ([:paperclip:](https://arxiv.org/pdf/2307.09112.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.09112)), ([:house:](https://huggingface.co/papers/2307.09112)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/nu-mcc-multiview-compressive-coding-with)) |
| 7.18 | Measuring Faithfulness in Chain-of-Thought Reasoning ([PDF](https://www-files.anthropic.com/production/files/measuring-faithfulness-in-chain-of-thought-reasoning.pdf)) |
| 7.18 | ü¶ô Llama 2 and Claude 2 are now live on Chatbot Arena! ([arena](https://huggingface.co/spaces/lmsys/Chat-and-Battle-with-Open-LLMs)) |
| 7.18 | Statement of Support for Meta‚Äôs Open Approach to Today‚Äôs AI ([blog](https://about.fb.com/news/2023/07/llama-2-statement-of-support/)) |
| 7.18 | Llama 2: Open Foundation and Fine-Tuned Chat Models ([paper](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/)), ([PDF](https://scontent-ssn1-1.xx.fbcdn.net/v/t39.2365-6/10000000_663429262362723_1696968207443577320_n.pdf?_nc_cat=101&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=5ol-jUSglG4AX-46yHU&_nc_ht=scontent-ssn1-1.xx&oh=00_AfCR0oNWkc6kxTrD1j6ODAZq38M7xzwDzu8Fz-Z_h-v1kg&oe=64BBB691)), ([:octocat:](https://github.com/facebookresearch/llama)![GitHub Repo stars](https://img.shields.io/github/stars/facebookresearch/llama?style=social)) |
| 7.18 | Meta and Microsoft Introduce the Next Generation of Llama ([tweet](https://twitter.com/ylecun/status/1681336284453781505)), ([news](https://about.fb.com/news/2023/07/llama-2/)), ([Llama2](https://ai.meta.com/llama/)), ([download](https://ai.meta.com/llama/#download-the-model)) |
| 7.18 | Retentive Network: A Successor to Transformer for Large Language Models ([:x:](https://arxiv.org/abs/2307.08621)), ([:paperclip:](https://arxiv.org/pdf/2307.08621.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.08621)), ([:house:](https://huggingface.co/papers/2307.08621)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/retentive-network-a-successor-to-transformer)), ([:octocat:](https://github.com/microsoft/unilm)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/unilm?style=social))  |
| 7.18 | Diffusion Models Beat GANs on Image Classification ([:x:](https://arxiv.org/abs/2307.08702)), ([:paperclip:](https://arxiv.org/pdf/2307.08702.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.08702)), ([:house:](https://huggingface.co/papers/2307.08702)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/diffusion-models-beat-gans-on-image)) |
| 7.18 | BuboGPT: Enabling Visual Grounding in Multi-Modal LLMs ([:x:](https://arxiv.org/abs/2307.08581)), ([:paperclip:](https://arxiv.org/pdf/2307.08581.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.08581)), ([:house:](https://huggingface.co/papers/2307.08581)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/bubogpt-enabling-visual-grounding-in-multi)) |
| 7.18 | TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT ([:x:](https://arxiv.org/abs/2307.08674)), ([:paperclip:](https://arxiv.org/pdf/2307.08674.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.08674)), ([:house:](https://huggingface.co/papers/2307.08674)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/tablegpt-towards-unifying-tables-nature)) |
| 7.17 | Performance of a Large Language Model on Practice Questions for the Neonatal Board Examination (Jama [doi: 10.1001/jamapediatrics.2023.2373](https://jamanetwork.com/journals/jamapediatrics/fullarticle/2807329)) |
| 7.17 | Large language models in medicine (nature medicine [https://doi.org/10.1038/s41591-023-02448-8](https://www.nature.com/articles/s41591-023-02448-8)) |
| 7.17 | Chatbot vs Medical Student Performance on Free-Response Clinical Reasoning Examinations (JAMA, [doi:10.1001/jamainternmed.2023.2909](https://jamanetwork.com/journals/jamainternalmedicine/article-abstract/2806980)) |
| 7.17 | AlpaGasus: Training A Better Alpaca with Fewer Data ([:x:](https://arxiv.org/abs/2307.08701)), ([:paperclip:](https://arxiv.org/pdf/2307.08701.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.08701)), ([:house:](https://huggingface.co/papers/2307.08701)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/alpagasus-training-a-better-alpaca-with-fewer)) |
| 7.16 | Communicative Agents for Software Development ([:x:](https://arxiv.org/abs/2307.07924)), ([:paperclip:](https://arxiv.org/pdf/2307.07924.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.07924)), ([:house:](https://huggingface.co/papers/2307.07924)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/communicative-agents-for-software-development)) |
| 7.16 | Planting a SEED of Vision in Large Language Model ([:x:](https://arxiv.org/abs/2307.08041)), ([:paperclip:](https://arxiv.org/pdf/2307.08041.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.08041)), ([:house:](https://huggingface.co/papers/2307.08041)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/planting-a-seed-of-vision-in-large-language)), ([:octocat:](https://github.com/ailab-cvc/seed)![GitHub Repo stars](https://img.shields.io/github/stars/ailab-cvc/seed?style=social)) |
| 7.15 | DreamTeacher: Pretraining Image Backbones with Deep Generative Models ([:x:](https://arxiv.org/abs/2307.07487)), ([:paperclip:](https://arxiv.org/pdf/2307.07487.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.07487)), ([:house:](https://huggingface.co/papers/2307.07487)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/dreamteacher-pretraining-image-backbones-with)) |
| 7.15 | INVE: Interactive Neural Video Editing ([:x:](https://arxiv.org/abs/2307.07663)), ([:paperclip:](https://arxiv.org/pdf/2307.07663.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.07663)), ([:house:](https://huggingface.co/papers/2307.07663)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/inve-interactive-neural-video-editing)) |
| 7.14 | Are Large Language Models a Threat to Digital Public Goods? Evidence from Activity on Stack Overflow ([:x:](https://arxiv.org/abs/2307.07367)), ([:paperclip:](https://arxiv.org/pdf/2307.07367.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.07367)), ([:house:](https://huggingface.co/papers/2307.07367)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/are-large-language-models-a-threat-to-digital)) |
| 7.14 | China takes major step in regulating generative AI services like ChatGPT ([news](https://edition.cnn.com/2023/07/14/tech/china-ai-regulation-intl-hnk/index.html)), ([ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊúçÂä°ÁÆ°ÁêÜÊöÇË°åÂäûÊ≥ï](http://www.cac.gov.cn/2023-07/13/c_1690898327029107.htm)) |
| 7.14 | What Happens When You Ask a Chinese Chatbot About Taiwan? ([news](https://www.nytimes.com/2023/07/14/business/baidu-ernie-openai-chatgpt-chinese.html)) |
| 7.14 | In-context Autoencoder for Context Compression in a Large Language Model ([:x:](https://arxiv.org/abs/2307.06945)), ([:paperclip:](https://arxiv.org/pdf/2307.06945.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.06945)), ([:house:](https://huggingface.co/papers/2307.06945)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/in-context-autoencoder-for-context)) |
| 7.14 | Mega-TTS 2: Zero-Shot Text-to-Speech with Arbitrary Length Speech Prompts ([:x:](https://arxiv.org/abs/2307.07218)), ([:paperclip:](https://arxiv.org/pdf/2307.07218.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.07218)), ([:house:](https://huggingface.co/papers/2307.07218)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/mega-tts-2-zero-shot-text-to-speech-with)) |
| 7.14 | Learning to Retrieve In-Context Examples for Large Language Models ([:x:](https://arxiv.org/abs/2307.07164)), ([:paperclip:](https://arxiv.org/pdf/2307.07164.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.07164)), ([:house:](https://huggingface.co/papers/2307.07164)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/learning-to-retrieve-in-context-examples-for)) |
| 7.14 | Rerender A Video: Zero-Shot Text-Guided Video-to-Video Translation ([:x:](https://arxiv.org/abs/2307.07954)), ([:paperclip:](https://arxiv.org/pdf/2307.07954.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.07954)), ([:house:](https://huggingface.co/papers/2307.07954)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/rerender-a-video-zero-shot-text-guided-video)) |
| 7.14 | CoTracker: It is Better to Track Together ([:x:](https://arxiv.org/abs/2307.07635)), ([:paperclip:](https://arxiv.org/pdf/2307.07635.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.07635)), ([:house:](https://huggingface.co/papers/2307.07635)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/cotracker-it-is-better-to-track-together)) |
| 7.14 | The Practical Guides for Large Language Models ([:octocat:](https://github.com/Mooler0410/LLMsPracticalGuide)![GitHub Repo stars](https://img.shields.io/github/stars/Mooler0410/LLMsPracticalGuide?style=social)) |
| 7.14 | Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning ([paper](https://ai.meta.com/research/publications/scaling-autoregressive-multi-modal-models-pretraining-and-instruction-tuning/)), ([PDF](https://scontent-ssn1-1.xx.fbcdn.net/v/t39.2365-6/358725877_789390529544546_1176484804732743296_n.pdf?_nc_cat=108&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=_diQr9c6Ru8AX9jOhWR&_nc_ht=scontent-ssn1-1.xx&oh=00_AfDtxreR8dzOFPvXAZOSeIhGGGuztehyXcPvY6lcF_BaRA&oe=64B94F32)) |
| 7.14 | Introducing CM3leon, a more efficient, state-of-the-art generative model for text and images ([blog](https://ai.meta.com/blog/generative-ai-text-images-cm3leon/?utm_source=twitter&utm_medium=organic_social&utm_campaign=blog&utm_content=image)) |
| 7.14 | Animate-A-Story: Storytelling with Retrieval-Augmented Video Generation ([:x:](https://arxiv.org/abs/2307.06940)), ([:paperclip:](https://arxiv.org/pdf/2307.06940.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.06940)), ([:house:](https://huggingface.co/papers/2307.06940)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/animate-a-story-storytelling-with-retrieval)), ([:octocat:](https://github.com/videocrafter/animate-a-story)![GitHub Repo stars](https://img.shields.io/github/stars/videocrafter/animate-a-story?style=social)) |
| 7.14 | Domain-Agnostic Tuning-Encoder for Fast Personalization of Text-To-Image Models  ([:x:](https://arxiv.org/abs/2307.06925)), ([:paperclip:](https://arxiv.org/pdf/2307.06925.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.06925)), ([:house:](https://huggingface.co/papers/2307.06925)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/domain-agnostic-tuning-encoder-for-fast)) |
| 7.14 | Generating Benchmarks for Factuality Evaluation of Language Models ([:x:](https://arxiv.org/abs/2307.06908)), ([:paperclip:](https://arxiv.org/pdf/2307.06908.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.06908)), ([:house:](https://huggingface.co/papers/2307.06908)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/generating-benchmarks-for-factuality)) |
| 7.13 | F.T.C. Opens Investigation Into ChatGPT Maker Over Technology‚Äôs Potential Harms ([news](https://www.nytimes.com/2023/07/13/technology/chatgpt-investigation-ftc-openai.html)) |
| 7.13 | Instruction Mining: High-Quality Instruction Data Selection for Large Language Models ([:x:](https://arxiv.org/abs/2307.06290)), ([:paperclip:](https://arxiv.org/pdf/2307.06290.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.06290)), ([:house:](https://huggingface.co/papers/2307.06290)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/instruction-mining-high-quality-instruction)) |
| 7.13 | Patch n' Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution ([:x:](https://arxiv.org/abs/2307.06304)), ([:paperclip:](https://arxiv.org/pdf/2307.06304.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.06304)), ([:house:](https://huggingface.co/papers/2307.06304)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/patch-n-pack-navit-a-vision-transformer-for)) |
| 7.13 | T2I-CompBench: A Comprehensive Benchmark for Open-world Compositional Text-to-image Generation ([:x:](https://arxiv.org/abs/2307.06350)), ([:paperclip:](https://arxiv.org/pdf/2307.06350.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.06350)), ([:house:](https://huggingface.co/papers/2307.06350)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/t2i-compbench-a-comprehensive-benchmark-for)), ([:octocat:](https://github.com/Karine-Huang/T2I-CompBench)![GitHub Repo stars](https://img.shields.io/github/stars/Karine-Huang/T2I-CompBench?style=social)) |
| 7.13 | Distilling Large Language Models for Biomedical Knowledge Extraction: A Case Study on Adverse Drug Events ([:x:](https://arxiv.org/abs/2307.06439)), ([:paperclip:](https://arxiv.org/pdf/2307.06439.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.06439)), ([:house:](https://huggingface.co/papers/2307.06439)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/distilling-large-language-models-for)) |
| 7.13 | DIALGEN: Collaborative Human-LM Generated Dialogues for Improved Understanding of Human-Human Conversations ([:x:](https://arxiv.org/abs/2307.07047)), ([:paperclip:](https://arxiv.org/pdf/2307.07047.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.07047)), ([:house:](https://huggingface.co/papers/2307.07047)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/dialgen-collaborative-human-lm-generated)) |
| 7.13 | Copy Is All You Need ([:x:](https://arxiv.org/abs/2307.06962)), ([:paperclip:](https://arxiv.org/pdf/2307.06962.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.06962)), ([:house:](https://huggingface.co/papers/2307.06962)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/copy-is-all-you-need)), ([:octocat:](https://github.com/gmftbygmftby/copyisallyouneed)![GitHub Repo stars](https://img.shields.io/github/stars/gmftbygmftby/copyisallyouneed?style=social)) |
| 7.13 | AniFaceDrawing: Anime Portrait Exploration during Your Sketching ([:x:](https://arxiv.org/abs/2307.07476)), ([:paperclip:](https://arxiv.org/pdf/2307.07476.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.07476)), ([:house:](https://huggingface.co/papers/2307.07476)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/anifacedrawing-anime-portrait-exploration)) |
| 7.13 | HyperDreamBooth: HyperNetworks for Fast Personalization of Text-to-Image Models ([project](https://hyperdreambooth.github.io/)), ([:x:](https://arxiv.org/abs/2307.06949)), ([:paperclip:](https://arxiv.org/pdf/2307.06949.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.06949)), ([:house:](https://huggingface.co/papers/2307.06949)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/hyperdreambooth-hypernetworks-for-fast)) |
| 7.13 | Stability AI releases Stable Doodle, a sketch-to-image tool ([news](https://techcrunch.com/2023/07/13/stability-ai-releases-stable-doodle-a-sketch-to-image-tool/)), ([announcement](https://stability.ai/blog/clipdrop-launches-stable-doodle)) |
| 7.12 | Efficient 3D Articulated Human Generation with Layered Surface Volumes ([:x:](https://arxiv.org/abs/2307.05462)), ([:paperclip:](https://arxiv.org/pdf/2307.05462.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.05462)), ([:house:](https://huggingface.co/papers/2307.05462)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/efficient-3d-articulated-human-generation)) |
| 7.12 | SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Task Planning ([:x:](https://arxiv.org/abs/2307.06135)), ([:paperclip:](https://arxiv.org/pdf/2307.06135.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.06135)), ([:house:](https://huggingface.co/papers/2307.06135)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/sayplan-grounding-large-language-models-using)) |
| 7.12 | Stack More Layers Differently: High-Rank Training Through Low-Rank Updates ([:x:](https://arxiv.org/abs/2307.05695)), ([:paperclip:](https://arxiv.org/pdf/2307.05695.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.05695)), ([:house:](https://huggingface.co/papers/2307.05695)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/stack-more-layers-differently-high-rank)), ([:octocat:](https://github.com/guitaricet/peft_pretraining)![GitHub Repo stars](https://img.shields.io/github/stars/guitaricet/peft_pretraining?style=social)) |
| 7.12 | PolyLM: An Open Source Polyglot Large Language Model  ([:x:](https://arxiv.org/abs/2307.06018)), ([:paperclip:](https://arxiv.org/pdf/2307.06018.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.06018)), ([:house:](https://huggingface.co/papers/2307.06018)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/polylm-an-open-source-polyglot-large-language)) |
| 7.12 | Today we announce the formation of xAI ([announcement](https://x.ai/)) |
| 7.12 | Large language models encode clinical knowledge (Nature, [https://doi.org/10.1038/s41586-023-06291-2](https://www.nature.com/articles/s41586-023-06291-2)), ([PDF](https://www.nature.com/articles/s41586-023-06291-2.pdf)) |
| 7.12 | Google's NotebookLM ([waitlist](https://notebooklm.google.com/about)) |
| 7.12 | 27% of jobs at high risk from AI revolution, says OECD ([news](https://www.reuters.com/technology/27-jobs-high-risk-ai-revolution-says-oecd-2023-07-11/)) |
| 7.12 | Objaverse-XL: A Universe of 10M+ 3D Objects ([PDF](https://objaverse.allenai.org/objaverse-xl-paper.pdf)) |
| 7.12 | EgoVLPv2: Egocentric Video-Language Pre-training with Fusion in the Backbone ([:x:](https://arxiv.org/abs/2307.05463)), ([:paperclip:](https://arxiv.org/pdf/2307.05463.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.05463)), ([:house:](https://huggingface.co/papers/2307.05463)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/egovlpv2-egocentric-video-language-pre)) |
| 7.12 | Differentiable Blocks World: Qualitative 3D Decomposition by Rendering Primitives ([:x:](https://arxiv.org/abs/2307.05473)), ([:paperclip:](https://arxiv.org/pdf/2307.05473.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.05473)), ([:house:](https://huggingface.co/papers/2307.05473)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/differentiable-blocks-world-qualitative-3d)) |
| 7.11 | AmadeusGPT: a natural language interface for interactive animal behavioral analysis ([:x:](https://arxiv.org/abs/2307.04858)), ([:paperclip:](https://arxiv.org/pdf/2307.04858.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.04858)), ([:house:](https://huggingface.co/papers/2307.04858)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/amadeusgpt-a-natural-language-interface-for)), ([:octocat:](https://github.com/adaptivemotorcontrollab/amadeusgpt)![GitHub Repo stars](https://img.shields.io/github/stars/adaptivemotorcontrollab/amadeusgpt?style=social)) |
| 7.11 | 3 principles for regulatory-grade large language model application (CIO [news](https://www.cio.com/article/645602/3-principles-for-regulatory-grade-large-language-model-application.html)) |
| 7.11 | Generative Pretraining in Multimodality ([:x:](https://arxiv.org/abs/2307.05222)), ([:paperclip:](https://arxiv.org/pdf/2307.05222.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.05222)), ([:house:](https://huggingface.co/papers/2307.05222)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/generative-pretraining-in-multimodality)), ([:octocat:](https://github.com/baaivision/emu)![GitHub Repo stars](https://img.shields.io/github/stars/baaivision/emu?style=social)) |
| 7.11 | DNAGPT: A Generalized Pretrained Tool for Multiple DNA Sequence Analysis Tasks ([:x:](https://arxiv.org/abs/2307.05628)), ([:paperclip:](https://arxiv.org/pdf/2307.05628.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.05628)), ([:house:](https://huggingface.co/papers/2307.05628)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/dnagpt-a-generalized-pretrained-tool-for)) |
| 7.11 | VampNet: Music Generation via Masked Acoustic Token Modeling  ([:x:](https://arxiv.org/abs/2307.04686)), ([:paperclip:](https://arxiv.org/pdf/2307.04686.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.04686)), ([:house:](https://huggingface.co/papers/2307.04686)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/vampnet-music-generation-via-masked-acoustic)) |
| 7.11 | Shelving, Stacking, Hanging: Relational Pose Diffusion for Multi-modal Rearrangement  ([:x:](https://arxiv.org/abs/2307.04751)), ([:paperclip:](https://arxiv.org/pdf/2307.04751.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.04751)), ([:house:](https://huggingface.co/papers/2307.04751)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/shelving-stacking-hanging-relational-pose)) |
| 7.11 | International Institutions for Advanced AI ([:x:](https://arxiv.org/abs/2307.04699)), ([:paperclip:](https://arxiv.org/pdf/2307.04699.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.04699)), ([:house:](https://huggingface.co/papers/2307.04699)), ([:eight_spoked_asterisk:]()) |
| 7.11 | Semantic-SAM: Segment and Recognize Anything at Any Granularity  ([:x:](https://arxiv.org/abs/2307.04767)), ([:paperclip:](https://arxiv.org/pdf/2307.04767.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.04767)), ([:house:](https://huggingface.co/papers/2307.04767)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/semantic-sam-segment-and-recognize-anything)), ([:octocat:](https://github.com/ux-decoder/semantic-sam)![GitHub Repo stars](https://img.shields.io/github/stars/ux-decoder/semantic-sam?style=social)) |
| 7.11 | AI tools are designing entirely new proteins that could transform medicine (Nature, [doi: https://doi.org/10.1038/d41586-023-02227-y](https://www.nature.com/articles/d41586-023-02227-y)), ([PDF](https://www.nature.com/articles/d41586-023-02227-y.pdf?pdf=button%20sticky)) |
| 7.11 | Shutterstock expands deal with OpenAI to build generative AI tools ([news](https://techcrunch.com/2023/07/11/shutterstock-expands-deal-with-openai-to-build-generative-ai-tools/)) |
| 7.11 | Generative Pretraining in Multimodality ([:x:](https://arxiv.org/abs/2307.05222)), ([:paperclip:](https://arxiv.org/pdf/2307.05222.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.05222)), ([:house:](https://huggingface.co/papers/2307.05222)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/generative-pretraining-in-multimodality)) |
| 7.11 | Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration  ([:x:](https://arxiv.org/abs/2307.05300)), ([:paperclip:](https://arxiv.org/pdf/2307.05300.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.05300)), ([:house:](https://huggingface.co/papers/2307.05300)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/unleashing-cognitive-synergy-in-large)) |
| 7.11 | Secrets of RLHF in Large Language Models Part I: PPO ([:x:](https://arxiv.org/abs/2307.04964)), ([:paperclip:](https://arxiv.org/pdf/2307.04964.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.04964)), ([:house:](https://huggingface.co/papers/2307.04964)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/secrets-of-rlhf-in-large-language-models-part)),  ([:octocat:](https://github.com/OpenLMLab/MOSS-RLHF)![GitHub Repo stars](https://img.shields.io/github/stars/OpenLMLab/MOSS-RLHF?style=social)) |
| 7.11 | Anthropic's Claude-2 was just released ([blog](https://www.anthropic.com/index/claude-2)), ([claude](https://claude.ai/login)) |
| 7.11 | Large Language Models as General Pattern Machines ([:x:](https://arxiv.org/abs/2307.04721)), ([:paperclip:](https://arxiv.org/pdf/2307.04721.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.04721)), ([:house:](https://huggingface.co/papers/2307.04721)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/large-language-models-as-general-pattern)) |
| 7.10 | Google is testing its medical AI chatbot at the Mayo Clinic ([news](https://www.engadget.com/google-is-testing-its-medical-ai-chatbot-at-the-mayo-clinic-102055669.html?guccounter=1)) |
| 7.10 | RLTF: Reinforcement Learning from Unit Test Feedback ([:x:](https://arxiv.org/abs/2307.04349)), ([:paperclip:](https://arxiv.org/pdf/2307.04349.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.04349)), ([:house:](https://huggingface.co/papers/2307.04349)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/rltf-reinforcement-learning-from-unit-test)) |
| 7.10 | AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning ([:x:](https://arxiv.org/abs/2307.04725)), ([:paperclip:](https://arxiv.org/pdf/2307.04725.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.04725)), ([:house:](https://huggingface.co/papers/2307.04725)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/animatediff-animate-your-personalized-text-to)), ([:octocat:](https://github.com/guoyww/animatediff)![GitHub Repo stars](https://img.shields.io/github/stars/guoyww/animatediff?style=social)) |
| 7.10 | GPT Researcher - GPT based autonomous agent that does online comprehensive research on any given topic ([:octocat:](https://github.com/assafelovic/gpt-researcher)![GitHub Repo stars](https://img.shields.io/github/stars/assafelovic/gpt-researcher?style=social))  |
| 7.9 | Chapyter: ChatGPT Code Interpreter in Jupyter Notebooks ([:octocat:](https://github.com/chapyter/chapyter)![GitHub Repo stars](https://img.shields.io/github/stars/chapyter/chapyter?style=social)) |
| 7.9 | DragGAN - Drag Your GAN - Face Inversion: Interactive Point-based Manipulation on the Generative Image Manifold ([tweet](https://twitter.com/radamar/status/1677924592915206144)), ([HF demo](https://huggingface.co/spaces/DragGan/DragGan-Inversion)) |
| 7.8 | Google‚Äôs medical AI chatbot is already being tested in hospitals ([news](https://www.theverge.com/2023/7/8/23788265/google-med-palm-2-mayo-clinic-chatbot-bard-chatgpt)) |
| 7.8 | Large Language Models for Supply Chain Optimization ([:x:](https://arxiv.org/abs/2307.03875)), ([:paperclip:](https://arxiv.org/pdf/2307.03875.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.03875)), ([:house:](https://huggingface.co/papers/2307.03875)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/large-language-models-for-supply-chain)) |
| 7.8 | Sketch-A-Shape: Zero-Shot Sketch-to-3D Shape Generation ([:x:](https://arxiv.org/abs/2307.03869)), ([:paperclip:](https://arxiv.org/pdf/2307.03869.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.03869)), ([:house:](https://huggingface.co/papers/2307.03869)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/sketch-a-shape-zero-shot-sketch-to-3d-shape)) |
| 7.8 | AutoDecoding Latent 3D Diffusion Models ([:x:](https://arxiv.org/abs/2307.05445)), ([:paperclip:](https://arxiv.org/pdf/2307.05445.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.05445)), ([:house:](https://huggingface.co/papers/2307.05445)), ([:eight_spoked_asterisk:]()) |
| 7.8 | Awesome Generative AI Techniques: a curated list of Generative AI Techniques ([:octocat:](https://github.com/hollobit/awesome-GenAITech)![GitHub Repo stars](https://img.shields.io/github/stars/hollobit/awesome-GenAITech?style=social))  |
| 7.8 | Robots say they won't steal jobs, rebel against humans ([news](https://www.reuters.com/technology/robots-say-they-wont-steal-jobs-rebel-against-humans-2023-07-07/)) |
| 7.7 | CheXmask: a large-scale dataset of anatomical segmentation masks for multi-center chest x-ray images ([:x:](https://arxiv.org/abs/2307.03293)), ([:paperclip:](https://arxiv.org/pdf/2307.03293.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.03293)), ([:house:](https://huggingface.co/papers/2307.03293)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/chexmask-a-large-scale-dataset-of-anatomical)), ([:octocat:](https://github.com/ngaggion/chexmask-database)![GitHub Repo stars](https://img.shields.io/github/stars/ngaggion/chexmask-database?style=social)) |
| 7.7 | Teaching Arithmetic to Small Transformers ([:x:](https://arxiv.org/abs/2307.03381)), ([:paperclip:](https://arxiv.org/pdf/2307.03381.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.03381)), ([:house:](https://huggingface.co/papers/2307.03381)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/teaching-arithmetic-to-small-transformers)) |
| 7.7 | GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest ([:x:](https://arxiv.org/abs/2307.03601)), ([:paperclip:](https://arxiv.org/pdf/2307.03601.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.03601)), ([:house:](https://huggingface.co/papers/2307.03601)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/gpt4roi-instruction-tuning-large-language)) |
| 7.7 | Lost in the Middle: How Language Models Use Long Contexts ([:x:](https://arxiv.org/abs/2307.03172)), ([:paperclip:](https://arxiv.org/pdf/2307.03172.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.03172)), ([:house:](https://huggingface.co/papers/2307.03172)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/lost-in-the-middle-how-language-models-use)) |
| 7.6 | What Should Data Science Education Do with Large Language Models? ([:x:](https://arxiv.org/abs/2307.02792)), ([:paperclip:](https://arxiv.org/pdf/2307.02792.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.02792)), ([:house:](https://huggingface.co/papers/2307.02792)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/what-should-data-science-education-do-with)) |
| 7.6 | A.I. Will Change Medicine but Not What It Means to Be a Doctor (NYT, [news](https://archive.is/nJtCC)) |
| 7.6 | Frontier AI Regulation: Managing Emerging Risks to Public Safety ([:x:](https://arxiv.org/abs/2307.03718)), ([:paperclip:](https://arxiv.org/pdf/2307.03718.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.03718)), ([:house:](https://huggingface.co/papers/2307.03718)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/frontier-ai-regulation-managing-emerging)) |
| 7.6 | The imperative for regulatory oversight of large language models (or generative AI) in healthcare (npj Digital Medicine, [https://doi.org/10.1038/s41746-023-00873-0](https://www.nature.com/articles/s41746-023-00873-0)), ([PDF](https://www.nature.com/articles/s41746-023-00873-0.pdf?pdf=button%20sticky)) |
| 7.6 | OpenAI launches ChatGTP code interpreter for better coding using only natural language ([tweet](https://twitter.com/OpenAI/status/1677015057316872192)), ([blog](https://the-decoder.com/openai-launches-chatgtp-code-interpreter-for-better-coding-using-only-natural-language/)), ([news](https://www.searchenginejournal.com/code-interpreter-chatgpt-plus/490980/#close)) |
| 7.6 | Jailbroken: How Does LLM Safety Training Fail? ([:x:](https://arxiv.org/abs/2307.02483)), ([:paperclip:](https://arxiv.org/pdf/2307.02483.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.02483)), ([:house:](https://huggingface.co/papers/2307.02483)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/jailbroken-how-does-llm-safety-training-fail)) |
| 7.6 | Building Cooperative Embodied Agents Modularly with Large Language Models ([:x:](https://arxiv.org/abs/2307.02485)), ([:paperclip:](https://arxiv.org/pdf/2307.02485.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.02485)), ([:house:](https://huggingface.co/papers/2307.02485)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/building-cooperative-embodied-agents)) |
| 7.6 | What Matters in Training a GPT4-Style Language Model with Multimodal Inputs?  ([:x:](https://arxiv.org/abs/2307.02469)), ([:paperclip:](https://arxiv.org/pdf/2307.02469.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.02469)), ([:house:](https://huggingface.co/papers/2307.02469)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/what-matters-in-training-a-gpt4-style)) |
| 7.6 | DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models ([:x:](https://arxiv.org/abs/2307.02421)), ([:paperclip:](https://arxiv.org/pdf/2307.02421.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.02421)), ([:house:](https://huggingface.co/papers/2307.02421)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/dragondiffusion-enabling-drag-style)), ([:octocat:](https://github.com/mc-e/dragondiffusion)![GitHub Repo stars](https://img.shields.io/github/stars/mc-e/dragondiffusion?style=social)) |
| 7.6 | Elastic Decision Transformer ([:x:](https://arxiv.org/abs/2307.02484)), ([:paperclip:](https://arxiv.org/pdf/2307.02484.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.02484)), ([:house:](https://huggingface.co/papers/2307.02484)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/elastic-decision-transformer)) |
| 7.6 | Releasing üöÄ CodeGen2.5 üöÄ, a small but mighty LLM for code ([tweet](https://twitter.com/erik_nijkamp/status/1677055271104045056)), ([blog](https://blog.salesforceairesearch.com/codegen25/)), ([:octocat:](https://github.com/salesforce/CodeGen)![GitHub Repo stars](https://img.shields.io/github/stars/salesforce/CodeGen?style=social)) |
| 7.6 | Training Models to Generate, Recognize, and Reframe Unhelpful Thoughts ([:x:](https://arxiv.org/abs/2307.02768)), ([:paperclip:](https://arxiv.org/pdf/2307.02768.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.02768)), ([:house:](https://huggingface.co/papers/2307.02768)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/training-models-to-generate-recognize-and)) |
| 7.6 | Lost in the Middle: How Language Models Use Long Contexts ([:x:](https://arxiv.org/abs/2307.03172)), ([:paperclip:](https://arxiv.org/pdf/2307.03172.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.03172)), ([:house:](https://huggingface.co/papers/2307.03172)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/lost-in-the-middle-how-language-models-use)) |
| 7.6 | Artificial Intelligence in Clinical Diagnosis Opportunities, Challenges, and Hype (JAMA, [doi:10.1001/jama.2023.11440](https://jamanetwork.com/journals/jama/fullarticle/2807166)) |
| 7.6 | AI Chatbots, Health Privacy, and Challenges to HIPAA Compliance (JAMA, [doi:10.1001/jama.2023.9458](https://jamanetwork.com/journals/jama/fullarticle/2807170)) |
| 7.6 | Health Care Privacy Risks of AI Chatbots (JAMA, [doi:10.1001/jama.2023.9618](https://jamanetwork.com/journals/jama/fullarticle/2807169)) |
| 7.6 | Generative AI in Health Care and Liability Risks for Physicians and Safety Concerns for Patients (JAMA, [doi:10.1001/jama.2023.9630](https://jamanetwork.com/journals/jama/fullarticle/2807168)) |
| 7.6 | The Challenges for Regulating Medical Use of ChatGPT and Other Large Language Models (JAMA, [doi:10.1001/jama.2023.9651](https://jamanetwork.com/journals/jama/fullarticle/2807167)) |
| 7.6 | A Survey on Evaluation of Large Language Models ([:x:](https://arxiv.org/abs/2307.03109)), ([:paperclip:](https://arxiv.org/pdf/2307.03109.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.03109)), ([:house:](https://huggingface.co/papers/2307.03109)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-survey-on-evaluation-of-large-language)), ([SS](https://www.semanticscholar.org/paper/A-Survey-on-Evaluation-of-Large-Language-Models-Chang-Wang/5530f6f57e3e1bc7ba1910b1c4274ec5a7a0a44f)) |
| 7.5 | Collaborative Score Distillation for Consistent Visual Synthesis ([:x:](https://arxiv.org/abs/2307.04787)), ([:paperclip:](https://arxiv.org/pdf/2307.04787.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.04787)), ([:house:](https://huggingface.co/papers/2307.04787)), ([:eight_spoked_asterisk:]()) |
| 7.5 | Becoming self-instruct: introducing early stopping criteria for minimal instruct tuning ([:x:](https://arxiv.org/abs/2307.03692)), ([:paperclip:](https://arxiv.org/pdf/2307.03692.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.03692)), ([:house:](https://huggingface.co/papers/2307.03692)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/becoming-self-instruct-introducing-early)) |
| 7.5 | OpenAI - Introducing Superalignment ([blog](https://openai.com/blog/introducing-superalignment)) |
| 7.5 | Open-Source Large Language Models Outperform Crowd Workers and Approach ChatGPT in Text-Annotation Tasks ([:x:](https://arxiv.org/abs/2307.02179)), ([:paperclip:](https://arxiv.org/pdf/2307.02179.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.02179)), ([:house:](https://huggingface.co/papers/2307.02179)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/open-source-large-language-models-outperform)) |
| 7.5 | Embodied Task Planning with Large Language Models ([:x:](https://arxiv.org/abs/2307.01928)), ([:paperclip:](https://arxiv.org/pdf/2307.01928.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.01928)), ([:house:](https://huggingface.co/papers/2307.01928)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/embodied-task-planning-with-large-language)) |
| 7.5 | Flacuna: Unleashing the Problem Solving Power of Vicuna using FLAN Fine-Tuning ([:x:](https://arxiv.org/abs/2307.02053)), ([:paperclip:](https://arxiv.org/pdf/2307.02053.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.02053)), ([:house:](https://huggingface.co/papers/2307.02053)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/flacuna-unleashing-the-problem-solving-power)), ([:octocat:](https://github.com/declare-lab/flacuna)![GitHub Repo stars](https://img.shields.io/github/stars/declare-lab/flacuna?style=social))  |
| 7.5 | Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners  ([:x:](https://arxiv.org/abs/2307.01848)), ([:paperclip:](https://arxiv.org/pdf/2307.01848.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.01848)), ([:house:](https://huggingface.co/papers/2307.01848)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/robots-that-ask-for-help-uncertainty)) |
| 7.5 | Physics-based Motion Retargeting from Sparse Inputs  ([:x:](https://arxiv.org/abs/2307.01938)), ([:paperclip:](https://arxiv.org/pdf/2307.01938.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.01938)), ([:house:](https://huggingface.co/papers/2307.01938)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/physics-based-motion-retargeting-from-sparse)) |
| 7.5 | MSViT: Dynamic Mixed-Scale Tokenization for Vision Transformers  ([:x:](https://arxiv.org/abs/2307.02321)), ([:paperclip:](https://arxiv.org/pdf/2307.02321.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.02321)), ([:house:](https://huggingface.co/papers/2307.02321)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/msvit-dynamic-mixed-scale-tokenization-for)) |
| 7.5 | Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks ([:x:](https://arxiv.org/abs/2307.02477)), ([:paperclip:](https://arxiv.org/pdf/2307.02477.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.02477)), ([:house:](https://huggingface.co/papers/2307.02477)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/reasoning-or-reciting-exploring-the)) |
| 7.5 | All about the generative tasks in the Generative Medical AI ([blog](https://link.medium.com/be79VOaheBb)) |
| 7.5 | LongNet: Scaling Transformers to 1,000,000,000 Tokens ([:x:](https://arxiv.org/abs/2307.02486)), ([:paperclip:](https://arxiv.org/pdf/2307.02486.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.02486)), ([:house:](https://huggingface.co/papers/2307.02486)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/longnet-scaling-transformers-to-1000000000)), ([:octocat:](https://github.com/kyegomez/LongNet)![GitHub Repo stars](https://img.shields.io/github/stars/kyegomez/LongNet?style=social)) |
| 7.4 | Segment Anything Meets Point Tracking ([:x:](https://arxiv.org/abs/2307.01197)), ([:paperclip:](https://arxiv.org/pdf/2307.01197.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.01197)), ([:house:](https://huggingface.co/papers/2307.01197)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/segment-anything-meets-point-tracking)), ([:octocat:](https://github.com/SysCV/sam-pt)![GitHub Repo stars](https://img.shields.io/github/stars/SysCV/sam-pt?style=social)) |
| 7.4 | Career Essentials in Generative AI by Microsoft and LinkedIn ([learning](https://www.linkedin.com/learning/paths/career-essentials-in-generative-ai-by-microsoft-and-linkedin)) |
| 7.4 | SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis ([PDF](https://github.com/Stability-AI/generative-models/blob/main/assets/sdxl_report.pdf)), ([:x:](https://arxiv.org/abs/2307.01952)), ([:paperclip:](https://arxiv.org/pdf/2307.01952.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.01952)), ([:house:](https://huggingface.co/papers/2307.01952)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/sdxl-improving-latent-diffusion-models-for)), ([:octocat:](https://github.com/stability-ai/generative-models)![GitHub Repo stars](https://img.shields.io/github/stars/stability-ai/generative-models?style=social)) |
| 7.4 | Real-time Monocular Full-body Capture in World Space via Sequential Proxy-to-Motion Learning ([:x:](https://arxiv.org/abs/2307.01200)), ([:paperclip:](https://arxiv.org/pdf/2307.01200.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.01200)), ([:house:](https://huggingface.co/papers/2307.01200)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/real-time-monocular-full-body-capture-in)) |
| 7.3 | Motion-X: A Large-scale 3D Expressive Whole-body Human Motion Dataset ([:x:](https://arxiv.org/abs/2307.00818)), ([:paperclip:](https://arxiv.org/pdf/2307.00818.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.00818)), ([:house:](https://huggingface.co/papers/2307.00818)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/motion-x-a-large-scale-3d-expressive-whole)), ([:octocat:](https://github.com/idea-research/motion-x)![GitHub Repo stars](https://img.shields.io/github/stars/idea-research/motion-x?style=social)) |
| 7.3 | EmoGen: Eliminating Subjective Bias in Emotional Music Generation ([:x:](https://arxiv.org/abs/2307.01229)), ([:paperclip:](https://arxiv.org/pdf/2307.01229.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.01229)), ([:house:](https://huggingface.co/papers/2307.01229)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/emogen-eliminating-subjective-bias-in)) |
| 7.3 | SketchMetaFace: A Learning-based Sketching Interface for High-fidelity 3D Character Face Modeling ([:x:](https://arxiv.org/abs/2307.00804)), ([:paperclip:](https://arxiv.org/pdf/2307.00804.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.00804)), ([:house:](https://huggingface.co/papers/2307.00804)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/sketchmetaface-a-learning-based-sketching)) |
| 7.2 | LEDITS: Real Image Editing with DDPM Inversion and Semantic Guidance ([:x:](https://arxiv.org/abs/2307.00522)), ([:paperclip:](https://arxiv.org/pdf/2307.00522.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.00522)), ([:house:](https://huggingface.co/papers/2307.00522)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/ledits-real-image-editing-with-ddpm-inversion)), ([demo](https://huggingface.co/spaces/editing-images/ledits)) |
| 7.1 | Global Mental Health Services and the Impact of Artificial Intelligence‚ÄìPowered Large Language Models (Jama [doi:10.1001/jamapediatrics.2023.2373](https://jamanetwork.com/journals/jamapsychiatry/fullarticle/2804646)) |
| 7.1 | Personality Traits in Large Language Models ([:x:](https://arxiv.org/abs/2307.00184)), ([:paperclip:](https://arxiv.org/pdf/2307.00184.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.00184)), ([:house:](https://huggingface.co/papers/2307.00184)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/personality-traits-in-large-language-models)) |
| 7.1 | DisCo: Disentangled Control for Referring Human Dance Generation in Real World ([:x:](https://arxiv.org/abs/2307.00040)), ([:paperclip:](https://arxiv.org/pdf/2307.00040.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.00040)), ([:house:](https://huggingface.co/papers/2307.00040)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/disco-disentangled-control-for-referring)), ([:octocat:](https://github.com/Wangt-CN/DisCo)![GitHub Repo stars](https://img.shields.io/github/stars/Wangt-CN/DisCo?style=social)) |
| 7.1 | BatGPT: A Bidirectional Autoregessive Talker from Generative Pre-trained Transformer ([:x:](https://arxiv.org/abs/2307.00360)), ([:paperclip:](https://arxiv.org/pdf/2307.00360.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2307.00360)), ([:house:](https://huggingface.co/papers/2307.00360)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/batgpt-a-bidirectional-autoregessive-talker)) |
| 7.1 | Improve ChatGPT with Knowledge Graphs ([blog](https://mlabonne.github.io/blog/posts/Article_Improve_ChatGPT_with_Knowledge_Graphs.html)) |
| 7.1 | The Rise of the AI Engineer ([Blog](https://www.latent.space/p/ai-engineer)) |  
| 6.30 | DrugGPT: A GPT-based Strategy for Designing Potential Ligands Targeting Specific Proteins  ([:x:](https://www.biorxiv.org/content/10.1101/2023.06.29.543848v1)), ([:paperclip:](https://www.biorxiv.org/content/10.1101/2023.06.29.543848v1.full.pdf)) |
| 6.30 | Doctor Chatbot: The EU ºs Regulatory Prescription for Generative Medical AI (Oslo Law Review, [https://doi.org/10.18261/olr.10.1.1](https://www.idunn.no/doi/10.18261/olr.10.1.1)), ([PDF](https://www.idunn.no/doi/epdf/10.18261/olr.10.1.1)) |
| 6.30 | Preference Ranking Optimization for Human Alignment ([:x:](https://arxiv.org/abs/2306.17492)), ([:paperclip:](https://arxiv.org/pdf/2306.17492.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.17492)), ([:house:](https://huggingface.co/papers/2306.17492)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/preference-ranking-optimization-for-human)) |
| 6.30 | Reliability of Medical Information Provided by ChatGPT: Assessment Against Clinical Guidelines and Patient Information Quality Instrument (JMIR, [doi: 10.2196/47479](https://www.jmir.org/2023/1/e47479)), ([PDF](https://www.jmir.org/2023/1/e47479/PDF)) |
| 6.30 | Large language model AI chatbots require approval as medical devices (Nature Medicine, [https://doi.org/10.1038/s41591-023-02412-6](https://www.nature.com/articles/s41591-023-02412-6)) | 
| 6.30 | LLaVAR: Enhanced Visual Instruction Tuning for Text-Rich Image Understanding ([:x:](https://arxiv.org/abs/2306.17107)), ([:paperclip:](https://arxiv.org/pdf/2306.17107.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.17107)), ([:house:](https://huggingface.co/papers/2306.17107)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/llavar-enhanced-visual-instruction-tuning-for)) |
| 6.30 | Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors ([:x:](https://arxiv.org/abs/2306.17156)), ([:paperclip:](https://arxiv.org/pdf/2306.17156.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.17156)), ([:house:](https://huggingface.co/papers/2306.17156)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/generative-ai-for-programming-education)) |
| 6.30 | Michelangelo: Conditional 3D Shape Generation based on Shape-Image-Text Aligned Latent Representation ([:x:](https://arxiv.org/abs/2306.17115)), ([:paperclip:](https://arxiv.org/pdf/2306.17115.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.17115)), ([:house:](https://huggingface.co/papers/2306.17115)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/michelangelo-conditional-3d-shape-generation)) |
| 6.30 | Generate Anything Anywhere in Any Scene ([:x:](https://arxiv.org/abs/2306.17154)), ([:paperclip:](https://arxiv.org/pdf/2306.17154.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.17154)), ([:house:](https://huggingface.co/papers/2306.17154)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/generate-anything-anywhere-in-any-scene)) |
| 6.30 | Benchmarking Large Language Model Capabilities for Conditional Generation ([:x:](https://arxiv.org/abs/2306.16793)), ([:paperclip:](https://arxiv.org/pdf/2306.16793.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.16793)), ([:house:](https://huggingface.co/papers/2306.16793)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/benchmarking-large-language-model)) |
| 6.29 | ‚≠ê A Survey of Large Language Models - version 11 ([:x:](https://arxiv.org/abs/2303.18223)), ([:paperclip:](https://arxiv.org/pdf/2303.18223.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.18223)), ([:house:](https://huggingface.co/papers/2303.18223)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-survey-of-large-language-models)), ([:octocat:](https://github.com/rucaibox/llmsurvey)![GitHub Repo stars](https://img.shields.io/github/stars/rucaibox/llmsurvey?style=social)), ([SS](https://www.semanticscholar.org/paper/A-Survey-of-Large-Language-Models-Zhao-Zhou/1d29334cfbe9a1a943082058876f0c22d44c62fd))  |
| 6.29 | June 2023, A Stage Review of Instruction Tuning ([notion](https://yaofu.notion.site/June-2023-A-Stage-Review-of-Instruction-Tuning-f59dbfc36e2d4e12a33443bd6b2012c2)) |
| 6.29 | Towards Language Models That Can See: Computer Vision Through the LENS of Natural Language ([:x:](https://arxiv.org/abs/2306.16410)), ([:paperclip:](https://arxiv.org/pdf/2306.16410.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.16410)), ([:house:](https://huggingface.co/papers/2306.16410)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/towards-language-models-that-can-see-computer)), ([:octocat:](https://github.com/contextualai/lens)![GitHub Repo stars](https://img.shields.io/github/stars/contextualai/lens?style=social)) |
| 6.29 | Towards Measuring the Representation of Subjective Global Opinions in Language Models ([:x:](https://arxiv.org/abs/2306.16388)), ([:paperclip:](https://arxiv.org/pdf/2306.16388.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.16388)), ([:house:](https://huggingface.co/papers/2306.16388)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/towards-measuring-the-representation-of)) |
| 6.29 | REFLECT: Summarizing Robot Experiences for Failure Explanation and Correction ([:x:](https://arxiv.org/abs/2306.15724)), ([:paperclip:](https://arxiv.org/pdf/2306.15724.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.15724)), ([:house:](https://huggingface.co/papers/2306.15724)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/reflect-summarizing-robot-experiences-for)) |
| 6.29 | One-2-3-45: Any Single Image to 3D Mesh in 45 Seconds without Per-Shape Optimization ([:x:](https://arxiv.org/abs/2306.16928)), ([:paperclip:](https://arxiv.org/pdf/2306.16928.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.16928)), ([:house:](https://huggingface.co/papers/2306.16928)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/one-2-3-45-any-single-image-to-3d-mesh-in-45)) |
| 6.29 | DreamDiffusion: Generating High-Quality Images from Brain EEG Signals ([:x:](https://arxiv.org/abs/2306.16934)), ([:paperclip:](https://arxiv.org/pdf/2306.16934.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.16934)), ([:house:](https://huggingface.co/papers/2306.16934)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/dreamdiffusion-generating-high-quality-images)) |
| 6.28 | On the Exploitability of Instruction Tuning ([:x:](https://arxiv.org/abs/2306.17194)), ([:paperclip:](https://arxiv.org/pdf/2306.17194.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.17194)), ([:house:](https://huggingface.co/papers/2306.17194)), ([:eight_spoked_asterisk:]()) |
| 6.28 | ChatLaw: Open-Source Legal Large Language Model with Integrated External Knowledge Bases  ([:x:](https://arxiv.org/abs/2306.16092)), ([:paperclip:](https://arxiv.org/pdf/2306.16092.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.16092)), ([:house:](https://huggingface.co/papers/2306.16092)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/chatlaw-open-source-legal-l)), ([:octocat:](https://github.com/pku-yuangroup/chatlaw)![GitHub Repo stars](https://img.shields.io/github/stars/pku-yuangroup/chatlaw?style=social)) |
| 6.28 | RSPrompter: Learning to Prompt for Remote Sensing Instance Segmentation based on Visual Foundation Model ([:x:](https://arxiv.org/abs/2306.16269)), ([:paperclip:](https://arxiv.org/pdf/2306.16269.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.16269)), ([:house:](https://huggingface.co/papers/2306.16269)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/rsprompter-learning-to-prompt-for-remote)), ([demo](https://huggingface.co/spaces/KyanChen/RSPrompter)) |
| 6.28 | Extending Context Window of Large Language Models via Positional Interpolation ([:x:](https://arxiv.org/abs/2306.15595)), ([:paperclip:](https://arxiv.org/pdf/2306.15595.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.15595)), ([:house:](https://huggingface.co/papers/2306.15595)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/extending-context-window-of-large-language)) |
| 6.28 | CLIPA-v2: Scaling CLIP Training with 81.1% Zero-shot ImageNet Accuracy within a \10,000 Budget; An Extra 4,000 Unlocks 81.8% Accuracy  ([:x:](https://arxiv.org/abs/2306.15658)), ([:paperclip:](https://arxiv.org/pdf/2306.15658.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.15658)), ([:house:](https://huggingface.co/papers/2306.15658)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/clipa-v2-scaling-clip-training-with-81-1-zero)), ([:octocat:](https://github.com/ucsc-vlaa/clipa)![GitHub Repo stars](https://img.shields.io/github/stars/ucsc-vlaa/clipa?style=social)) |
| 6.28 | Automatic Calibration and Error Correction for Large Language Models via Pareto Optimal Self-Supervision ([:x:](https://arxiv.org/abs/2306.16564)), ([:paperclip:](https://arxiv.org/pdf/2306.16564.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.16564)), ([:house:](https://huggingface.co/papers/2306.16564)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/automatic-calibration-and-error-correction) |
| 6.28 | PoseDiffusion: Solving Pose Estimation via Diffusion-aided Bundle Adjustment ([project](https://posediffusion.github.io/)), ([:paperclip:](https://posediffusion.github.io/resources/pose_diffusion.pdf)), ([:octocat:](https://github.com/facebookresearch/PoseDiffusion)![GitHub Repo stars](https://img.shields.io/github/stars/facebookresearch/PoseDiffusion?style=social)) |
| 6.28 | BrainGPT - A Large Language Model tool to assist neuroscientific research ([home](https://braingpt.org/)) |
| 6.28 | Toward Actionable Generative AI - LAMs: From Large Language Models to Large Action Models ([blog](https://blog.salesforceairesearch.com/large-action-models/)) |
| 6.28 | The official #DragGAN app and code ([tweet](https://twitter.com/OpenMMLab/status/1673884887768784896)), ([application](https://openxlab.org.cn/apps/detail/XingangPan/DragGAN)), ([:octocat:](https://github.com/XingangPan/DragGAN)![GitHub Repo stars](https://img.shields.io/github/stars/XingangPan/DragGAN?style=social)) |
| 6.27 | Vision Augmented Language Models: Computer vision through the LENS of natural language ([blog](https://contextual.ai/introducing-lens/)), ([demo](https://lens.contextual.ai/#intro)), ([:octocat:](https://github.com/ContextualAI/lens)![GitHub Repo stars](https://img.shields.io/github/stars/ContextualAI/lens?style=social)) |
| 6.27 | Restart Sampling for Improving Generative Processes  ([:x:](https://arxiv.org/abs/2306.14878)), ([:paperclip:](https://arxiv.org/pdf/2306.14878.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14878)), ([:house:](https://huggingface.co/papers/2306.14878)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/restart-sampling-for-improving-generative)), ([:octocat:](https://github.com/newbeeer/diffusion_restart_sampling)![GitHub Repo stars](https://img.shields.io/github/stars/newbeeer/diffusion_restart_sampling?style=social)) |
| 6.27 | 3D-Speaker: A Large-Scale Multi-Device, Multi-Distance, and Multi-Dialect Corpus for Speech Representation Disentanglement  ([:x:](https://arxiv.org/abs/2306.15354)), ([:paperclip:](https://arxiv.org/pdf/2306.15354.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.15354)), ([:house:](https://huggingface.co/papers/2306.15354)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/3d-speaker-a-large-scale-multi-device-multi)), ([:octocat:](https://github.com/alibaba-damo-academy/3D-Speaker)![GitHub Repo stars](https://img.shields.io/github/stars/alibaba-damo-academy/3D-Speaker?style=social)) |
| 6.27 | MIMIC: Masked Image Modeling with Image Correspondences ([:x:](https://arxiv.org/abs/2306.15128)), ([:paperclip:](https://arxiv.org/pdf/2306.15128.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.15128)), ([:house:](https://huggingface.co/papers/2306.15128)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/mimic-masked-image-modeling-with-image)), ([:octocat:](https://github.com/raivnlab/mimic)![GitHub Repo stars](https://img.shields.io/github/stars/raivnlab/mimic?style=social)) |
| 6.27 | LeanDojo: Theorem Proving with Retrieval-Augmented Language Models ([project](https://leandojo.org/)), ([:x:](https://arxiv.org/abs/2306.15626)), ([:paperclip:](https://arxiv.org/pdf/2306.15626.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.15626)), ([:house:](https://huggingface.co/papers/2306.15626)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/leandojo-theorem-proving-with-retrieval)), ([:octocat:](https://github.com/lean-dojo/leandojo)![GitHub Repo stars](https://img.shields.io/github/stars/lean-dojo/leandojo?style=social)) |
| 6.27 | Any Image to 3D ([blog](https://csm.ai/any-image-to-3d)) |
| 6.27 | ‚≠êÔ∏èLangChain Integrations‚≠êÔ∏è Hub ([link](https://integrations.langchain.com/)) |
| 6.27 | MVDiffusion: Enabling Holistic Multi-view Image Generation with Correspondence-Aware Diffusion ([project](https://mvdiffusion.github.io/)), ([demo](https://huggingface.co/spaces/tangshitao/MVDiffusion)) |
| 6.27 | Extending Context Window of Large Language Models via Positional Interpolation ([:x:](https://arxiv.org/abs/2306.15595)), ([:paperclip:](https://arxiv.org/pdf/2306.15595.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.15595)), ([:house:](https://huggingface.co/papers/2306.15595)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/extending-context-window-of-large-language)) |
| 6.27 | Salesforce open-source LLMs with 8k sequence length - Xgen 7B ([tweet](https://twitter.com/CaimingXiong/status/1674123308177178624)), ([blog](https://blog.salesforceairesearch.com/xgen/)), ([:octocat:](https://github.com/salesforce/xgen)![GitHub Repo stars](https://img.shields.io/github/stars/salesforce/xgen?style=social)) |
| 6.27 | Embracing change and resetting expectations ([blog](https://unlocked.microsoft.com/ai-anthology/terence-tao/)) | 
| 6.27 | Baby steps in evaluating the capacities of large language models (Nature Reviews Psychology, [https://doi.org/10.1038/s44159-023-00211-x](https://www.nature.com/articles/s44159-023-00211-x)), ([preview](https://www.nature.com/articles/s44159-023-00211-x.epdf?sharing_token=PYbU8twpfLCX_0iUnZ5uHdRgN0jAjWel9jnR3ZoTv0PTYDivHgU9XA-WV7YjPPGbQEAeKTPDC7dr9mwqTIpkLUsmlJssgvX6OrpHW0tUqyl6eOBgbVyX3hTm3yuWSHL8TstCrNpVavi8oMDsWvz2M2PcFa-YYEJruKabaEqbDMo%3D)) |
| 6.26 | MedLSAM: Localize and Segment Anything Model for 3D Medical Images ([:x:](https://arxiv.org/abs/2306.14752)), ([:paperclip:](https://arxiv.org/pdf/2306.14752.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14752)), ([:house:](https://huggingface.co/papers/2306.14752)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/medlsam-localize-and-segment-anything-model)), ([:octocat:](https://github.com/openmedlab/medlsam)![GitHub Repo stars](https://img.shields.io/github/stars/openmedlab/medlsam?style=social)) |
| 6.26 | MotionGPT: Human Motion as a Foreign Language ([:x:](https://arxiv.org/abs/2306.14795)), ([:paperclip:](https://arxiv.org/pdf/2306.14795.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14795)), ([:house:](https://huggingface.co/papers/2306.14795)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/motiongpt-human-motion-as-a-foreign-language)), ([:octocat:](https://github.com/openmotionlab/motiongpt)![GitHub Repo stars](https://img.shields.io/github/stars/openmotionlab/motiongpt?style=social)) |
| 6.26 | Faster Segment Anything: Towards Lightweight SAM for Mobile Applications ([:x:](https://arxiv.org/abs/2306.14289)), ([:paperclip:](https://arxiv.org/pdf/2306.14289.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14289)), ([:house:](https://huggingface.co/papers/2306.14289)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/faster-segment-anything-towards-lightweight)), ([:octocat:](https://github.com/chaoningzhang/mobilesam)![GitHub Repo stars](https://img.shields.io/github/stars/chaoningzhang/mobilesam?style=social)) |
| 6.26 | Aligning Large Multi-Modal Model with Robust Instruction Tuning ([:x:](https://arxiv.org/abs/2306.14565)), ([:paperclip:](https://arxiv.org/pdf/2306.14565.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14565)), ([:house:](https://huggingface.co/papers/2306.14565)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/aligning-large-multi-modal-model-with-robust)) |
| 6.26 | InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback ([project](https://intercode-benchmark.github.io/)), ([:x:](https://arxiv.org/abs/2306.14898)), ([:paperclip:](https://arxiv.org/pdf/2306.14898.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14898)), ([:house:](https://huggingface.co/papers/2306.14898)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/intercode-standardizing-and-benchmarking)), ([:octocat:](https://github.com/princeton-nlp/intercode)![GitHub Repo stars](https://img.shields.io/github/stars/princeton-nlp/intercode?style=social)) |
| 6.26 | LongCoder: A Long-Range Pre-trained Language Model for Code Completion ([:x:](https://arxiv.org/abs/2306.14893)), ([:paperclip:](https://arxiv.org/pdf/2306.14893.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14893)), ([:house:](https://huggingface.co/papers/2306.14893)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/longcoder-a-long-range-pre-trained-language)) |
| 6.26 | Kosmos-2: Grounding Multimodal Large Language Models to the World ([:x:](https://arxiv.org/abs/2306.14824)), ([:paperclip:](https://arxiv.org/pdf/2306.14824.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14824)), ([:house:](https://huggingface.co/papers/2306.14824)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/kosmos-2-grounding-multimodal-large-language)) |
| 6.26 | ViNT: A Foundation Model for Visual Navigation ([project](https://visualnav-transformer.github.io/)), ([:x:](https://arxiv.org/abs/2306.14846)), ([:paperclip:](https://arxiv.org/pdf/2306.14846.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14846)), ([:house:](https://huggingface.co/papers/2306.14846)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/vint-a-foundation-model-for-visual-navigation)), ([video](https://www.youtube.com/watch?v=6kNex5dJ5sQ)) |
| 6.26 | DragDiffusion: Harnessing Diffusion Models for Interactive Point-based Image Editing ([:x:](https://arxiv.org/abs/2306.14435)), ([:paperclip:](https://arxiv.org/pdf/2306.14435.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14435)), ([:house:](https://huggingface.co/papers/2306.14435)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/dragdiffusion-harnessing-diffusion-models-for)) |
| 6.25 | Generative AI ‚Äî LLMOps Architecture Patterns ([blog](https://medium.datadriveninvestor.com/generative-ai-llmops-deployment-architecture-patterns-6d45d1668aba)) |
| 6.25 | DomainStudio: Fine-Tuning Diffusion Models for Domain-Driven Image Generation using Limited Data ([:x:](https://arxiv.org/abs/2306.14153)), ([:paperclip:](https://arxiv.org/pdf/2306.14153.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14153)), ([:house:](https://huggingface.co/papers/2306.14153)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/domainstudio-fine-tuning-diffusion-models-for)) |
| 6.25 | H_2O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models ([:x:](https://arxiv.org/abs/2306.14048)), ([:paperclip:](https://arxiv.org/pdf/2306.14048.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14048)), ([:house:](https://huggingface.co/papers/2306.14048)), ([:eight_spoked_asterisk:]()) |
| 6.25 | Thinking Like an Annotator: Generation of Dataset Labeling Instructions ([:x:](https://arxiv.org/abs/2306.14035)), ([:paperclip:](https://arxiv.org/pdf/2306.14035.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14035)), ([:house:](https://huggingface.co/papers/2306.14035)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/thinking-like-an-annotator-generation-of)) |
| 6.25 | Language models are weak learners ([:x:](https://arxiv.org/abs/2306.14101)), ([:paperclip:](https://arxiv.org/pdf/2306.14101.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14101)), ([:house:](https://huggingface.co/papers/2306.14101)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/language-models-are-weak-learners)) |
| 6.25 | Let's Do a Thought Experiment: Using Counterfactuals to Improve Moral Reasoning ([:x:](https://arxiv.org/abs/2306.14308)), ([:paperclip:](https://arxiv.org/pdf/2306.14308.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14308)), ([:house:](https://huggingface.co/papers/2306.14308)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/let-s-do-a-thought-experiment-using)) |
| 6.25 | Chat with Hacker News in real-time using natural language ([demo](https://chathn.vercel.app/)) |
| 6.24 | Zero-shot spatial layout conditioning for text-to-image diffusion models ([:x:](https://arxiv.org/abs/2306.13754)), ([:paperclip:](https://arxiv.org/pdf/2306.13754.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.13754)), ([:house:](https://huggingface.co/papers/2306.13754)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/zero-shot-spatial-layout-conditioning-for)) |
| 6.24 | Beyond Scale: the Diversity Coefficient as a Data Quality Metric Demonstrates LLMs are Pre-trained on Formally Diverse Data  ([:x:](https://arxiv.org/abs/2306.13840)), ([:paperclip:](https://arxiv.org/pdf/2306.13840.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.13840)), ([:house:](https://huggingface.co/papers/2306.13840)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/beyond-scale-the-diversity-coefficient-as-a)) |
| 6.24 | On the paper ‚ÄúExploring the MIT Mathematics and EECS Curriculum Using Large Language Models‚Äù ([MIT](https://people.csail.mit.edu/asolar/CoursesPaperStatement.pdf)) |
| 6.24 | A critical analysis of ‚ÄúExploring the MIT Mathematics and EECS Curriculum Using Large Language Models‚Äù ([blog](https://flower-nutria-41d.notion.site/No-GPT4-can-t-ace-MIT-b27e6796ab5a48368127a98216c76864)) |
| 6.24 | System-Level Natural Language Feedback  ([:x:](https://arxiv.org/abs/2306.13588)), ([:paperclip:](https://arxiv.org/pdf/2306.13588.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.13588)), ([:house:](https://huggingface.co/papers/2306.13588)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/system-level-natural-language-feedback)) |
| 6.24 | OpenMask3D: Open-Vocabulary 3D Instance Segmentation ([:x:](https://arxiv.org/abs/2306.13631)), ([:paperclip:](https://arxiv.org/pdf/2306.13631.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.13631)), ([:house:](https://huggingface.co/papers/2306.13631)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/openmask3d-open-vocabulary-3d-instance)) |
| 6.24 | Scaling MLPs: A Tale of Inductive Bias ([:x:](https://arxiv.org/abs/2306.13575)), ([:paperclip:](https://arxiv.org/pdf/2306.13575.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.13575)), ([:house:](https://huggingface.co/papers/2306.13575)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/scaling-mlps-a-tale-of-inductive-bias)) |
| 6.23 | MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models ([:x:](https://arxiv.org/abs/2306.13394)), ([:paperclip:](https://arxiv.org/pdf/2306.13394.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.13394)), ([:house:](https://huggingface.co/papers/2306.13394)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/mme-a-comprehensive-evaluation-benchmark-for)), ([:octocat:](https://github.com/awesome-multimodal-large-language-models)![GitHub Repo stars](https://img.shields.io/github/stars/awesome-multimodal-large-language-models?style=social)) |
| 6.23 | What's going on with the Open LLM Leaderboard? ([blog](https://huggingface.co/blog/evaluating-mmlu-leaderboard)) |
| 6.23 | A Survey on Multimodal Large Language Models ([:x:](https://arxiv.org/abs/2306.13549)), ([:paperclip:](https://arxiv.org/pdf/2306.13549.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.13549)), ([:house:](https://huggingface.co/papers/2306.13549)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-survey-on-multimodal-large-language-models)), ([:octocat:](https://github.com/bradyfu/awesome-multimodal-large-language-models)![GitHub Repo stars](https://img.shields.io/github/stars/bradyfu/awesome-multimodal-large-language-models?style=social)) |
| 6.23 | LLM Powered Autonomous Agents ([blog](https://lilianweng.github.io/posts/2023-06-23-agent/)) |
| 6.23 | DreamEditor: Text-Driven 3D Scene Editing with Neural Fields ([:x:](https://arxiv.org/abs/2306.13455)), ([:paperclip:](https://arxiv.org/pdf/2306.13455.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.13455)), ([:house:](https://huggingface.co/papers/2306.13455)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/dreameditor-text-driven-3d-scene-editing-with)) |
| 6.23 | Long-range Language Modeling with Self-retrieval  ([:x:](https://arxiv.org/abs/2306.13421)), ([:paperclip:](https://arxiv.org/pdf/2306.13421.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.13421)), ([:house:](https://huggingface.co/papers/2306.13421)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/long-range-language-modeling-with-self)) |
| 6.23 | Bring Your Own Data! Self-Supervised Evaluation for Large Language Models ([:x:](https://arxiv.org/abs/2306.13651)), ([:paperclip:](https://arxiv.org/pdf/2306.13651.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.13651)), ([:house:](https://huggingface.co/papers/2306.13651)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/bring-your-own-data-self-supervised)), ([:octocat:](https://github.com/neelsjain/byod)![GitHub Repo stars](https://img.shields.io/github/stars/neelsjain/byod?style=social)) |
| 6.22 | reliableGPT: Stop OpenAI Errors in Production ([:octocat:](https://github.com/BerriAI/reliableGPT)![GitHub Repo stars](https://img.shields.io/github/stars/BerriAI/reliableGPT?style=social)) |
| 6.22 | Lit-GPT : Implementation of Falcon, StableLM, Pythia, INCITE language models based on nanoGPT ([:octocat:](https://github.com/Lightning-AI/lit-gpt)![GitHub Repo stars](https://img.shields.io/github/stars/Lightning-AI/lit-gpt?style=social)) |
| 6.22 | Perspective Fields for Single Image Camera Calibration ([project page](https://jinlinyi.github.io/PerspectiveFields/)), ([video](https://www.youtube.com/watch?v=sN5B_ZvMva8)), ([demo](https://huggingface.co/spaces/jinlinyi/PerspectiveFields)), ([:x:](https://arxiv.org/abs/2212.03239)), ([:paperclip:](https://arxiv.org/pdf/2212.03239.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2212.03239)), ([:house:](https://huggingface.co/papers/2212.03239)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/perspective-fields-for-single-image-camera)), ([:octocat:](https://github.com/jinlinyi/PerspectiveFields)![GitHub Repo stars](https://img.shields.io/github/stars/jinlinyi/PerspectiveFields?style=social)), (CVPR 2023) |
| 6.22 | Event Stream GPT (ESGPT), for "event stream" datasets, particularly Electronic Health Record (EHR) datasets ([tweet](https://twitter.com/MattBMcDermott/status/1671912624366166018)), ([:octocat:](https://github.com/mmcdermott/EventStreamGPT)![GitHub Repo stars](https://img.shields.io/github/stars/mmcdermott/EventStreamGPT?style=social)) |
| 6.22 | MPT-30B is here ([tweet](https://twitter.com/jefrankle/status/1671897555435913220)), ([blog](https://www.mosaicml.com/blog/mpt-30b)), ([HF](https://huggingface.co/mosaicml/mpt-30b)), ([MosaicML MPT-30B-Chat](https://huggingface.co/spaces/mosaicml/mpt-30b-chat)) |
| 6.22 | How continuous batching enables 23x throughput in LLM inference while reducing p50 latency ([blog](https://www.anyscale.com/blog/continuous-batching-llm-inference)) |
| 6.22 | DreamTime: An Improved Optimization Strategy for Text-to-3D Content Creation ([:x:](https://arxiv.org/abs/2306.12422)), ([:paperclip:](https://arxiv.org/pdf/2306.12422.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.12422)), ([:house:](https://huggingface.co/papers/2306.12422)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/dreamtime-an-improved-optimization-strategy)) |
| 6.22 | Stability AI launches SDXL 0.9: A Leap Forward in AI Image Generation ([news](https://stability.ai/blog/sdxl-09-stable-diffusion)) |
| 6.21 | ChatGPT Poses New Regulatory Questions for FDA, Medical Industry (Bloomber [news](https://news.bloomberglaw.com/health-law-and-business/chatgpt-poses-new-regulatory-questions-for-fda-medical-industry)), [Youtube](https://www.youtube.com/watch?v=ZLCfasjTWvY)) |
| 6.21 | Understanding Social Reasoning in Language Models with Language Models ([:x:](https://arxiv.org/abs/2306.15448)), ([:paperclip:](https://arxiv.org/pdf/2306.15448.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.15448)), ([:house:](https://huggingface.co/papers/2306.15448)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/understanding-social-reasoning-in-language)) |
| 6.21 | Opportunities and Risks of LLMs for Scalable Deliberation with Polis ([:x:](https://arxiv.org/abs/2306.11932)), ([:paperclip:](https://arxiv.org/pdf/2306.11932.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.11932)), ([:house:](https://huggingface.co/papers/2306.11932)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/opportunities-and-risks-of-llms-for-scalable)) |
| 6.21 | Training Transformers with 4-bit Integers ([:x:](https://arxiv.org/abs/2306.11987)), ([:paperclip:](https://arxiv.org/pdf/2306.11987.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.11987)), ([:house:](https://huggingface.co/papers/2306.11987)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/training-transformers-with-4-bit-integers)) |
| 6.21 | Fast Segment Anything ([:x:](https://arxiv.org/abs/2306.12156)), ([:paperclip:](https://arxiv.org/pdf/2306.12156.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.12156)), ([:house:](https://huggingface.co/papers/2306.12156)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/fast-segment-anything)), ([:octocat:](https://github.com/casia-iva-lab/fastsam)![GitHub Repo stars](https://img.shields.io/github/stars/casia-iva-lab/fastsam?style=social)) |
| 6.21 | DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models ([:x:](https://arxiv.org/abs/2306.11698)), ([:paperclip:](https://arxiv.org/pdf/2306.11698.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.11698)), ([:house:](https://huggingface.co/papers/2306.11698)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/decodingtrust-a-comprehensive-assessment-of)) |
| 6.20 | Visual Foundation Models for Medical Image Analysis ([blog](https://developer.nvidia.com/blog/visual-foundation-models-for-medical-image-analysis/)) |
| 6.20 | Learning to Generate Better Than Your LLM ([:x:](https://arxiv.org/abs/2306.11816)), ([:paperclip:](https://arxiv.org/pdf/2306.11816.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.11816)), ([:house:](https://huggingface.co/papers/2306.11816)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/learning-to-generate-better-than-your-llm)) |
| 6.20 | Sound reconstruction from human brain activity via a generative model with brain-like auditory features ([:x:](https://arxiv.org/abs/2306.11629)), ([:paperclip:](https://arxiv.org/pdf/2306.11629.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.11629)), ([:house:](https://huggingface.co/papers/2306.11629)), ([:eight_spoked_asterisk:](https://cs.paperswithcode.com/paper/sound-reconstruction-from-human-brain)), ([:octocat:](https://github.com/KamitaniLab/DeepImageReconstruction)![GitHub Repo stars](https://img.shields.io/github/stars/KamitaniLab/DeepImageReconstruction?style=social)) |
| 6.20 | A Simple and Effective Pruning Approach for Large Language Models ([:x:](https://arxiv.org/abs/2306.11695)), ([:paperclip:](https://arxiv.org/pdf/2306.11695.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.11695)), ([:house:](https://huggingface.co/papers/2306.11695)), ([:eight_spoked_asterisk:]([https://paperswithcode.com/paper/fast-segment-anything](https://paperswithcode.com/paper/a-simple-and-effective-pruning-approach-for)), ([:octocat:](https://github.com/locuslab/wanda)![GitHub Repo stars](https://img.shields.io/github/stars/locuslab/wanda?style=social)) |
| 6.20 | Radiology Report Expert Evaluation (ReXVal) Dataset (PhysioNet [https://doi.org/10.13026/2fp8-qr71](https://physionet.org/content/rexval-dataset/1.0.0/)) |
| 6.20 | RoboCat: A Self-Improving Foundation Agent for Robotic Manipulation ([:x:](https://arxiv.org/abs/2306.11706)), ([:paperclip:](https://arxiv.org/pdf/2306.11706.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.11706)), ([:house:](https://huggingface.co/papers/2306.11706)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/robocat-a-self-improving-foundation-agent-for)), ([:octocat:](https://github.com/kyegomez/RoboCAT)![GitHub Repo stars](https://img.shields.io/github/stars/kyegomez/RoboCAT?style=social)) |
| 6.20 | Segment Anything Model (SAM) for Radiation Oncology ([:x:](https://arxiv.org/abs/2306.11730)), ([:paperclip:](https://arxiv.org/pdf/2306.11730.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.11730)), ([:house:](https://huggingface.co/papers/2306.11730)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/segment-anything-model-sam-for-radiation)) |
| 6.20 | RepoFusion: Training Code Models to Understand Your Repository  ([:x:](https://arxiv.org/abs/2306.10998)), ([:paperclip:](https://arxiv.org/pdf/2306.10998.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.10998)), ([:house:](https://huggingface.co/papers/2306.10998)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/repofusion-training-code-models-to-understand)) |
| 6.20 | Textbooks Are All You Need ([:x:](https://arxiv.org/abs/2306.11644)), ([:paperclip:](https://arxiv.org/pdf/2306.11644.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.11644)), ([:house:](https://huggingface.co/papers/2306.11644)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/textbooks-are-all-you-need)) |
| 6.19 | Path to Medical AGI: Unify Domain-specific Medical LLMs with the Lowest Cost ([:x:](https://arxiv.org/abs/2306.10765)), ([:paperclip:](https://arxiv.org/pdf/2306.10765.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.10765)), ([:house:](https://huggingface.co/papers/2306.10765)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/path-to-medical-agi-unify-domain-specific)), ([:octocat:](https://github.com/joshuachou2018/medagi)![GitHub Repo stars](https://img.shields.io/github/stars/joshuachou2018/medagi?style=social)) |
| 6.19 | CounselGPT - Korean psychological counseling dataset ([:octocat:](https://github.com/MrBananaHuman/CounselGPT)![GitHub Repo stars](https://img.shields.io/github/stars/MrBananaHuman/CounselGPT?style=social)) |
| 6.19 | MotionGPT: Finetuned LLMs are General-Purpose Motion Generators ([:x:](https://arxiv.org/abs/2306.10900)), ([:paperclip:](https://arxiv.org/pdf/2306.10900.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.10900)), ([:house:](https://huggingface.co/papers/2306.10900)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/motiongpt-finetuned-llms-are-general-purpose)) |
| 6.18 | Point-Cloud Completion with Pretrained Text-to-image Diffusion Models ([:x:](https://arxiv.org/abs/2306.10533)), ([:paperclip:](https://arxiv.org/pdf/2306.10533.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.10533)), ([:house:](https://huggingface.co/papers/2306.10533)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/point-cloud-completion-with-pretrained-text)) |
| 6.18 | Mercedes-Benz Installs ChatGPT Artificial Intelligence in 900,000 Cars ([Newsweek](https://www.newsweek.com/mercedes-benz-installs-chatgpt-artificial-intelligence-900000-cars-1807384)), ([Mercedes Benz](https://media.mercedes-benz.com/article/323212b5-1b56-458a-9324-20b25cc176cb)) |
| 6.18 | OpenLLaMA-13B released ([tweet](https://twitter.com/hardmaru/status/1670628627057197059)), ([:octocat:](https://github.com/openlm-research/open_llama)![GitHub Repo stars](https://img.shields.io/github/stars/openlm-research/open_llama?style=social)) |
| 6.17 | Beware of Unreliable Data in Model Evaluation: A LLM Prompt Selection case study with Flan-T5 ([blog](https://towardsdatascience.com/beware-of-unreliable-data-in-model-evaluation-a-llm-prompt-selection-case-study-with-flan-t5-88cfd469d058)) | 
| 6.17 | GPT Engineer - specify what you want it to build, the AI asks for clarification, and then builds it ([:octocat:](https://github.com/AntonOsika/gpt-engineer)![GitHub Repo stars](https://img.shields.io/github/stars/AntonOsika/gpt-engineer?style=social)) |
| 6.17 | Demystifying GPT Self-Repair for Code Generation ([:x:](https://arxiv.org/abs/2306.09896)), ([:paperclip:](https://arxiv.org/pdf/2306.09896.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09896)), ([:house:](https://huggingface.co/papers/2306.09896)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/demystifying-gpt-self-repair-for-code)) |
| 6.17 | Introducing GAIA-1: A Cutting-Edge Generative AI Model for Autonomy ([blog](https://wayve.ai/thinking/introducing-gaia1/)) |
| 6.17 | Understanding Encoder And Decoder LLMs ([blog](https://magazine.sebastianraschka.com/p/understanding-encoder-and-decoder)) | 
| 6.16 | Evaluating Superhuman Models with Consistency Checks ([:x:](https://arxiv.org/abs/2306.09983)), ([:paperclip:](https://arxiv.org/pdf/2306.09983.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09983)), ([:house:](https://huggingface.co/papers/2306.09983)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/evaluating-superhuman-models-with-consistency)) |
| 6.16 | AvatarBooth: High-Quality and Customizable 3D Human Avatar Generation ([project](https://zeng-yifei.github.io/avatarbooth_page/)), ([:x:](https://arxiv.org/abs/2306.09864)), ([:paperclip:](https://arxiv.org/pdf/2306.09864.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09864)), ([:house:](https://huggingface.co/papers/2306.09864)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/avatarbooth-high-quality-and-customizable-3d)) |
| 6.16 | Gradient is All You Need? ([:x:](https://arxiv.org/abs/2306.09778)), ([:paperclip:](https://arxiv.org/pdf/2306.09778.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09778)), ([:house:](https://huggingface.co/papers/2306.09778)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/gradients-are-not-all-you-need)), ([:octocat:](https://github.com/google/learned_optimization)![GitHub Repo stars](https://img.shields.io/github/stars/google/learned_optimization?style=social)) |
| 6.16 | LabelBench: A Comprehensive Framework for Benchmarking Label-Efficient Learning ([:x:](https://arxiv.org/abs/2306.09910)), ([:paperclip:](https://arxiv.org/pdf/2306.09910.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09910)), ([:house:](https://huggingface.co/papers/2306.09910)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/labelbench-a-comprehensive-framework-for)), ([:octocat:](https://github.com/efficienttraining/labelbench)![GitHub Repo stars](https://img.shields.io/github/stars/efficienttraining/labelbench?style=social)) |
| 6.16 | AD-AutoGPT: An Autonomous GPT for Alzheimer's Disease Infodemiology ([:x:](https://arxiv.org/abs/2306.10095)), ([:paperclip:](https://arxiv.org/pdf/2306.10095.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.10095)), ([:house:](https://huggingface.co/papers/2306.10095)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/ad-autogpt-an-autonomous-gpt-for-alzheimer-s)) |
| 6.16 | Meta - Introducing Voicebox: The Most Versatile AI for Speech Generation ([news](https://about.fb.com/news/2023/06/introducing-voicebox-ai-for-speech-generation/)) |
| 6.16 | Explore, Establish, Exploit: Red Teaming Language Models from Scratch  ([:x:](https://arxiv.org/abs/2306.09442)), ([:paperclip:](https://arxiv.org/pdf/2306.09442.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09442)), ([:house:](https://huggingface.co/papers/2306.09442)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/explore-establish-exploit-red-teaming)) |
| 6.16 | Full Parameter Fine-tuning for Large Language Models with Limited Resources  ([:x:](https://arxiv.org/abs/2306.09782)), ([:paperclip:](https://arxiv.org/pdf/2306.09782.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09782)), ([:house:](https://huggingface.co/papers/2306.09782)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/full-parameter-fine-tuning-for-large-language)), ([:octocat:](https://github.com/openlmlab/lomo)![GitHub Repo stars](https://img.shields.io/github/stars/openlmlab/lomo?style=social)) |
| 6.16 | ClinicalGPT: Large Language Models Finetuned with Diverse Medical Data and Comprehensive Evaluation ([:x:](https://arxiv.org/abs/2306.09968)), ([:paperclip:](https://arxiv.org/pdf/2306.09968.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09968)), ([:house:](https://huggingface.co/papers/2306.09968)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/clinicalgpt-large-language-models-finetuned)) |
| 6.16 | CLIPSonic: Text-to-Audio Synthesis with Unlabeled Videos and Pretrained Language-Vision Models ([:x:](https://arxiv.org/abs/2306.09635)), ([:paperclip:](https://arxiv.org/pdf/2306.09635.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09635)), ([:house:](https://huggingface.co/papers/2306.09635)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/clipsonic-text-to-audio-synthesis-with)) |
| 6.16 | Language-Guided Music Recommendation for Video via Prompt Analogies ([:x:](https://arxiv.org/abs/2306.09327)), ([:paperclip:](https://arxiv.org/pdf/2306.09327.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09327)), ([:house:](https://huggingface.co/papers/2306.09327)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/language-guided-music-recommendation-for-1)) |
| 6.16 | QR Code AI Art Generator ([tweet](https://twitter.com/radamar/status/1669549592470499328)), ([Hugging face](https://huggingface.co/spaces/huggingface-projects/QR-code-AI-art-generator)), ([SD art](https://stable-diffusion-art.com/qr-code/)) |
| 6.16 | Standford CRFM - Transparency Index for Foundation Model Provider's Compliance measurement with the Draft EU AI Act ([tweet](https://twitter.com/RishiBommasani/status/1669463873869709313)), ([:octocat:](https://github.com/stanford-crfm/TransparencyIndex)![GitHub Repo stars](https://img.shields.io/github/stars/stanford-crfm/TransparencyIndex?style=social)) |
| 6.16 | The economic potential of generative AI: The next productivity frontier (McKinsey & Company. [report](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier)) |
| 6.15 | Opportunities and Challenges for ChatGPT and Large Language Models in Biomedicine and Health ([:x:](https://arxiv.org/abs/2306.10070)), ([:paperclip:](https://arxiv.org/pdf/2306.10070.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.10070)), ([:house:](https://huggingface.co/papers/2306.10070)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/opportunities-and-challenges-for-chatgpt-and)), ([SS](https://www.semanticscholar.org/paper/Opportunities-and-Challenges-for-ChatGPT-and-Large-Tian-Jin/8772847b9b87a7babd3aa0b5fe5bf55f8c9e028b)) |
| 6.15 | Introducing the ElevenLabs AI Speech Classifier: Elevating Safety Standards for AI-generated Audio Content ([news](https://beta.elevenlabs.io/blog/ai-speech-classifier/)) |
| 6.15 | ChatGPT AI Shines in Challenging Medical Cases ([news](https://neurosciencenews.com/chatgpt-medical-ai-23480/)) |
| 6.15 | Accuracy of a Generative Artificial Intelligence Model in a Complex Diagnostic Challenge (JAMA [doi:10.1001/jama.2023.8288](https://jamanetwork.com/journals/jama/fullarticle/2806457)) |
| 6.15 | LOVM: Language-Only Vision Model Selection ([:x:](https://arxiv.org/abs/2306.08893)), ([:paperclip:](https://arxiv.org/pdf/2306.08893.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08893)), ([:house:](https://huggingface.co/papers/2306.08893)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/lovm-language-only-vision-model-selection)) |
| 6.15 | WizardCoder: Empowering Code Large Language Models with Evol-Instruct ([:x:](https://arxiv.org/abs/2306.08568)), ([:paperclip:](https://arxiv.org/pdf/2306.08568.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08568)), ([:house:](https://huggingface.co/papers/2306.08568)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/wizardcoder-empowering-code-large-language)), ([:octocat:](https://github.com/nlpxucan/wizardlm)![GitHub Repo stars](https://img.shields.io/github/stars/nlpxucan/wizardlm?style=social)) |
| 6.15 | Segment Any Point Cloud Sequences by Distilling Vision Foundation Models ([:x:](https://arxiv.org/abs/2306.09347)), ([:paperclip:](https://arxiv.org/pdf/2306.09347.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09347)), ([:house:](https://huggingface.co/papers/2306.09347)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/segment-any-point-cloud-sequences-by)), ([:octocat:](https://github.com/youquanl/segment-any-point-cloud)![GitHub Repo stars](https://img.shields.io/github/stars/youquanl/segment-any-point-cloud?style=social)) |
| 6.15 | Seeing the World through Your Eyes ([:x:](https://arxiv.org/abs/2306.09348)), ([:paperclip:](https://arxiv.org/pdf/2306.09348.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09348)), ([:house:](https://huggingface.co/papers/2306.09348)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/seeing-the-world-through-your-eyes)) |
| 6.15 | Exploring the MIT Mathematics and EECS Curriculum Using Large Language Models ([:x:](https://arxiv.org/abs/2306.08997)), ([:paperclip:](https://arxiv.org/pdf/2306.08997.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08997)), ([:house:](https://huggingface.co/papers/2306.08997)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/exploring-the-mit-mathematics-and-eecs)) |
| 6.15 | Can Language Models Teach Weaker Agents? Teacher Explanations Improve Students via Theory of Mind ([:x:](https://arxiv.org/abs/2306.09299)), ([:paperclip:](https://arxiv.org/pdf/2306.09299.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09299)), ([:house:](https://huggingface.co/papers/2306.09299)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/can-language-models-teach-weaker-agents)), ([:octocat:](https://github.com/swarnahub/explanationintervention)![GitHub Repo stars](https://img.shields.io/github/stars/swarnahub/explanationintervention?style=social)) |
| 6.15 | Segment Any Point Cloud Sequences by Distilling Vision Foundation Models ([:x:](https://arxiv.org/abs/2306.09347)), ([:paperclip:](https://arxiv.org/pdf/2306.09347.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09347)), ([:house:](https://huggingface.co/papers/2306.09347)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/segment-any-point-cloud-sequences-by)), ([:octocat:](https://github.com/youquanl/segment-any-point-cloud)![GitHub Repo stars](https://img.shields.io/github/stars/youquanl/segment-any-point-cloud?style=social)) |
| 6.15 | ChessGPT: Bridging Policy Learning and Language Modeling ([:x:](https://arxiv.org/abs/2306.09200)), ([:paperclip:](https://arxiv.org/pdf/2306.09200.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09200)), ([:house:](https://huggingface.co/papers/2306.09200)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/chessgpt-bridging-policy-learning-and)), ([:octocat:](https://github.com/waterhorse1/chessgpt)![GitHub Repo stars](https://img.shields.io/github/stars/waterhorse1/chessgpt?style=social)) |
| 6.15 | Top Use Cases and Cutting-Edge Solutions with Generative AI in Healthcare ([blog](https://emorphis.health/blogs/generative-ai-in-healthcare-top-use-cases-and-solutions/)) | 
| 6.15 | [SCIENCE] Art and the science of generative AI, Vol 380, Issue 6650, ([DOI: 10.1126/science.adh4451](https://www.science.org/doi/full/10.1126/science.adh4451)) |
| 6.14 | Radiology-GPT: A Large Language Model for Radiology ([demo](https://huggingface.co/spaces/allen-eric/radiology-gpt)), ([:x:](https://arxiv.org/abs/2306.08666)), ([:paperclip:](https://arxiv.org/pdf/2306.08666.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08666)), ([:house:](https://huggingface.co/papers/2306.08666)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/radiology-gpt-a-large-language-model-for)) |
| 6.14 | Unifying Large Language Models and Knowledge Graphs: A Roadmap ([:x:](https://arxiv.org/abs/2306.08302)), ([:paperclip:](https://arxiv.org/pdf/2306.08302.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08302)), ([:house:](https://huggingface.co/papers/2306.08302)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/unifying-large-language-models-and-knowledge)) |
| 6.14 | Knowledge Distillation of Large Language Models ([:x:](https://arxiv.org/abs/2306.08543)), ([:paperclip:](https://arxiv.org/pdf/2306.08543.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08543)), ([:house:](https://huggingface.co/papers/2306.08543)), ([:eight_spoked_asterisk:]()) |
| 6.14 | TAPIR: Tracking Any Point with per-frame Initialization and temporal Refinement ([:x:](https://arxiv.org/abs/2306.08637)), ([:paperclip:](https://arxiv.org/pdf/2306.08637.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08637)), ([:house:](https://huggingface.co/papers/2306.08637)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/tapir-tracking-any-point-with-per-frame)) |
| 6.14 | EU MEPs ready to negotiate first-ever rules for safe and transparent AI ([news](https://www.europarl.europa.eu/news/en/press-room/20230609IPR96212/meps-ready-to-negotiate-first-ever-rules-for-safe-and-transparent-ai)) |
| 6.14 | TryOnDiffusion: A Tale of Two UNets ([:x:](https://arxiv.org/abs/2306.08276)), ([:paperclip:](https://arxiv.org/pdf/2306.08276.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08276)), ([:house:](https://huggingface.co/papers/2306.08276)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/tryondiffusion-a-tale-of-two-unets)) |
| 6.14 | AssistGPT: A General Multi-modal Assistant that can Plan, Execute, Inspect, and Learn ([:x:](https://arxiv.org/abs/2306.08640)), ([:paperclip:](https://arxiv.org/pdf/2306.08640.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08640)), ([:house:](https://huggingface.co/papers/2306.08640)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/assistgpt-a-general-multi-modal-assistant)) |
| 6.14 | Stable Diffusion with Core ML on Apple Silicon  ([tweet](https://twitter.com/atiorh/status/1669009755191537664)), ([:octocat:](https://github.com/apple/ml-stable-diffusion)![GitHub Repo stars](https://img.shields.io/github/stars/apple/ml-stable-diffusion?style=social)) |
| 6.13 | How AI Responds to Common Lung Cancer Questions: ChatGPT vs Google Bard (RSNA Radiology, [https://doi.org/10.1148/radiol.230922](https://pubs.rsna.org/doi/full/10.1148/radiol.230922)) |
| 6.13 | Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use Large Language Models for Text Production Tasks ([:x:](https://arxiv.org/abs/2306.07899)), ([:paperclip:](https://arxiv.org/pdf/2306.07899.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07899)), ([:house:](https://huggingface.co/papers/2306.07899)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/artificial-artificial-artificial-intelligence)), ([:octocat:](https://github.com/epfl-dlab/gpturk)![GitHub Repo stars](https://img.shields.io/github/stars/epfl-dlab/gpturk?style=social)) |
| 6.13 | Scalable 3D Captioning with Pretrained Models ([:x:](https://arxiv.org/abs/2306.07279)), ([:paperclip:](https://arxiv.org/pdf/2306.07279.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07279)), ([:house:](https://huggingface.co/papers/2306.07279)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/scalable-3d-captioning-with-pretrained-models)) |
| 6.13 | Rerender A Video: Zero-Shot Text-Guided Video-to-Video Translation ([:x:](https://arxiv.org/abs/2306.07954)), ([:paperclip:](https://arxiv.org/pdf/2306.07954.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07954)), ([:house:](https://huggingface.co/papers/2306.07954)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/rerender-a-video-zero-shot-text-guided-video)) |
| 6.13 | arXiVeri: Automatic table verification with GPT ([:x:](https://arxiv.org/abs/2306.07968)), ([:paperclip:](https://arxiv.org/pdf/2306.07968.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07968)), ([:house:](https://huggingface.co/papers/2306.07968)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/arxiveri-automatic-table-verification-with)) |
| 6.13 | AVIS: Autonomous Visual Information Seeking with Large Language Models ([:x:](https://arxiv.org/abs/2306.08129)), ([:paperclip:](https://arxiv.org/pdf/2306.08129.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08129)), ([:house:](https://huggingface.co/papers/2306.08129)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/avis-autonomous-visual-information-seeking)) |
| 6.13 | AniFaceDrawing: Anime Portrait Exploration during Your Sketching ([:x:](https://arxiv.org/abs/2306.07476)), ([:paperclip:](https://arxiv.org/pdf/2306.07476.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07476)), ([:house:](https://huggingface.co/papers/2306.07476)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/anifacedrawing-anime-portrait-exploration)) |
| 6.13 | h2oGPT: Democratizing Large Language Models ([:x:](https://arxiv.org/abs/2306.08161)), ([:paperclip:](https://arxiv.org/pdf/2306.08161.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08161)), ([:house:](https://huggingface.co/papers/2306.08161)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/h2ogpt-democratizing-large-language-models)), [:octocat:](https://github.com/h2oai/h2ogpt)![GitHub Repo stars](https://img.shields.io/github/stars/h2oai/h2ogpt?style=social)) |
| 6.13 | 3D molecule generation by denoising voxel grids [:x:](https://arxiv.org/abs/2306.07473)), ([:paperclip:](https://arxiv.org/pdf/2306.07473.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07473)), ([:house:](https://huggingface.co/papers/2306.07473)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/3d-molecule-generation-by-denoising-voxel)) |
| 6.13 | GeneCIS: A Benchmark for General Conditional Image Similarity ([project page](https://sgvaze.github.io/genecis/)), ([:x:](https://arxiv.org/abs/2306.07969)), ([:paperclip:](https://arxiv.org/pdf/2306.07969.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07969)), ([:house:](https://huggingface.co/papers/2306.07969)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/genecis-a-benchmark-for-general-conditional-1)), ([:octocat:](https://github.com/facebookresearch/genecis)![GitHub Repo stars](https://img.shields.io/github/stars/facebookresearch/genecis?style=social)), (CVPR 2023) |
| 6.13 | Macaw-LLM: Multi-Modal Language Modeling with Image, Audio, Video, and Text Integration  ([:octocat:](https://github.com/lyuchenyang/Macaw-LLM)![GitHub Repo stars](https://img.shields.io/github/stars/lyuchenyang/Macaw-LLM?style=social)) |
| 6.13 | One-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning ([:x:](https://arxiv.org/abs/2306.07967)), ([:paperclip:](https://arxiv.org/pdf/2306.07967.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07967)), ([:house:](https://huggingface.co/papers/2306.07967)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/one-for-all-generalized-lora-for-parameter)), ([:octocat:](https://github.com/arnav0400/vit-slim)![GitHub Repo stars](https://img.shields.io/github/stars/arnav0400/vit-slim?style=social)) |
| 6.13 | GitHub survey result - 92% of U.S.-based developers are already using AI coding tools both in and outside of work ([blog](https://github.blog/2023-06-13-survey-reveals-ais-impact-on-the-developer-experience/)) |
| 6.13 | ChatGPT Workspaces - Upcoming ChatGPT features: file uploading, profiles, organizations and workspaces ([reddit](https://www.reddit.com/r/ChatGPT/comments/144cfzg/upcoming_chatgpt_features_file_uploading_profiles/?utm_source=share&utm_medium=web2x&context=3)) |
| 6.12 | Data-Copilot: Bridging Billions of Data and Humans with Autonomous Workflow ([:x:](https://arxiv.org/abs/2306.07209)), ([:paperclip:](https://arxiv.org/pdf/2306.07209.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07209)), ([:house:](https://huggingface.co/papers/2306.07209)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/data-copilot-bridging-billions-of-data-and)), ([:octocat:](https://github.com/zwq2018/data-copilot)![GitHub Repo stars](https://img.shields.io/github/stars/zwq2018/data-copilot?style=social)) |
| 6.12 | Transformers learn through gradual rank increase ([:x:](https://arxiv.org/abs/2306.07042)), ([:paperclip:](https://arxiv.org/pdf/2306.07042.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07042)), ([:house:](https://huggingface.co/papers/2306.07042)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/transformers-learn-through-gradual-rank)) |
| 6.12 | Large Language Models as Tax Attorneys: A Case Study in Legal Capabilities Emergence ([:x:](https://arxiv.org/abs/2306.07075)), ([:paperclip:](https://arxiv.org/pdf/2306.07075.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07075)), ([:house:](https://huggingface.co/papers/2306.07075)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/large-language-models-as-tax-attorneys-a-case)) |
| 6.12 | Augmenting Language Models with Long-Term Memory ([:x:](https://arxiv.org/abs/2306.07174)), ([:paperclip:](https://arxiv.org/pdf/2306.07174.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07174)), ([:house:](https://huggingface.co/papers/2306.07174)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/augmenting-language-models-with-long-term)), ([:octocat:](https://github.com/Victorwz/LongMem)![GitHub Repo stars](https://img.shields.io/github/stars/Victorwz/LongMem?style=social)) |
| 6.12 | Yann LeCun and Geoffrrey Hinton's Consensus on a number of questions about AI and catastrophic risks ([tweet](https://twitter.com/ylecun/status/1667947166764023808)) |
| 6.12 | Conversation of Andrew Ng and Geoffrey Hinton about AI and catastrophic risks ([tweet](https://twitter.com/AndrewYNg/status/1667920020587020290)) |
| 6.12 | Benchmarking Neural Network Training Algorithms ([:x:](https://arxiv.org/abs/2306.07179)), ([:paperclip:](https://arxiv.org/pdf/2306.07179.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07179)), ([:house:](https://huggingface.co/papers/2306.07179)), ([:eight_spoked_asterisk:]()) |
| 6.12 | Lit-llama - Implementation of the LLaMA language model based on nanoGPT ([:octocat:](https://github.com/Lightning-AI/lit-llama)![GitHub Repo stars](https://img.shields.io/github/stars/Lightning-AI/lit-llama?style=social)) |
| 6.12 | OpenAI, DeepMind will open up models to UK government ([news](https://www.politico.eu/article/openai-deepmind-will-open-up-models-to-uk-government/)) |
| 6.12 | WizardLM: An Instruction-following LLM Using Evol-Instruct ([:octocat:](https://github.com/nlpxucan/WizardLM)![GitHub Repo stars](https://img.shields.io/github/stars/nlpxucan/WizardLM?style=social)) |
| 6.11 | Face0: Instantaneously Conditioning a Text-to-Image Model on a Face ([:x:](https://arxiv.org/abs/2306.06638)), ([:paperclip:](https://arxiv.org/pdf/2306.06638.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.06638)), ([:house:](https://huggingface.co/papers/2306.06638)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/face0-instantaneously-conditioning-a-text-to)) |
| 6.11 | A Comprehensive Survey on Applications of Transformers for Deep Learning Tasks ([:x:](https://arxiv.org/abs/2306.07303)), ([:paperclip:](https://arxiv.org/pdf/2306.07303.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07303)), ([:house:](https://huggingface.co/papers/2306.07303)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-comprehensive-survey-on-applications-of)) |
| 6.10 | Large Language Model Evaluation in 2023: 5 Methods ([blog](https://research.aimultiple.com/large-language-model-evaluation/)) | 
| 6.9 | On the Challenges and Perspectives of Foundation Models for Medical Image Analysis ([:x:](https://arxiv.org/abs/2306.05705)), ([:paperclip:](https://arxiv.org/pdf/2306.05705.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.05705)), ([:house:](https://huggingface.co/papers/2306.05705)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/on-the-challenges-and-perspectives-of)), ([üéì](https://www.semanticscholar.org/paper/On-the-Challenges-and-Perspectives-of-Foundation-Zhang-Metaxas/fed150a219f9c31bdb4920e615c7c9264c634736)) |
| 6.9 | Chat Generative Pretrained Transformer Fails the Multiple-Choice American College of Gastroenterology Self-Assessment Test (The American Journal of Gastroenterology, [DOI: 10.14309/ajg.0000000000002320](https://journals.lww.com/ajg/Abstract/9900/Chat_Generative_Pretrained_Transformer_Fails_the.751.aspx)) |
| 6.9 | Aladdin: Zero-Shot Hallucination of Stylized 3D Assets from Abstract Scene Descriptions ([:x:](https://arxiv.org/abs/2306.06212)), ([:paperclip:](https://arxiv.org/pdf/2306.06212.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.06212)), ([:house:](https://huggingface.co/papers/2306.06212)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/aladdin-zero-shot-hallucination-of-stylized)), ([:octocat:](https://github.com/ianhuang0630/aladdin)![GitHub Repo stars](https://img.shields.io/github/stars/ianhuang0630/aladdin?style=social)) |
| 6.9 | Judging LLM-as-a-judge with MT-Bench and Chatbot Arena ([:x:](https://arxiv.org/abs/2306.05685)), ([:paperclip:](https://arxiv.org/pdf/2306.05685.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.05685)), ([:house:](https://huggingface.co/papers/2306.05685)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/judging-llm-as-a-judge-with-mt-bench-and)), ([:octocat:](https://github.com/lm-sys/fastchat)![GitHub Repo stars](https://img.shields.io/github/stars/lm-sys/fastchat?style=social)) |
| 6.9 | Evaluating the Social Impact of Generative AI Systems in Systems and Society ([:x:](https://arxiv.org/abs/2306.05949)), ([:paperclip:](https://arxiv.org/pdf/2306.05949.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.05949)), ([:house:](https://huggingface.co/papers/2306.05949)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/evaluating-the-social-impact-of-generative-ai)) |
| 6.9 | Can Large Language Models Infer Causation from Correlation? ([:x:](https://arxiv.org/abs/2306.05836)), ([:paperclip:](https://arxiv.org/pdf/2306.05836.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.05836)), ([:house:](https://huggingface.co/papers/2306.05836)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/can-large-language-models-infer-causation)), ([:octocat:](https://github.com/causalNLP/corr2cause)![GitHub Repo stars](https://img.shields.io/github/stars/causalNLP/corr2cause?style=social)) |
| 6.9 | FinGPT: Open-Source Financial Large Language Models ([:x:](https://arxiv.org/abs/2306.06031)), ([:paperclip:](https://arxiv.org/pdf/2306.06031.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.06031)), ([:house:](https://huggingface.co/papers/2306.06031)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/fingpt-open-source-financial-large-language)), ([:octocat:](https://github.com/AI4Finance-Foundation/FinGPT)![GitHub Repo stars](https://img.shields.io/github/stars/AI4Finance-Foundation/FinGPT?style=social)) |
| 6.8 | Regulators Face Novel Challenges as Artificial Intelligence Tools Enter Medical Practice (JAMA Health Forum [doi: 10.1001/jamahealthforum.2023.2300](https://jamanetwork.com/journals/jama-health-forum/fullarticle/2806091)) |
| 6.8 | Artificial General Intelligence for Medical Imaging ([:x:](https://arxiv.org/abs/2306.05480)), ([:paperclip:](https://arxiv.org/pdf/2306.05480.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.05480)), ([:house:](https://huggingface.co/papers/2306.05480)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/artificial-general-intelligence-for-medical)) |
| 6.8 | On the Reliability of Watermarks for Large Language Models ([:x:](https://arxiv.org/abs/2306.04634)), ([:paperclip:](https://arxiv.org/pdf/2306.04634.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.04634)), ([:house:](https://huggingface.co/papers/2306.04634)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/on-the-reliability-of-watermarks-for-large)), ([:octocat:](https://github.com/jwkirchenbauer/lm-watermarking)![GitHub Repo stars](https://img.shields.io/github/stars/jwkirchenbauer/lm-watermarking?style=social)) |
| 6.8 | PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization ([:x:](https://arxiv.org/abs/2306.05087)), ([:paperclip:](https://arxiv.org/pdf/2306.05087.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.05087)), ([:house:](https://huggingface.co/papers/2306.05087)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/pandalm-an-automatic-evaluation-benchmark-for)), ([:octocat:](https://github.com/weopenml/pandalm)![GitHub Repo stars](https://img.shields.io/github/stars/weopenml/pandalm?style=social)) |
| 6.8 | How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources ([:x:](https://arxiv.org/abs/2306.04751)), ([:paperclip:](https://arxiv.org/pdf/2306.04751.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.04751)), ([:house:](https://huggingface.co/papers/2306.04751)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/how-far-can-camels-go-exploring-the-state-of)) |
| 6.8 | StableDiffusion - Clipdrop Launches Uncrop: The Ultimate Aspect Ratio Editor ([blog](https://stability.ai/blog/clipdrop-launches-uncrop-the-ultimate-aspect-ratio-editor)) |
| 6.8 | Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and Language Models ([:x:](https://arxiv.org/abs/2306.05424)), ([:paperclip:](https://arxiv.org/pdf/2306.05424.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.05424)), ([:house:](https://huggingface.co/papers/2306.05424)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/video-chatgpt-towards-detailed-video)), ([:octocat:](https://github.com/mbzuai-oryx/video-chatgpt)![GitHub Repo stars](https://img.shields.io/github/stars/mbzuai-oryx/video-chatgpt?style=social)) |
| 6.8 | Simple and Controllable Music Generation ([:x:](https://arxiv.org/abs/2306.05284)), ([:paperclip:](https://arxiv.org/pdf/2306.05284.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.05284)), ([:house:](https://huggingface.co/papers/2306.05284)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/simple-and-controllable-music-generation)), ([:octocat:](https://github.com/facebookresearch/audiocraft)![GitHub Repo stars](https://img.shields.io/github/stars/facebookresearch/audiocraft?style=social)) |
| 6.8 | Tracking Everything Everywhere All at Once ([project page](https://omnimotion.github.io/)), ([:x:](https://arxiv.org/abs/2306.05422)), ([:paperclip:](https://arxiv.org/pdf/2306.05422.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.05422)), ([:house:](https://huggingface.co/papers/2306.05422)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/tracking-everything-everywhere-all-at-once)), ([:octocat:](https://github.com/qianqianwang68/omnimotion)![GitHub Repo stars](https://img.shields.io/github/stars/qianqianwang68/omnimotion?style=social) |
| 6.8 | Understanding GPT tokenizers ([blog](https://simonwillison.net/2023/Jun/8/gpt-tokenizers/)) |
| 6.7 | Health system-scale language models are all-purpose prediction engines (Nature [https://doi.org/10.1038/s41586-023-06160-y](https://www.nature.com/articles/s41586-023-06160-y#citeas)), ([:paperclip:](https://www.nature.com/articles/s41586-023-06160-y.pdf?pdf=button%20sticky)), ([:octocat:](https://github.com/nyuolab/NYUTron)![GitHub Repo stars](https://img.shields.io/github/stars/nyuolab/NYUTron?style=social) |
| 6.7 | Learning to Ground Instructional Articles in Videos through Narrations ([:x:](https://arxiv.org/abs/2306.03802)), ([:paperclip:](https://arxiv.org/pdf/2306.03802.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03802)), ([:house:](https://huggingface.co/papers/2306.03802)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/learning-to-ground-instructional-articles-in)) |
| 6.7 | Emergent Correspondence from Image Diffusion ([:x:](https://arxiv.org/abs/2306.03881)), ([:paperclip:](https://arxiv.org/pdf/2306.03881.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03881)), ([:house:](https://huggingface.co/papers/2306.03881)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/emergent-correspondence-from-image-diffusion)) |
| 6.7 | Certified Reasoning with Language Models ([:x:](https://arxiv.org/abs/2306.04031)), ([:paperclip:](https://arxiv.org/pdf/2306.04031.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.04031)), ([:house:](https://huggingface.co/papers/2306.04031)), ([:eight_spoked_asterisk:]()) |
| 6.7 | Increasing Diversity While Maintaining Accuracy: Text Data Generation with Large Language Models and Human Interventions  ([:x:](https://arxiv.org/abs/2306.04140)), ([:paperclip:](https://arxiv.org/pdf/2306.04140.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.04140)), ([:house:](https://huggingface.co/papers/2306.04140)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/increasing-diversity-while-maintaining)) |
| 6.7 | Youku-mPLUG: A 10 Million Large-scale Chinese Video-Language Dataset for Pre-training and Benchmarks ([:x:](https://arxiv.org/abs/2306.04362)), ([:paperclip:](https://arxiv.org/pdf/2306.04362.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.04362)), ([:house:](https://huggingface.co/papers/2306.04362)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/youku-mplug-a-10-million-large-scale-chinese)), ([:octocat:](https://github.com/x-plug/youku-mplug)![GitHub Repo stars](https://img.shields.io/github/stars/x-plug/youku-mplug?style=social) |
| 6.7 | M$^3$IT: A Large-Scale Dataset towards Multi-Modal Multilingual Instruction Tuning ([:x:](https://arxiv.org/abs/2306.04387)), ([:paperclip:](https://arxiv.org/pdf/2306.04387.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.04387)), ([:house:](https://huggingface.co/papers/2306.04387)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/m-3-it-a-large-scale-dataset-towards-multi)) |
| 6.7 | PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts ([:x:](https://arxiv.org/abs/2306.04528)), ([:paperclip:](https://arxiv.org/pdf/2306.04528.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.04528)), ([:house:](https://huggingface.co/papers/2306.04528)), ([:eight_spoked_asterisk:]()), ([:octocat:](https://github.com/microsoft/promptbench)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/promptbench?style=social) |
| 6.7 | INSTRUCTEVAL: Towards Holistic Evaluation of Instruction-Tuned Large Language Models ([:x:](https://arxiv.org/abs/2306.04757)), ([:paperclip:](https://arxiv.org/pdf/2306.04757.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.04757)), ([:house:](https://huggingface.co/papers/2306.04757)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/promptbench-towards-evaluating-the-robustness)), ([:octocat:](https://github.com/declare-lab/instruct-eval)![GitHub Repo stars](https://img.shields.io/github/stars/declare-lab/instruct-eval?style=social)) |
| 6.7 | ChatGPT is fun, but it is not funny! Humor is still challenging Large Language Models ([:x:](https://arxiv.org/abs/2306.04563)), ([:paperclip:](https://arxiv.org/pdf/2306.04563.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.04563)), ([:house:](https://huggingface.co/papers/2306.04563)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/chatgpt-is-fun-but-it-is-not-funny-humor-is)) |
| 6.7 | Deductive Verification of Chain-of-Thought Reasoning ([:x:](https://arxiv.org/abs/2306.03872)), ([:paperclip:](https://arxiv.org/pdf/2306.03872.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03872)), ([:house:](https://huggingface.co/papers/2306.03872)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/deductive-verification-of-chain-of-thought)), ([:octocat:](https://github.com/lz1oceani/verify_cot)![GitHub Repo stars](https://img.shields.io/github/stars/lz1oceani/verify_cot?style=social))  |
| 6.6 | ChatGPT might replace your doctor ‚Äî and it will actually do a better job of caring for you ([news](https://www.businessinsider.com/ai-chatbots-tech-doctors-medicine-healthcare-system-empathy-quality-email-2023-6)) |
| 6.6 | ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory ([:x:](https://arxiv.org/abs/2306.03901)), ([:paperclip:](https://arxiv.org/pdf/2306.03901.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03901)), ([:house:](https://huggingface.co/papers/2306.03901)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/chatdb-augmenting-llms-with-databases-as)) |
| 6.6 | InstructZero: Efficient Instruction Optimization for Black-Box Large Language Models ([:x:](https://arxiv.org/abs/2306.03082)), ([:paperclip:](https://arxiv.org/pdf/2306.03082.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03082)), ([:house:](https://huggingface.co/papers/2306.03082)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/instructzero-efficient-instruction)), ([:octocat:](https://github.comlichang-chen/instructzero)![GitHub Repo stars](https://img.shields.io/github/stars/lichang-chen/instructzero?style=social)) |
| 6.6 | HeadSculpt: Crafting 3D Head Avatars with Text ([:x:](https://arxiv.org/abs/2306.03038)), ([:paperclip:](https://arxiv.org/pdf/2306.03038.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03038)), ([:house:](https://huggingface.co/papers/2306.03038)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/headsculpt-crafting-3d-head-avatars-with-text)) |
| 6.6 | MotionDiffuser: Controllable Multi-Agent Motion Prediction using Diffusion ([:x:](https://arxiv.org/abs/2306.03083)), ([:paperclip:](https://arxiv.org/pdf/2306.03083.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03083)), ([:house:](https://huggingface.co/papers/2306.03083)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/motiondiffuser-controllable-multi-agent-1)) |
| 6.6 | Neuralangelo: High-Fidelity Neural Surface Reconstruction ([:x:](https://arxiv.org/abs/2306.03092)), ([:paperclip:](https://arxiv.org/pdf/2306.03092.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03092)), ([:house:](https://huggingface.co/papers/2306.03092)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/neuralangelo-high-fidelity-neural-surface-1)) |
| 6.6 | PokemonChat: Auditing ChatGPT for Pok√©mon Universe Knowledge ([:x:](https://arxiv.org/abs/2306.03024)), ([:paperclip:](https://arxiv.org/pdf/2306.03024.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03024)), ([:house:](https://huggingface.co/papers/2306.03024)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/pokemonchat-auditing-chatgpt-for-pokemon)) |
| 6.6 | A Static Evaluation of Code Completion by Large Language Models ([:x:](https://arxiv.org/abs/2306.03203)), ([:paperclip:](https://arxiv.org/pdf/2306.03203.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03203)), ([:house:](https://huggingface.co/papers/2306.03203)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-static-evaluation-of-code-completion-by)) |
| 6.6 | Large Language Models of Code Fail at Completing Code with Potential Bugs  ([:x:](https://arxiv.org/abs/2306.03438)), ([:paperclip:](https://arxiv.org/pdf/2306.03438.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03438)), ([:house:](https://huggingface.co/papers/2306.03438)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/large-language-models-of-code-fail-at)) |
| 6.6 | Mega-TTS: Zero-Shot Text-to-Speech at Scale with Intrinsic Inductive Bias ([:x:](https://arxiv.org/abs/2306.03509)), ([:paperclip:](https://arxiv.org/pdf/2306.03509.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03509)), ([:house:](https://huggingface.co/papers/2306.03509)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/mega-tts-zero-shot-text-to-speech-at-scale)) |
| 6.6 | Ada-TTA: Towards Adaptive High-Quality Text-to-Talking Avatar Synthesis ([:x:](https://arxiv.org/abs/2306.03504)), ([:paperclip:](https://arxiv.org/pdf/2306.03504.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03504)), ([:house:](https://huggingface.co/papers/2306.03504)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/ada-tta-towards-adaptive-high-quality-text-to)) |
| 6.6 | Recognize Anything: A Strong Image Tagging Model ([:x:](https://arxiv.org/abs/2306.03514)), ([:paperclip:](https://arxiv.org/pdf/2306.03514.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03514)), ([:house:](https://huggingface.co/papers/2306.03514)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/recognize-anything-a-strong-image-tagging)), ([:octocat:](https://github.com/xinyu1205/recognize-anything)![GitHub Repo stars](https://img.shields.io/github/stars/xinyu1205/recognize-anything?style=social)) |
| 6.6 | ATT3D: Amortized Text-to-3D Object Synthesis ([:x:](https://arxiv.org/abs/2306.07349)), ([:paperclip:](https://arxiv.org/pdf/2306.07349.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07349)), ([:house:](https://huggingface.co/papers/2306.07349)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/att3d-amortized-text-to-3d-object-synthesis)) |
| 6.6 | Falcon-40B-Instruct is a 40B parameters causal decoder-only model built by TII based on Falcon-40B and finetuned on a mixture of Baize ([HF](https://huggingface.co/tiiuae/falcon-40b-instruct)) |
| 6.5 | A survey of Generative AI Applications ([:x:](https://arxiv.org/abs/2306.02781)), ([:paperclip:](https://arxiv.org/pdf/2306.02781.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.02781)), ([:house:](https://huggingface.co/papers/2306.02781)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-survey-of-generative-ai-applications)) |
| 6.5 | New Artificial Intelligence ChatGPT Performs Poorly on the 2022 Self-assessment Study Program for Urology (AUA Urology practice [https://doi.org/10.1097/UPJ.0000000000000406](https://www.auajournals.org/doi/10.1097/UPJ.0000000000000406)) |
| 6.5 | LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion ([:x:](https://arxiv.org/abs/2306.02561)), ([:paperclip:](https://arxiv.org/pdf/2306.02561.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.02561)), ([:house:](https://huggingface.co/papers/2306.02561)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/llm-blender-ensembling-large-language-models)) |
| 6.5 | Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding ([:x:](https://arxiv.org/abs/2306.02858)), ([:paperclip:](https://arxiv.org/pdf/2306.02858.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.02858)), ([:house:](https://huggingface.co/papers/2306.02858)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/video-llama-an-instruction-tuned-audio-visual)), ([:octocat:](https://github.com/damo-nlp-sg/video-llama)![GitHub Repo stars](https://img.shields.io/github/stars/damo-nlp-sg/video-llama?style=social)) |
| 6.5 | PLANNER: Generating Diversified Paragraph via Latent Language Diffusion Mode ([:x:](https://arxiv.org/abs/2306.02531)), ([:paperclip:](https://arxiv.org/pdf/2306.02531.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.02531)), ([:house:](https://huggingface.co/papers/2306.02531)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/planner-generating-diversified-paragraph-via)) |
| 6.5 | Orca: Progressive Learning from Complex Explanation Traces of GPT-4 ([:x:](https://arxiv.org/abs/2306.02707)), ([:paperclip:](https://arxiv.org/pdf/2306.02707.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.02707)), ([:house:](https://huggingface.co/papers/2306.02707)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/orca-progressive-learning-from-complex)) |
| 6.4 | Fine-Tuning Language Models with Advantage-Induced Policy Alignment ([:x:](https://arxiv.org/abs/2306.02231)), ([:paperclip:](https://arxiv.org/pdf/2306.02231.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.02231)), ([:house:](https://huggingface.co/papers/2306.02231)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/fine-tuning-language-models-with-advantage)), ([:octocat:](https://github.com/microsoft/rlhf-apa)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/rlhf-apa?style=social)) |
| 6.4 | SAM3D: Zero-Shot 3D Object Detection via Segment Anything Model  ([:x:](https://arxiv.org/abs/2306.02245)), ([:paperclip:](https://arxiv.org/pdf/2306.02245.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.02245)), ([:house:](https://huggingface.co/papers/2306.02245)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/sam3d-zero-shot-3d-object-detection-via)), ([:octocat:](https://github.com/dyzhang09/sam3d)![GitHub Repo stars](https://img.shields.io/github/stars/dyzhang09/sam3d?style=social))  |
| 6.4 | A Technical Report for Polyglot-Ko: Open-Source Large-Scale Korean Language Models ([:x:](https://arxiv.org/abs/2306.02254)), ([:paperclip:](https://arxiv.org/pdf/2306.02254.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.02254)), ([:house:](https://huggingface.co/papers/2306.02254)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-technical-report-for-polyglot-ko-open)) |
| 6.3 | The Role of ChatGPT, Generative Language Models, and Artificial Intelligence in Medical Education: A Conversation With ChatGPT and a Call for Papers (JMIR, [doi: 10.2196/46885](https://mededu.jmir.org/2023/1/e46885)), ([PDF](https://mededu.jmir.org/2023/1/e46885/PDF)) |
| 6.3 | VisualGPTScore: Visio-Linguistic Reasoning with Multimodal Generative Pre-Training Scores ([:x:](https://arxiv.org/abs/2306.01879)), ([:paperclip:](https://arxiv.org/pdf/2306.01879.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.01879)), ([:house:](https://huggingface.co/papers/2306.01879)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/visualgptscore-visio-linguistic-reasoning)) |
| 6.2 | Segment Anything in High Quality ([:x:](https://arxiv.org/abs/2306.01567)), ([:paperclip:](https://arxiv.org/pdf/2306.01567.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.01567)), ([:house:](https://huggingface.co/papers/2306.01567)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/segment-anything-in-high-quality)), ([:octocat:](https://github.com/syscv/sam-hq)![GitHub Repo stars](https://img.shields.io/github/stars/syscv/sam-hq?style=social)) |
| 6.2 | The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only ([:x:](https://arxiv.org/abs/2306.01116)), ([:paperclip:](https://arxiv.org/pdf/2306.01116.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.01116)), ([:house:](https://huggingface.co/papers/2306.01116)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/the-refinedweb-dataset-for-falcon-llm)) |
| 6.2 | StyleDrop: Text-To-Image Generation in Any Style ([project page](https://styledrop.github.io/)), ([:x:](https://arxiv.org/abs/2306.00983)), ([:paperclip:](https://arxiv.org/pdf/2306.00983.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00983)), ([:house:](https://huggingface.co/papers/2306.00983)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/styledrop-text-to-image-generation-in-any)) |
| 6.1 | How Chatbots and Large Language Model Artificial Intelligence Systems Will Reshape Modern Medicine: Fountain of Creativity or Pandora‚Äôs Box? (Jama [doi: 10.1001/jamainternmed.2023.1835](https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2804310)) |
| 6.1 | StableRep: Synthetic Images from Text-to-Image Models Make Strong Visual Representation Learners ([:x:](https://arxiv.org/abs/2306.00984)), ([:paperclip:](https://arxiv.org/pdf/2306.00984.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00984)), ([:house:](https://huggingface.co/papers/2306.00984)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/stablerep-synthetic-images-from-text-to-image)) |
| 6.1 | The TIME - "The End of Humanity" cover ([tweet](https://twitter.com/TIME/status/1663939590908985348)), (["AI Is Not an Arms Race"](https://time.com/6283609/artificial-intelligence-race-existential-threat/)) | 
| 6.1 | AutoGPTQ - An easy-to-use LLMs quantization package with user-friendly apis, based on GPTQ algorithm ([:octocat:](https://github.com/PanQiWei/AutoGPTQ)![GitHub Repo stars](https://img.shields.io/github/stars/PanQiWei/AutoGPTQ?style=social)) |
| 6.1 | Wuerstchen: Efficient Pretraining of Text-to-Image Models ([:x:](https://arxiv.org/abs/2306.00637)), ([:paperclip:](https://arxiv.org/pdf/2306.00637.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00637)), ([:house:](https://huggingface.co/papers/2306.00637)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/wuerstchen-efficient-pretraining-of-text-to)) |
| 6.1 | StyleGAN knows Normal, Depth, Albedo, and More ([:x:](https://arxiv.org/abs/2306.00987)), ([:paperclip:](https://arxiv.org/pdf/2306.00987.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00987)), ([:house:](https://huggingface.co/papers/2306.00987)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/stylegan-knows-normal-depth-albedo-and-more)) |
| 6.1 | Diffusion Self-Guidance for Controllable Image Generation ([:x:](https://arxiv.org/abs/2306.00986)), ([:paperclip:](https://arxiv.org/pdf/2306.00986.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00986)), ([:house:](https://huggingface.co/papers/2306.00986)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/diffusion-self-guidance-for-controllable)) |
| 6.1 | Thought Cloning: Learning to Think while Acting by Imitating Human Thinking ([:x:](https://arxiv.org/abs/2306.00323)), ([:paperclip:](https://arxiv.org/pdf/2306.00323.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00323)), ([:house:](https://huggingface.co/papers/2306.00323)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/thought-cloning-learning-to-think-while)), ([:octocat:](https://github.com/ShengranHu/Thought-Cloning)![GitHub Repo stars](https://img.shields.io/github/stars/ShengranHu/Thought-Cloning?style=social)) |
| 6.1 | Hiera: A Hierarchical Vision Transformer without the Bells-and-Whistles ([:x:](https://arxiv.org/abs/2306.00989)), ([:paperclip:](https://arxiv.org/pdf/2306.00989.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00989)), ([:house:](https://huggingface.co/papers/2306.00989)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/hiera-a-hierarchical-vision-transformer)) |
| 6.1 | The Hidden Language of Diffusion Models ([:x:](https://arxiv.org/abs/2306.00966)), ([:paperclip:](https://arxiv.org/pdf/2306.00966.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00966)), ([:house:](https://huggingface.co/papers/2306.00966)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/the-hidden-language-of-diffusion-models)) |
| 6.1 | Inserting Anybody in Diffusion Models via Celeb Basis ([:x:](https://arxiv.org/abs/2306.00926)), ([:paperclip:](https://arxiv.org/pdf/2306.00926.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00926)), ([:house:](https://huggingface.co/papers/2306.00926)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/inserting-anybody-in-diffusion-models-via)), ([project page](https://celeb-basis.github.io/)), ([:octocat:](https://github.com/ygtxr1997/celebbasis)![GitHub Repo stars](https://img.shields.io/github/stars/ygtxr1997/celebbasis?style=social)) |
| 6.1 | LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day ([:x:](https://arxiv.org/abs/2306.00890)), ([:paperclip:](https://arxiv.org/pdf/2306.00890.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00890)), ([:house:](https://huggingface.co/papers/2306.00890)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/llava-med-training-a-large-language-and)), ([:octocat:](https://github.com/microsoft/LLaVA-Med)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/LLaVA-Med?style=social)) |
| 6.1 | Birth of a Transformer: A Memory Viewpoint  ([:x:](https://arxiv.org/abs/2306.00802)), ([:paperclip:](https://arxiv.org/pdf/2306.00802.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00802)), ([:house:](https://huggingface.co/papers/2306.00802)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/birth-of-a-transformer-a-memory-viewpoint)) |
| 6.1 | SnapFusion: Text-to-Image Diffusion Model on Mobile Devices within Two Seconds ([:x:](https://arxiv.org/abs/2306.00980)), ([:paperclip:](https://arxiv.org/pdf/2306.00980.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00980)), ([:house:](https://huggingface.co/papers/2306.00980)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/snapfusion-text-to-image-diffusion-model-on)) |
| 6.1 | Make-Your-Video: Customized Video Generation Using Textual and Structural Guidance ([:x:](https://arxiv.org/abs/2306.00943)), ([:paperclip:](https://arxiv.org/pdf/2306.00943.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00943)), ([:house:](https://huggingface.co/papers/2306.00943)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/make-your-video-customized-video-generation)) |
| 6.1 | ReviewerGPT? An Exploratory Study on Using Large Language Models for Paper Reviewing ([:x:](https://arxiv.org/abs/2306.00622)), ([:paperclip:](https://arxiv.org/pdf/2306.00622.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00622)), ([:house:](https://huggingface.co/papers/2306.00622)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/reviewergpt-an-exploratory-study-on-using)) |
| 5.31 | The Impact of Positional Encoding on Length Generalization in Transformers ([:x:](https://arxiv.org/abs/2305.19466)), ([:paperclip:](https://arxiv.org/pdf/2305.19466.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.19466)), ([:house:](https://huggingface.co/papers/2305.19466)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/the-impact-of-positional-encoding-on-length)), ([:octocat:](https://github.com/mcgill-nlp/length-generalization)![GitHub Repo stars](https://img.shields.io/github/stars/mcgill-nlp/length-generalization?style=social)) |
| 5.31 | Tree-Ring Watermarks: Fingerprints for Diffusion Images that are Invisible and Robust ([:x:](https://arxiv.org/abs/2305.20030)), ([:paperclip:](https://arxiv.org/pdf/2305.20030.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.20030)), ([:house:](https://huggingface.co/papers/2305.20030)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/tree-ring-watermarks-fingerprints-for)), ([:octocat:](https://github.com/YuxinWenRick/tree-ring-watermark)![GitHub Repo stars](https://img.shields.io/github/stars/YuxinWenRick/tree-ring-watermark?style=social)) |
| 5.31 | Discovering New Interpretable Conservation Laws as Sparse Invariants ([:x:](https://arxiv.org/abs/2305.19525)), ([:paperclip:](https://arxiv.org/pdf/2305.19525.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.19525)), ([:house:](https://huggingface.co/papers/2305.19525)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/discovering-new-interpretable-conservation)) |
| 5.31 | Control4D: Dynamic Portrait Editing by Learning 4D GAN from 2D Diffusion-based Editor ([:x:](https://arxiv.org/abs/2305.20082)), ([:paperclip:](https://arxiv.org/pdf/2305.20082.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.20082)), ([:house:](https://huggingface.co/papers/2305.20082)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/control4d-dynamic-portrait-editing-by)) |
| 5.31 | Understanding and Mitigating Copying in Diffusion Models ([:x:](https://arxiv.org/abs/2305.20086)), ([:paperclip:](https://arxiv.org/pdf/2305.20086.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.20086)), ([:house:](https://huggingface.co/papers/2305.20086)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/understanding-and-mitigating-copying-in)) |
| 5.31 | PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning ([:x:](https://arxiv.org/abs/2305.19472)), ([:paperclip:](https://arxiv.org/pdf/2305.19472.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.19472)), ([:house:](https://huggingface.co/papers/2305.19472)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/plasma-making-small-language-models-better)) |
| 5.31 | Human or Not? A Gamified Approach to the Turing Test ([:x:](https://arxiv.org/abs/2305.20010)), ([:paperclip:](https://arxiv.org/pdf/2305.20010.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.20010)), ([:house:](https://huggingface.co/papers/2305.20010)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/human-or-not-a-gamified-approach-to-the)) |
| 5.31 | OpenAI - Let‚Äôs Verify Step by Step ([paper](https://cdn.openai.com/improving-mathematical-reasoning-with-process-supervision/Lets_Verify_Step_by_Step.pdf)), ([:x:](https://arxiv.org/abs/2305.20050)), ([:paperclip:](https://arxiv.org/pdf/2305.20050.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.20050)), ([:house:](https://huggingface.co/papers/2305.20050)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/let-s-verify-step-by-step-1)), ([blog](https://openai.com/research/improving-mathematical-reasoning-with-process-supervision)), ([GitHub dataset](https://github.com/openai/prm800k)![GitHub Repo stars](https://img.shields.io/github/stars/openai/prm800k?style=social)) | 
| 5.31 | Humans in 4D: Reconstructing and Tracking Humans with Transformers ([:x:](https://arxiv.org/abs/2306.20091)), ([:paperclip:](https://arxiv.org/pdf/2306.20091.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.20091)), ([:house:](https://huggingface.co/papers/2306.20091)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/humans-in-4d-reconstructing-and-tracking)), ([:octocat:](https://github.com/shubham-goel/4D-Humans)![GitHub Repo stars](https://img.shields.io/github/stars/shubham-goel/4D-Humans?style=social)) |
| 5.31 | Improving CLIP Training with Language Rewrites ([:x:](https://arxiv.org/abs/2306.20088)), ([:paperclip:](https://arxiv.org/pdf/2306.20088.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.20088)), ([:house:](https://huggingface.co/papers/2306.20088)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/improving-clip-training-with-language)) |
| 5.31 | MuseCoco: Generating Symbolic Music from Text ([:x:](https://arxiv.org/abs/2306.00110)), ([:paperclip:](https://arxiv.org/pdf/2306.00110.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00110)), ([:house:](https://huggingface.co/papers/2306.00110)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/musecoco-generating-symbolic-music-from-text)) |
| 5.31 | MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training ([:x:](https://arxiv.org/abs/2306.00107)), ([:paperclip:](https://arxiv.org/pdf/2306.00107.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00107)), ([:house:](https://huggingface.co/papers/2306.00107)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/mert-acoustic-music-understanding-model-with)), ([:octocat:](https://github.com/yizhilll/mert)![GitHub Repo stars](https://img.shields.io/github/stars/yizhilll/mert?style=social)) |
| 5.31 | CodeTF: One-stop Transformer Library for State-of-the-art Code LLM ([:x:](https://arxiv.org/abs/2306.00029)), ([:paperclip:](https://arxiv.org/pdf/2306.00029.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00029)), ([:house:](https://huggingface.co/papers/2306.00029)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/codetf-one-stop-transformer-library-for-state)), ([:octocat:](https://github.com/salesforce/codetf)![GitHub Repo stars](https://img.shields.io/github/stars/salesforce/codetf?style=social)) |
| 5.30 | Prompt Engineering for Effective Use of Large Language Models in Radiology ([RSNA](https://pubs.rsna.org/page/ai/blog/2023/05/ryai_editorsblog053023)) |
| 5.30 | Re-evaluating Word Mover's Distance ([:x:](https://arxiv.org/abs/2305.14403)), ([:paperclip:](https://arxiv.org/pdf/2305.14403.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14403)), ([:house:](https://huggingface.co/papers/2305.14403)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/re-evaluating-word-mover-s-distance)), ([:octocat:](https://github.com/joisino/reeval-wmd)![GitHub Repo stars](https://img.shields.io/github/stars/joisino/reeval-wmd?style=social)) |
| 5.30 | Bigger, Better, Faster: Human-level Atari with human-level efficiency ([:x:](https://arxiv.org/abs/2305.19452)), ([:paperclip:](https://arxiv.org/pdf/2305.19452.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.19452)), ([:house:](https://huggingface.co/papers/2305.19452)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/bigger-better-faster-human-level-atari-with)), ([:octocat:](https://github.com/google-research/google-research)![GitHub Repo stars](https://img.shields.io/github/stars/google-research/google-research?style=social)) |
| 5.30 | Japan Goes All In: Copyright Doesn‚Äôt Apply To AI Training ([news](https://technomancers.ai/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/)) |
| 5.30 | A.I. Poses ‚ÄòRisk of Extinction,‚Äô Industry Leaders Warn - ([NYT news](https://www.nytimes.com/2023/05/30/technology/ai-threat-warning.html)) |
| 5.30 | Statement on AI Risk - AI experts and public figures express their concern about AI risk ([statement](https://www.safe.ai/statement-on-ai-risk)) | 
| 5.30 | GPT4Tools: Teaching Large Language Model to Use Tools via Self-instruction ([:x:](https://arxiv.org/abs/2305.18752)), ([:paperclip:](https://arxiv.org/pdf/2305.18752.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18752)), ([:house:](https://huggingface.co/papers/2305.18752)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/gpt4tools-teaching-large-language-model-to)), ([:octocat:](https://github.com/stevengrove/gpt4tools)![GitHub Repo stars](https://img.shields.io/github/stars/stevengrove/gpt4tools?style=social)) |
| 5.30 | Nested Diffusion Processes for Anytime Image Generation ([:x:](https://arxiv.org/abs/2305.19066)), ([:paperclip:](https://arxiv.org/pdf/2305.19066.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.19066)), ([:house:](https://huggingface.co/papers/2305.19066)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/nested-diffusion-processes-for-anytime-image)) |
| 5.30 | StyleAvatar3D: Leveraging Image-Text Diffusion Models for High-Fidelity 3D Avatar Generation ([:x:](https://arxiv.org/abs/2305.19012)), ([:paperclip:](https://arxiv.org/pdf/2305.19012.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.19012)), ([:house:](https://huggingface.co/papers/2305.19012)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/styleavatar3d-leveraging-image-text-diffusion)), ([GitHub dataset](https://github.com/icoz69/styleavatar3d)![GitHub Repo stars](https://img.shields.io/github/stars/icoz69/styleavatar3d?style=social))  |
| 5.30 | HiFA: High-fidelity Text-to-3D with Advanced Diffusion Guidance ([:x:](https://arxiv.org/abs/2305.18766)), ([:paperclip:](https://arxiv.org/pdf/2305.18766.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18766)), ([:house:](https://huggingface.co/papers/2305.18766)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/hifa-high-fidelity-text-to-3d-with-advanced)) |
| 5.30 | Grammar Prompting for Domain-Specific Language Generation with Large Language Models ([:x:](https://arxiv.org/abs/2305.19234)), ([:paperclip:](https://arxiv.org/pdf/2305.19234.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.19234)), ([:house:](https://huggingface.co/papers/2305.19234)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/grammar-prompting-for-domain-specific)) |
| 5.30 | AlteredAvatar: Stylizing Dynamic 3D Avatars with Fast Style Adaptation  ([:x:](https://arxiv.org/abs/2305.19245)), ([:paperclip:](https://arxiv.org/pdf/2305.19245.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.19245)), ([:house:](https://huggingface.co/papers/2305.19245)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/alteredavatar-stylizing-dynamic-3d-avatars)) |
| 5.30 | Ambient Diffusion: Learning Clean Distributions from Corrupted Data  ([:x:](https://arxiv.org/abs/2305.19256)), ([:paperclip:](https://arxiv.org/pdf/2305.19256.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.19256)), ([:house:](https://huggingface.co/papers/2305.19256)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/ambient-diffusion-learning-clean)), ([:octocat:](https://github.com/giannisdaras/ambient-diffusion)![GitHub Repo stars](https://img.shields.io/github/stars/giannisdaras/ambient-diffusion?style=social)) |
| 5.30 | ChatGPT and large language models in gastroenterology, ([Nature Reviews Gastroenterology & Hepatology](https://www.nature.com/articles/s41575-023-00799-8)) |
| 5.30 | Blockwise Parallel Transformer for Long Context Large Models ([:x:](https://arxiv.org/abs/2305.19370)), ([:paperclip:](https://arxiv.org/pdf/2305.19370.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.19370)), ([:house:](https://huggingface.co/papers/2305.19370)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/blockwise-parallel-transformer-for-long)) |
| 5.29 | A lawyer used ChatGPT to prepare a court filing. It went horribly awry. ([CBS news](https://www.cbsnews.com/news/lawyer-chatgpt-court-filing-avianca/)) |
| 5.29 | Reconstructing the Mind's Eye: fMRI-to-Image with Contrastive Learning and Diffusion Priors ([:x:](https://arxiv.org/abs/2305.18274)), ([:paperclip:](https://arxiv.org/pdf/2305.18274.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18274)), ([:house:](https://huggingface.co/papers/2305.18274)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/reconstructing-the-mind-s-eye-fmri-to-image)), ([:octocat:](https://github.com/medarc-ai/fmri-reconstruction-nsd)![GitHub Repo stars](https://img.shields.io/github/stars/medarc-ai/fmri-reconstruction-nsd?style=social)) |
| 5.29 | RAPHAEL: Text-to-Image Generation via Large Mixture of Diffusion Paths ([:x:](https://arxiv.org/abs/2305.18295)), ([:paperclip:](https://arxiv.org/pdf/2305.18295.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18295)), ([:house:](https://huggingface.co/papers/2305.18295)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/raphael-text-to-image-generation-via-large)) |
| 5.29 | Photoswap: Personalized Subject Swapping in Images ([:x:](https://arxiv.org/abs/2305.18286)), ([:paperclip:](https://arxiv.org/pdf/2305.18286.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18286)), ([:house:](https://huggingface.co/papers/2305.18286)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/photoswap-personalized-subject-swapping-in)) |
| 5.29 | TaleCrafter: Interactive Story Visualization with Multiple Characters ([:x:](https://arxiv.org/abs/2305.18247)), ([:paperclip:](https://arxiv.org/pdf/2305.18247.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18247)), ([:house:](https://huggingface.co/papers/2305.18247)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/talecrafter-interactive-story-visualization)), ([:octocat:](https://github.com/videocrafter/talecrafter)![GitHub Repo stars](https://img.shields.io/github/stars/videocrafter/talecrafter?style=social)) |
| 5.29 | GlyphControl: Glyph Conditional Control for Visual Text Generation ([:x:](https://arxiv.org/abs/2305.18259)), ([:paperclip:](https://arxiv.org/pdf/2305.18259.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18259)), ([:house:](https://huggingface.co/papers/2305.18259)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/glyphcontrol-glyph-conditional-control-for)) |
| 5.29 | Make-An-Audio 2: Temporal-Enhanced Text-to-Audio Generation ([:x:](https://arxiv.org/abs/2305.18474)), ([:paperclip:](https://arxiv.org/pdf/2305.18474.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18474)), ([:house:](https://huggingface.co/papers/2305.18474)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/make-an-audio-2-temporal-enhanced-text-to)) |
| 5.29 | Faith and Fate: Limits of Transformers on Compositionality  ([:x:](https://arxiv.org/abs/2305.18654)), ([:paperclip:](https://arxiv.org/pdf/2305.18654.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18654)), ([:house:](https://huggingface.co/papers/2305.18654)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/faith-and-fate-limits-of-transformers-on)) |
| 5.29 | PaLI-X: On Scaling up a Multilingual Vision and Language Model ([:x:](https://arxiv.org/abs/2305.18565)), ([:paperclip:](https://arxiv.org/pdf/2305.18565.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18565)), ([:house:](https://huggingface.co/papers/2305.18565)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/pali-x-on-scaling-up-a-multilingual-vision)) |
| 5.29 | Controllable Text-to-Image Generation with GPT-4  ([:x:](https://arxiv.org/abs/2305.18583)), ([:paperclip:](https://arxiv.org/pdf/2305.18583.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18583)), ([:house:](https://huggingface.co/papers/2305.18583)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/controllable-text-to-image-generation-with)) |
| 5.29 | Brainformers: Trading Simplicity for Efficiency ([:x:](https://arxiv.org/abs/2306.00008)), ([:paperclip:](https://arxiv.org/pdf/2306.00008.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00008)), ([:house:](https://huggingface.co/papers/2306.00008)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/brainformers-trading-simplicity-for)) |
| 5.28 | Geometric Algebra Transformers ([:x:](https://arxiv.org/abs/2305.18415)), ([:paperclip:](https://arxiv.org/pdf/2305.18415.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18415)), ([:house:](https://huggingface.co/papers/2305.18415)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/geometric-algebra-transformers)) |
| 5.28 | Tab-CoT: Zero-shot Tabular Chain of Thought ([:x:](https://arxiv.org/abs/2305.17812)), ([:paperclip:](https://arxiv.org/pdf/2305.17812.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17812)), ([:house:](https://huggingface.co/papers/2305.17812)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/tab-cot-zero-shot-tabular-chain-of-thought)) |
| 5.28 | Tab-CoT: Zero-shot Tabular Chain of Thought ([:x:](https://arxiv.org/abs/2305.17812)), ([:paperclip:](https://arxiv.org/pdf/2305.17812.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17812)), ([:house:](https://huggingface.co/papers/2305.17812)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/tab-cot-zero-shot-tabular-chain-of-thought)) |
| 5.28 | FuseCap: Leveraging Large Language Models to Fuse Visual Data into Enriched Image Captions ([:x:](https://arxiv.org/abs/2305.17718)), ([:paperclip:](https://arxiv.org/pdf/2305.17718.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17718)), ([:house:](https://huggingface.co/papers/2305.17718)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/fusecap-leveraging-large-language-models-to)), ([demo](https://huggingface.co/spaces/Xalphinions/tab-cot)) |
| 5.28 | Introducing NVIDIA ACE For Games - Spark Life Into Virtual Characters With Generative AI ([blog](https://www.nvidia.com/en-us/geforce/news/nvidia-ace-for-games-generative-ai-npcs/)) |
| 5.27 | SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks ([:x:](https://arxiv.org/abs/2305.17390)), ([:paperclip:](https://arxiv.org/pdf/2305.17390.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17390)), ([:house:](https://huggingface.co/papers/2305.17390)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/swiftsage-a-generative-agent-with-fast-and)) |
| 5.27 | The Curse of Recursion: Training on Generated Data Makes Models Forget ([:x:](https://arxiv.org/abs/2305.17493)), ([:paperclip:](https://arxiv.org/pdf/2305.17493.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17493)), ([:house:](https://huggingface.co/papers/2305.17493)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/model-dementia-generated-data-makes-models)) |
| 5.27 | DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of GPT-Generated Text ([:x:](https://arxiv.org/abs/2305.17359)), ([:paperclip:](https://arxiv.org/pdf/2305.17359.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17359)), ([:house:](https://huggingface.co/papers/2305.17359)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/dna-gpt-divergent-n-gram-analysis-for)) |
| 5.27 | What indeed can GPT models do in chemistry? A comprehensive benchmark on eight tasks ([:x:](https://arxiv.org/abs/2305.18365)), ([:paperclip:](https://arxiv.org/pdf/2305.18365.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18365)), ([:house:](https://huggingface.co/papers/2305.18365)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/what-indeed-can-gpt-models-do-in-chemistry-a)) |
| 5.27 | WingmanAI - real-time transcription of audio, integrated with ChatGPT for interactive use ([:octocat:](https://github.com/e-johnstonn/wingmanAI)![GitHub Repo stars](https://img.shields.io/github/stars/e-johnstonn/wingmanAI?style=social)) |
| 5.27 | ToolBench - Large-scale instruction tuning SFT data to equip LLMs with general tool-use capability ([:octocat:](https://github.com/OpenBMB/ToolBench)![GitHub Repo stars](https://img.shields.io/github/stars/OpenBMB/ToolBench?style=social)) |
| 5.27 | G7 officials to hold first meeting on AI regulation next week ([news](https://www.reuters.com/world/g7-officials-hold-first-meeting-ai-regulation-next-week-2023-05-26/)) |
| 5.26 | ChatGPT Fails American College of Gastroenterology Assessment Tests ([news](https://healthitanalytics.com/news/chatgpt-fails-american-college-of-gastroenterology-assessment-tests)) |
| 5.26 | Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance ([:x:](https://arxiv.org/abs/2305.17306)), ([:paperclip:](https://arxiv.org/pdf/2305.17306.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17306)), ([:house:](https://huggingface.co/papers/2305.17306)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/chain-of-thought-hub-a-continuous-effort-to)), ([:octocat:](https://github.com/franxyao/chain-of-thought-hub)![GitHub Repo stars](https://img.shields.io/github/stars/franxyao/chain-of-thought-hub?style=social)) |
| 5.26 | A new antibiotic, discovered with artificial intelligence, may defeat a dangerous superbug ([CNN news](https://edition.cnn.com/2023/05/25/health/antibiotic-artificial-intelligence-superbug/index.html)) |
| 5.26 | Generating Images with Multimodal Language Models ([:x:](https://arxiv.org/abs/2305.17216)), ([:paperclip:](https://arxiv.org/pdf/2305.17216.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17216)), ([:house:](https://huggingface.co/papers/2305.17216)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/generating-images-with-multimodal-language)), ([:octocat:](https://github.com/kohjingyu/gill)![GitHub Repo stars](https://img.shields.io/github/stars/kohjingyu/gill?style=social)) |
| 5.26 | Backpack Language Models ([:x:](https://arxiv.org/abs/2305.16765)), ([:paperclip:](https://arxiv.org/pdf/2305.16765.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16765)), ([:house:](https://huggingface.co/papers/2305.16765)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/backpack-language-models)) |
| 5.26 | Impossible Distillation: from Low-Quality Model to High-Quality Dataset & Model for Summarization and Paraphrasing ([:x:](https://arxiv.org/abs/2305.16635)), ([:paperclip:](https://arxiv.org/pdf/2305.16635.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16635)), ([:house:](https://huggingface.co/papers/2305.16635)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/impossible-distillation-from-low-quality)) |
| 5.26 | Playing repeated games with Large Language Models ([:x:](https://arxiv.org/abs/2305.16867)), ([:paperclip:](https://arxiv.org/pdf/2305.16867.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16867)), ([:house:](https://huggingface.co/papers/2305.16867)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/playing-repeated-games-with-large-language)) |
| 5.26 | Training Socially Aligned Language Models in Simulated Human Society ([:x:](https://arxiv.org/abs/2305.16960)), ([:paperclip:](https://arxiv.org/pdf/2305.16960.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16960)), ([:house:](https://huggingface.co/papers/2305.16960)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/training-socially-aligned-language-models-in)) |
| 5.26 | BiomedGPT: A Unified and Generalist Biomedical Generative Pre-trained Transformer for Vision, Language, and Multimodal Tasks ([:x:](https://arxiv.org/abs/2305.17100)), ([:paperclip:](https://arxiv.org/pdf/2305.17100.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17100)), ([:house:](https://huggingface.co/papers/2305.17100)) |
| 5.26 | Large Language Models as Tool Makers ([:x:](https://arxiv.org/abs/2305.17126)), ([:paperclip:](https://arxiv.org/pdf/2305.17126.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17126)), ([:house:](https://huggingface.co/papers/2305.17126)) |
| 5.26 | ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation  ([:x:](https://arxiv.org/abs/2305.16213)), ([:paperclip:](https://arxiv.org/pdf/2305.16213.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16213)), ([:house:](https://huggingface.co/papers/2305.16213)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/prolificdreamer-high-fidelity-and-diverse)), ([project page](https://ml.cs.tsinghua.edu.cn/prolificdreamer/)) |
| 5.25 | The Current and Future State of AI Interpretation of Medical Images (NEJM, [DOI: 10.1056/NEJMra2301725](https://www.nejm.org/doi/full/10.1056/NEJMra2301725)) |
| 5.25 | Deep learning-guided discovery of an antibiotic targeting Acinetobacter baumannii, (nature chemical biology [https://doi.org/10.1038/s41589-023-01349-8](https://www.nature.com/articles/s41589-023-01349-8)), ([:octocat:](https://github.com/chemprop/chemprop)![GitHub Repo stars](https://img.shields.io/github/stars/chemprop/chemprop?style=social)), ([Cloned snapshot](https://github.com/GaryLiu152/chemprop_abaucin)) |
| 5.25 | Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory ([:x:](https://arxiv.org/abs/2305.17144)), ([:paperclip:](https://arxiv.org/pdf/2305.17144.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17144)), ([:house:](https://huggingface.co/papers/2305.17144)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/ghost-in-the-minecraft-generally-capable)), ([:octocat:](https://github.com/opengvlab/gitm)![GitHub Repo stars](https://img.shields.io/github/stars/opengvlab/gitm?style=social)) |
| 5.25 | Role-Play with Large Language Models ([:x:](https://arxiv.org/abs/2305.16367)), ([:paperclip:](https://arxiv.org/pdf/2305.16367.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16367)), ([:house:](https://huggingface.co/papers/2305.16367)) |
| 5.25 | Break-A-Scene: Extracting Multiple Concepts from a Single Image ([:x:](https://arxiv.org/abs/2305.16311)), ([:paperclip:](https://arxiv.org/pdf/2305.16311.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16311)), ([:house:](https://huggingface.co/papers/2305.16311)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/break-a-scene-extracting-multiple-concepts)) |
| 5.25 | Voyager: An Open-Ended Embodied Agent with Large Language Models ([Project page](https://voyager.minedojo.org/)), ([:x:](https://arxiv.org/abs/2305.16291)), ([:paperclip:](https://arxiv.org/pdf/2305.16291.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16291)), ([:house:](https://huggingface.co/papers/2305.16291)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/voyager-an-open-ended-embodied-agent-with)), ([:octocat:](https://github.com/MineDojo/Voyager)![GitHub Repo stars](https://img.shields.io/github/stars/MineDojo/Voyager?style=social)), ([MindDojo](https://minedojo.org/)) |
| 5.25 | Efficient Neural Music Generation ([:x:](https://arxiv.org/abs/2305.15719)), ([:paperclip:](https://arxiv.org/pdf/2305.15719.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15719)), ([:house:](https://huggingface.co/papers/2305.15719)) |
| 5.25 | Custom-Edit: Text-Guided Image Editing with Customized Diffusion Models ([:x:](https://arxiv.org/abs/2305.15779)), ([:paperclip:](https://arxiv.org/pdf/2305.15779.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15779)), ([:house:](https://huggingface.co/papers/2305.15779)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/custom-edit-text-guided-image-editing-with)) |
| 5.25 | On Architectural Compression of Text-to-Image Diffusion Models ([:x:](https://arxiv.org/abs/2305.15798)), ([:paperclip:](https://arxiv.org/pdf/2305.15798.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15798)), ([:house:](https://huggingface.co/papers/2305.15798)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/on-architectural-compression-of-text-to-image)) |
| 5.25 | Prompt-Free Diffusion: Taking "Text" out of Text-to-Image Diffusion Models ([:x:](https://arxiv.org/abs/2305.16223)), ([:paperclip:](https://arxiv.org/pdf/2305.16223.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16223)), ([:house:](https://huggingface.co/papers/2305.16223)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/prompt-free-diffusion-taking-text-out-of-text)), ([:octocat:](https://github.com/SHI-Labs/Prompt-Free-Diffusion)![GitHub Repo stars](https://img.shields.io/github/stars/SHI-Labs/Prompt-Free-Diffusion?style=social)) |
| 5.25 | The False Promise of Imitating Proprietary LLMs ([:x:](https://arxiv.org/abs/2305.15717)), ([:paperclip:](https://arxiv.org/pdf/2305.15717.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15717)), ([:house:](https://huggingface.co/papers/2305.15717)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/the-false-promise-of-imitating-proprietary)) |
| 5.25 | the new Stable Diffusion ‚ÄúReimagine XL‚Äù model on @ClipdropApp x @StabilityAI ([tweet](https://twitter.com/hardmaru/status/1661739577395286022)), ([Clipdrop](https://clipdrop.co/stable-diffusion-reimagine)) |
| 5.25 | Gorilla: Large Language Model Connected with Massive APIs ([tweet](https://twitter.com/shishirpatil_/status/1661780076277678082)), ([project page](https://gorilla.cs.berkeley.edu/)), ([:x:](https://arxiv.org/abs/2305.15334)), ([:paperclip:](https://arxiv.org/pdf/2305.15334.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15334)), ([:house:](https://huggingface.co/papers/2305.15334)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/gorilla-large-language-model-connected-with)), ([:octocat:](https://github.com/ShishirPatil/gorilla)![GitHub Repo stars](https://img.shields.io/github/stars/ShishirPatil/gorilla?style=social)), ([demo video](https://drive.google.com/file/d/1E0k5mG1mTiaz0kukyK1PdeohJipTFh6j/view)), ([discord](https://discord.com/invite/3apqwwME)) |
| 5.25 | OpenAI - Democratic Inputs to AI ([Tweet](https://twitter.com/OpenAI/status/1661811329957781504)), ([Blog](https://openai.com/blog/democratic-inputs-to-ai)) |
| 5.24 | HuatuoGPT, towards Taming Language Model to Be a Doctor ([:x:](https://arxiv.org/abs/2305.15075)), ([:paperclip:](https://arxiv.org/pdf/2305.15075.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15075)), ([:house:](https://huggingface.co/papers/2305.15075)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/huatuogpt-towards-taming-language-model-to-be)), ([:octocat:](https://github.com/freedomintelligence/huatuogpt)![GitHub Repo stars](https://img.shields.io/github/stars/freedomintelligence/huatuogpt?style=social)) |
| 5.24 | Instructions as Backdoors: Backdoor Vulnerabilities of Instruction Tuning for Large Language Models ([:x:](https://arxiv.org/abs/2305.14710)), ([:paperclip:](https://arxiv.org/pdf/2305.14710.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14710)), ([:house:](https://huggingface.co/papers/2305.14710)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/instructions-as-backdoors-backdoor)) |
| 5.24 | Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For Large Language Models ([:x:](https://arxiv.org/abs/2305.15074)), ([:paperclip:](https://arxiv.org/pdf/2305.15074.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15074)), ([:house:](https://huggingface.co/papers/2305.15074)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/have-llms-advanced-enough-a-challenging)) |
| 5.24 | Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models ([:x:](https://arxiv.org/abs/2305.14763)), ([:paperclip:](https://arxiv.org/pdf/2305.14763.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14763)), ([:house:](https://huggingface.co/papers/2305.14763)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/clever-hans-or-neural-theory-of-mind-stress)) |
| 5.24 | A majority of Americans have heard of ChatGPT, but few have tried it themselves ([Pew Research Center news](https://www.pewresearch.org/short-reads/2023/05/24/a-majority-of-americans-have-heard-of-chatgpt-but-few-have-tried-it-themselves/)) |
| 5.24 | Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective ([:x:](https://arxiv.org/abs/2305.16338)), ([:paperclip:](https://arxiv.org/pdf/2305.16338.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16338)), ([:house:](https://huggingface.co/papers/2305.16338)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/towards-revealing-the-mystery-behind-chain-of)) |
| 5.24 | Think Before You Act: Decision Transformers with Internal Working Memory ([:x:](https://arxiv.org/abs/2305.15408)), ([:paperclip:](https://arxiv.org/pdf/2305.15408.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15408)), ([:house:](https://huggingface.co/papers/2305.15408)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/think-before-you-act-decision-transformers)) |
| 5.24 | PandaGPT: One Model to Instruction-Follow Them All ([project page](https://panda-gpt.github.io/)), ([:paperclip:](https://github.com/yxuansu/PandaGPT/blob/main/PandaGPT.pdf)), ([demo](https://huggingface.co/spaces/GMFTBY/PandaGPT)), ([video](https://www.youtube.com/watch?v=96XgdQle7EY)), ([dataset](https://huggingface.co/datasets/openllmplayground/pandagpt_visual_instruction_dataset)), ([model](https://huggingface.co/openllmplayground/pandagpt_13b_max_len_400)), ([:octocat:](https://github.com/yxuansu/PandaGPT)![GitHub Repo stars](https://img.shields.io/github/stars/yxuansu/PandaGPT?style=social)), ([tweet](https://twitter.com/yixuan_su/status/1661064018868551691)) |
| 5.24 | SPRING: GPT-4 Out-performs RL Algorithms by Studying Papers and Reasoning ([:x:](https://arxiv.org/abs/2305.15486)), ([:paperclip:](https://arxiv.org/pdf/2305.15486.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15486)), ([:house:](https://huggingface.co/papers/2305.15486)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/spring-gpt-4-out-performs-rl-algorithms-by)) |
| 5.24 | Manifold Diffusion Fields ([:x:](https://arxiv.org/abs/2305.15586)), ([:paperclip:](https://arxiv.org/pdf/2305.15586.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15586)), ([:house:](https://huggingface.co/papers/2305.15586)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/manifold-diffusion-fields)) |
| 5.24 | A Neural Space-Time Representation for Text-to-Image Personalization ([:x:](https://arxiv.org/abs/2305.15391)), ([:paperclip:](https://arxiv.org/pdf/2305.15391.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15391)), ([:house:](https://huggingface.co/papers/2305.15391)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-neural-space-time-representation-for-text)), ([:octocat:](https://github.com/NeuralTextualInversion/NeTI)![GitHub Repo stars](https://img.shields.io/github/stars/NeuralTextualInversion/NeTI?style=social)) |
| 5.24 | Can Transformers Learn to Solve Problems Recursively? ([:x:](https://arxiv.org/abs/2305.14699)), ([:paperclip:](https://arxiv.org/pdf/2305.14699.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14699)), ([:house:](https://huggingface.co/papers/2305.14699)) |
| 5.24 | This Land is {Your, My} Land: Evaluating Geopolitical Biases in Language Models ([:x:](https://arxiv.org/abs/2305.14610)), ([:paperclip:](https://arxiv.org/pdf/2305.14610.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14610)), ([:house:](https://huggingface.co/papers/2305.14610)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/this-land-is-your-my-land-evaluating)) |
| 5.24 | Model evaluation for extreme risks ([:x:](https://arxiv.org/abs/2305.15324)), ([:paperclip:](https://arxiv.org/pdf/2305.15324.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15324)), ([:house:](https://huggingface.co/papers/2305.15324)) |
| 5.24 | State of GPT and RLHF LLMs - Andrej Karpathy, OpenAI ([session](https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2)), ([video](https://mediusdownload.event.microsoft.com/video-51378/ea11c3c20e/BRK216HFS_v1.mp4?sv=2018-03-28&sr=c&sig=tlIPwp2z6q8TNAEig%2BOQGh4lL8o8hAHcdw33msvikXY%3D&se=2028-05-24T06%3A23%3A01Z&sp=r)) |
| 5.24 | LMs with a Voice: Spoken Language Modeling beyond Speech Tokens ([:x:](https://arxiv.org/abs/2305.15255)), ([:paperclip:](https://arxiv.org/pdf/2305.15255.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15255)), ([:house:](https://huggingface.co/papers/2305.15255)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/blip-diffusion-pre-trained-subject)), ([:octocat:](https://paperswithcode.com/paper/lms-with-a-voice-spoken-language-modeling)) |
| 5.24 | BLIP-Diffusion: Pre-trained Subject Representation for Controllable Text-to-Image Generation and Editing ([:x:](https://arxiv.org/abs/2305.14720)), ([:paperclip:](https://arxiv.org/pdf/2305.14720.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14720)), ([:house:](https://huggingface.co/papers/2305.14720)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/blip-diffusion-pre-trained-subject)), ([:octocat:](https://github.com/salesforce/LAVIS/tree/main/projects/blip-diffusion)), ([Project page](https://dxli94.github.io/BLIP-Diffusion-website/)) |
| 5.23 | Threats by artificial intelligence to human health and human existence (BMJ, [http://dx.doi.org/10.1136/bmjgh-2022-010435](https://gh.bmj.com/content/8/5/e010435)), ([PDF](https://gh.bmj.com/content/bmjgh/8/5/e010435.full.pdf)) |
| 5.23 | Transformer-based Vulnerability Detection in Code at EditTime: Zero-shot, Few-shot, or Fine-tuning? [:x:](https://arxiv.org/abs/2306.01754)), ([:paperclip:](https://arxiv.org/pdf/2306.01754.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.01754)), ([:house:](https://huggingface.co/papers/2306.01754)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/transformer-based-vulnerability-detection-in)) |
| 5.23 | Unity‚Äôs Project Barracuda Injects Generative AI Into Games To Kickstart Exponential Growth ([Forbes news](https://www.forbes.com/sites/johnkoetsier/2023/05/23/unitys-project-barracuda-injects-generative-ai-into-games-to-kickstart-exponential-growth/?sh=5b2154b3703a)) |
| 5.23 | VisorGPT: Learning Visual Prior via Generative Pre-Training ([:x:](https://arxiv.org/abs/2305.13777)), ([:paperclip:](https://arxiv.org/pdf/2305.13777.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13777)), ([:house:](https://huggingface.co/papers/2305.13777)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/visorgpt-learning-visual-prior-via-generative)), ([:octocat:](https://github.com/sierkinhane/visorgpt)![GitHub Repo stars](https://img.shields.io/github/stars/sierkinhane/visorgpt?style=social)) |
| 5.23 | ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models ([:x:](https://arxiv.org/abs/2305.18323)), ([:paperclip:](https://arxiv.org/pdf/2305.18323.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18323)), ([:house:](https://huggingface.co/papers/2305.18323)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/rewoo-decoupling-reasoning-from-observations)) |
| 5.23 | OlaGPT: Empowering LLMs With Human-like Problem-Solving Abilities ([:x:](https://arxiv.org/abs/2305.16334)), ([:paperclip:](https://arxiv.org/pdf/2305.16334.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16334)), ([:house:](https://huggingface.co/papers/2305.16334)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/olagpt-empowering-llms-with-human-like)) |
| 5.23 | Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks ([:x:](https://arxiv.org/abs/2305.14201)), ([:paperclip:](https://arxiv.org/pdf/2305.14201.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14201)), ([:house:](https://huggingface.co/papers/2305.14201)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/goat-fine-tuned-llama-outperforms-gpt-4-on)) |
| 5.23 | Enhancing Detail Preservation for Customized Text-to-Image Generation: A Regularization-Free Approach ([:x:](https://arxiv.org/abs/2305.13579)), ([:paperclip:](https://arxiv.org/pdf/2305.13579.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13579)), ([:house:](https://huggingface.co/papers/2305.13579)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/enhancing-detail-preservation-for-customized)) |
| 5.23 | Control-A-Video: Controllable Text-to-Video Generation with Diffusion Models ([:x:](https://arxiv.org/abs/2305.13840)), ([:paperclip:](https://arxiv.org/pdf/2305.13840.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13840)), ([:house:](https://huggingface.co/papers/2305.13840)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/control-a-video-controllable-text-to-video)), ([:octocat:](https://github.com/Weifeng-Chen/control-a-video)![GitHub Repo stars](https://img.shields.io/github/stars/Weifeng-Chen/control-a-video?style=social))|
| 5.23 | Aligning Large Language Models through Synthetic Feedback ([:x:](https://arxiv.org/abs/2305.13735)), ([:paperclip:](https://arxiv.org/pdf/2305.13735.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13735)), ([:house:](https://huggingface.co/papers/2305.13735)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/aligning-large-language-models-through)) |
| 5.23 | LLMs as Factual Reasoners: Insights from Existing Benchmarks and Beyond ([:x:](https://arxiv.org/abs/2305.14540)), ([:paperclip:](https://arxiv.org/pdf/2305.14540.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14540)), ([:house:](https://huggingface.co/papers/2305.14540)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/llms-as-factual-reasoners-insights-from)), ([:octocat:](https://github.com/salesforce/factualnlg)![GitHub Repo stars](https://img.shields.io/github/stars/salesforce/factualnlg?style=social)) |
| 5.23 | Lost in Translation: Large Language Models in Non-English Content Analysis ([news](https://cdt.org/insights/lost-in-translation-large-language-models-in-non-english-content-analysis)) |
| 5.23 | Anchor Prediction: Automatic Refinement of Internet Links ([:x:](https://arxiv.org/abs/2305.14337)), ([:paperclip:](https://arxiv.org/pdf/2305.14337.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14337)), ([:house:](https://huggingface.co/papers/2305.14337)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/anchor-prediction-automatic-refinement-of)) |
| 5.23 | Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for Improved Vision-Language Compositionality ([:x:](https://arxiv.org/abs/2305.13812)), ([:paperclip:](https://arxiv.org/pdf/2305.13812.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13812)), ([:house:](https://huggingface.co/papers/2305.13812)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/coarse-to-fine-contrastive-learning-in-image)) |
| 5.23 | Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training ([:x:](https://arxiv.org/abs/2305.14342)), ([:paperclip:](https://arxiv.org/pdf/2305.14342.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14342)), ([:house:](https://huggingface.co/papers/2305.14342)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/sophia-a-scalable-stochastic-second-order)) |
| 5.23 | PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents ([:x:](https://arxiv.org/abs/2305.14564)), ([:paperclip:](https://arxiv.org/pdf/2305.14564.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14564)), ([:house:](https://huggingface.co/papers/2305.14564)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/pearl-prompting-large-language-models-to-plan)) |
| 5.23 | Bing at Microsoft Build 2023: Continuing the Transformation of Search ([blog](https://blogs.bing.com/search/may_2023/Bing-at-Microsoft-Build-2023)) |
| 5.23 | Bringing the power of AI to Windows 11 ‚Äì unlocking a new era of productivity for customers and developers with Windows Copilot and Dev Home ([blog](https://blogs.windows.com/windowsdeveloper/2023/05/23/bringing-the-power-of-ai-to-windows-11-unlocking-a-new-era-of-productivity-for-customers-and-developers-with-windows-copilot-and-dev-home/)) |
| 5.23 | Adobe Unveils Future of Creative Cloud With Generative AI as a Creative Co-Pilot in Photoshop ([news](https://news.adobe.com/news/news-details/2023/Adobe-Unveils-Future-of-Creative-Cloud-with-Generative-AI-as-a-Creative-Co-Pilot-in-Photoshop-default.aspx/default.aspx)), ([blog](https://blog.adobe.com/en/publish/2023/05/23/photoshop-new-features-ai-contextual-presets)) |
| 5.23 | QLoRA: Efficient Finetuning of Quantized LLMs ([:x:](https://arxiv.org/abs/2305.14314)), ([:paperclip:](https://arxiv.org/pdf/2305.14314.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14314)), ([:house:](https://huggingface.co/papers/2305.14314)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/qlora-efficient-finetuning-of-quantized-llms)), ([:octocat:](https://github.com/artidoro/qlora)![GitHub Repo stars](https://img.shields.io/github/stars/artidoro/qlora?style=social)) |
| 5.22 | Large-language-model-based 10-year risk prediction of cardiovascular disease: insight from the UK biobank data ([medRxiv](https://www.medrxiv.org/content/10.1101/2023.05.22.23289842v1)), ([SS](https://www.semanticscholar.org/paper/Large-language-model-based-10-year-risk-prediction-Han-Kim/8f7d91fb227a1578f520df23b9d2e105ab30395f)) |
| 5.22 | SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization Evaluation ([:x:](https://arxiv.org/abs/2305.13194)), ([:paperclip:](https://arxiv.org/pdf/2305.13194.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13194)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/seahorse-a-multilingual-multifaceted-dataset)) |
| 5.22 | Meta-in-context learning in large language models  ([:x:](https://arxiv.org/abs/2305.12907)), ([:paperclip:](https://arxiv.org/pdf/2305.12907.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.12907)), ([:house:](https://huggingface.co/papers/2305.12647)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/meta-in-context-learning-in-large-language)) |
| 5.22 | AudioToken: Adaptation of Text-Conditioned Diffusion Models for Audio-to-Image Generation ([:x:](https://arxiv.org/abs/2305.13050)), ([:paperclip:](https://arxiv.org/pdf/2305.13050.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13050)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/audiotoken-adaptation-of-text-conditioned-1)), ([:octocat:](https://github.com/guyyariv/AudioToken)![GitHub Repo stars](https://img.shields.io/github/stars/guyyariv/AudioToken?style=social)) |
| 5.22 | Iterative Forward Tuning Boosts In-context Learning in Language Models  ([:x:](https://arxiv.org/abs/2305.13016)), ([:paperclip:](https://arxiv.org/pdf/2305.13016.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13016)), ([:house:](https://huggingface.co/papers/2305.13016)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/iterative-forward-tuning-boosts-in-context)) |
| 5.22 | How Language Model Hallucinations Can Snowball  ([:x:](https://arxiv.org/abs/2305.13534)), ([:paperclip:](https://arxiv.org/pdf/2305.13534.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13534)), ([:house:](https://huggingface.co/papers/2305.13534)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/how-language-model-hallucinations-can)), ([demo](https://huggingface.co/spaces/huybery/deep-thinking)) |
| 5.22 | Intel Announces Aurora genAI, Generative AI Model With 1 Trillion Parameters ([news](https://wccftech.com/intel-aurora-genai-chatgpt-competitor-generative-ai-model-with-1-trillion-parameters/)), ([Intel newsroom](https://www.intel.com/content/www/us/en/newsroom/news/intel-delivers-ai-accelerated-hpc-performance.html#gs.ymzdf9)) |
| 5.22 | Introducing Mind-Video ([Tweet](https://twitter.com/ZijiaoC/status/1660470518569639937)), ([demo](https://mind-video.com/)), ([data](https://drive.google.com/drive/folders/1swYQD-69phlJUz4_HmdM0RFk_7okLK4v)) |
| 5.22 | Reflective Linguistic Programming (RLP): A Stepping Stone in Socially-Aware AGI (SocialAGI) ([:x:](https://arxiv.org/abs/2305.12647)), ([:paperclip:](https://arxiv.org/pdf/2305.12647.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.12647)), ([:house:](https://huggingface.co/papers/2305.12647)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/reflective-linguistic-programming-rlp-a)) |
| 5.22 | GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints ([:x:](https://arxiv.org/abs/2305.13245)), ([:paperclip:](https://arxiv.org/pdf/2305.13245.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13245)), ([:house:](https://huggingface.co/papers/2305.13245)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/gqa-training-generalized-multi-query)) |
| 5.22 | LM vs LM: Detecting Factual Errors via Cross Examination ([:x:](https://arxiv.org/abs/2305.13281)), ([:paperclip:](https://arxiv.org/pdf/2305.13281.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13281)), ([:house:](https://huggingface.co/papers/2305.13281)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/lm-vs-lm-detecting-factual-errors-via-cross)) |
| 5.22 | XTREME-UP: A User-Centric Scarce-Data Benchmark for Under-Represented Languages ([:paperclip:](https://storage.googleapis.com/xtreme-up/xtreme-up.pdf)), ([:octocat:](https://github.com/google-research/xtreme-up)![GitHub Repo stars](https://img.shields.io/github/stars/google-research/xtreme-up?style=social)) |
| 5.22 | VideoLLM: Modeling Video Sequence with Large Language Models ([:x:](https://arxiv.org/abs/2305.13292)), ([:paperclip:](https://arxiv.org/pdf/2305.13292.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13292)), ([:house:](https://huggingface.co/papers/2305.13292)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/videollm-modeling-video-sequence-with-large)) |
| 5.22 | RecurrentGPT: Interactive Generation of (Arbitrarily) Long Text ([:x:](https://arxiv.org/abs/2305.13304)), ([:paperclip:](https://arxiv.org/pdf/2305.13304.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13304)), ([:house:](https://huggingface.co/papers/2305.13304)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/recurrentgpt-interactive-generation-of)) |
| 5.22 | RWKV: Reinventing RNNs for the Transformer Era  ([:x:](https://arxiv.org/abs/2305.13048)), ([:paperclip:](https://arxiv.org/pdf/2305.13048.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13048)), ([:house:](https://huggingface.co/papers/2305.13048)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/rwkv-reinventing-rnns-for-the-transformer-era)) |
| 5.22 | Introducing speech-to-text, text-to-speech, and more for 1,100+ languages ([Blog](https://ai.facebook.com/blog/multilingual-model-speech-recognition/)), ([:paperclip:](https://scontent-nrt1-1.xx.fbcdn.net/v/t39.8562-6/348836647_265923086001014_6878005808275791319_n.pdf?_nc_cat=104&ccb=1-7&_nc_sid=ae5e01&_nc_ohc=5exJiCqt0Y4AX-_7kQa&_nc_ht=scontent-nrt1-1.xx&oh=00_AfApkDyQVBqv7V82fFveVwLv3AC7KxmOR1FegeXQkrsPiQ&oe=6471ACCF)), ([:octocat:](https://github.com/facebookresearch/fairseq/tree/main/examples/mms)) | 
| 5.21 | Embracing Large Language Models for Medical Applications: Opportunities and Challenges ([abstract](https://www.cureus.com/articles/149797-embracing-large-language-models-for-medical-applications-opportunities-and-challenges#!/)), ([SS](https://www.semanticscholar.org/paper/Embracing-Large-Language-Models-for-Medical-and-Karabacak-Margetis/6486f0b6e443cb864639d4a85277d71cf69f78e0)) |
| 5.21 | Augmenting Autotelic Agents with Large Language Models ([:x:](https://arxiv.org/abs/2305.12487)), ([:paperclip:](https://arxiv.org/pdf/2305.12487.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.12487)), ([:house:](https://huggingface.co/papers/2305.12487)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/augmenting-autotelic-agents-with-large)) |
| 5.21 | XrayGPT: Chest Radiographs Summarization using Medical Vision-Language Models ([:octocat:](https://github.com/mbzuai-oryx/XrayGPT)![GitHub Repo stars](https://img.shields.io/github/stars/mbzuai-oryx/XrayGPT?style=social)), ([Video](https://www.youtube.com/watch?v=-zzq7bzbUuY&t=31s)) | 
| 5.20 | G7 Hiroshima Leaders‚Äô Communiqu√© ([statement](https://www.mofa.go.jp/files/100506878.pdf)), ([html](https://www.whitehouse.gov/briefing-room/statements-releases/2023/05/20/g7-hiroshima-leaders-communique/)) |
| 5.20 | G7 calls for developing global technical standards for AI ([news](https://www.reuters.com/world/g7-calls-developing-global-technical-standards-ai-2023-05-20/)) |
| 5.20 | Labour should pledge ¬£11bn to build ‚ÄòBritGPT‚Äô AI, thinktank says ([news](https://www.theguardian.com/technology/2023/may/20/labour-should-pledge-11bn-to-build-britgpt-ai-thinktank-says)) |
| 5.20 | CodeCompose: A Large-Scale Industrial Deployment of AI-assisted Code Authoring ([:x:](https://arxiv.org/abs/2305.12050)), ([:paperclip:](https://arxiv.org/pdf/2305.12050.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.12050)), ([:house:](https://huggingface.co/papers/2305.12050)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/codecompose-a-large-scale-industrial)) |
| 5.19 | A Survey of Safety and Trustworthiness of Large Language Models through the Lens of Verification and Validation ([:x:](https://arxiv.org/abs/2305.11391)), ([:paperclip:](https://arxiv.org/pdf/2305.11391.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11391)), ([:house:](https://huggingface.co/papers/2305.11391)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-survey-of-safety-and-trustworthiness-of)), ([SS](https://www.semanticscholar.org/paper/A-Survey-of-Safety-and-Trustworthiness-of-Large-the-Huang-Ruan/a723e78473c2f6d096b087e38eb31f6e7800b039)) |
| 5.19 | HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models ([:x:](https://arxiv.org/abs/2305.11747)), ([:paperclip:](https://arxiv.org/pdf/2305.11747.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11747)), ([:house:](https://huggingface.co/papers/2305.11747)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/helma-a-large-scale-hallucination-evaluation)), ([:octocat:](https://github.com/RUCAIBox/HaluEval)![GitHub Repo stars](https://img.shields.io/github/stars/RUCAIBox/HaluEval?style=social)) |
| 5.19 | OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models ([:x:](https://arxiv.org/abs/2305.12001)), ([:paperclip:](https://arxiv.org/pdf/2305.12001.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.12001)), ([:house:](https://huggingface.co/papers/2305.12001)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/opt-r-exploring-the-role-of-explanations-in)) |
| 5.19 | Neural Foundations of Mental Simulation: Future Prediction of Latent Representations on Dynamic Scenes ([:x:](https://arxiv.org/abs/2305.11772)), ([:paperclip:](https://arxiv.org/pdf/2305.11772.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11772)), ([:house:](https://huggingface.co/papers/2305.11772)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/neural-foundations-of-mental-simulation)) |
| 5.19 | Clinical Camel: An Open-Source Expert-Level Medical Language Model with Dialogue-Based Knowledge Encoding ([:x:](https://arxiv.org/abs/2305.12031)), ([:paperclip:](https://arxiv.org/pdf/2305.12031.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.12050)), ([:house:](https://huggingface.co/papers/2305.12050)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/codecompose-a-large-scale-industrial)), ([huggingface](https://huggingface.co/wanglab/clinical-camel)), ([:octocat:](https://github.com/bowang-lab/clinical-camel)![GitHub Repo stars](https://img.shields.io/github/stars/bowang-lab/clinical-camel?style=social)) |
| 5.19 | New York City public schools remove ChatGPT ban ([news](https://www.nbcnews.com/tech/chatgpt-ban-dropped-new-york-city-public-schools-rcna85089)) |
| 5.19 | Graphologue: Exploring Large Language Model Responses with Interactive Diagrams ([:x:](https://arxiv.org/abs/2305.11473)), ([:paperclip:](https://arxiv.org/pdf/2305.11473.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11473)), ([:house:](https://huggingface.co/papers/2305.11473)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/graphologue-exploring-large-language-model)) |
| 5.19 | The Inside Story: Towards Better Understanding of Machine Translation Neural Evaluation Metrics ([:x:](https://arxiv.org/abs/2305.11806)), ([:paperclip:](https://arxiv.org/pdf/2305.11806.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11806)), ([:house:](https://huggingface.co/papers/2305.11806)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/the-inside-story-towards-better-understanding)), ([:octocat:](https://github.com/Unbabel/COMET)![GitHub Repo stars](https://img.shields.io/github/stars/Unbabel/COMET?style=social)) |
| 5.19 | HalOmi: A Manually Annotated Benchmark for Multilingual Hallucination and Omission Detection in Machine Translation ([:x:](https://arxiv.org/abs/2305.11746)), ([:paperclip:](https://arxiv.org/pdf/2305.11746.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11746)), ([:house:](https://huggingface.co/papers/2305.11746)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/halomi-a-manually-annotated-benchmark-for)) |
| 5.19 | Characterizing tradeoffs between teaching via language and demonstrations in multi-agent systems ([:x:](https://arxiv.org/abs/2305.11374)), ([:paperclip:](https://arxiv.org/pdf/2305.11374.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11374)), ([:house:](https://huggingface.co/papers/2305.11374)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/characterizing-tradeoffs-between-teaching-via)) |
| 5.19 | TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks ([:x:](https://arxiv.org/abs/2305.11430)), ([:paperclip:](https://arxiv.org/pdf/2305.11430.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11430)), ([:house:](https://huggingface.co/papers/2305.11430)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/teler-a-general-taxonomy-of-llm-prompts-for)) |
| 5.19 | Text2NeRF: Text-Driven 3D Scene Generation with Neural Radiance Fields ([:x:](https://arxiv.org/abs/2305.11588)), ([:paperclip:](https://arxiv.org/pdf/2305.11588.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11588)), ([:house:](https://huggingface.co/papers/2305.11588)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/text2nerf-text-driven-3d-scene-generation)) |
| 5.19 | Chupa: Carving 3D Clothed Humans from Skinned Shape Priors using 2D Diffusion Probabilistic Models ([:x:](https://arxiv.org/abs/2305.11870)), ([:paperclip:](https://arxiv.org/pdf/2305.11870.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11870)), ([:house:](https://huggingface.co/papers/2305.11870)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/chupa-carving-3d-clothed-humans-from-skinned)) |
| 5.19 | Comparing Software Developers with ChatGPT: An Empirical Investigation ([:x:](https://arxiv.org/abs/2305.11837)), ([:paperclip:](https://arxiv.org/pdf/2305.11837.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11837)), ([:house:](https://huggingface.co/papers/2305.11837)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/comparing-software-developers-with-chatgpt-an)) |
| 5.19 | CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing ([:x:](https://arxiv.org/abs/2305.11738)), ([:paperclip:](https://arxiv.org/pdf/2305.11738.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11738)), ([:house:](https://huggingface.co/papers/2305.11738)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/critic-large-language-models-can-self-correct)), ([:octocat:](https://github.com/microsoft/ProphetNet)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/ProphetNet?style=social)) |
| 5.19 | Multimodal Web Navigation with Instruction-Finetuned Foundation Models ([:x:](https://arxiv.org/abs/2305.11854)), ([:paperclip:](https://arxiv.org/pdf/2305.11854.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11854)), ([:house:](https://huggingface.co/papers/2305.11854)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/multimodal-web-navigation-with-instruction)) |
| 5.19 | Cinematic Mindscapes: High-quality Video Reconstruction from Brain Activity ([:x:](https://arxiv.org/abs/2305.11675)), ([:paperclip:](https://arxiv.org/pdf/2305.11675.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11675)), ([:house:](https://huggingface.co/papers/2305.11675)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/cinematic-mindscapes-high-quality-video)) | 
| 5.19 | Scaling laws for language encoding models in fMRI ([:x:](https://arxiv.org/abs/2305.11863)), ([:paperclip:](https://arxiv.org/pdf/2305.11863.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11863)), ([:house:](https://huggingface.co/papers/2305.11863)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/scaling-laws-for-language-encoding-models-in)) | 
| 5.19 | Any-to-Any Generation via Composable Diffusion ([:x:](https://arxiv.org/abs/2305.11846)), ([:paperclip:](https://arxiv.org/pdf/2305.11846.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11846)), ([:house:](https://huggingface.co/papers/2305.11846)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/any-to-any-generation-via-composable)), ([:octocat:](https://github.com/microsoft/i-Code/tree/main/i-Code-V3)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/i-Code?style=social)) |
| 5.19 | ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings ([:x:](https://arxiv.org/abs/2305.11554)), ([:paperclip:](https://arxiv.org/pdf/2305.11554.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11554)), ([:house:](https://huggingface.co/papers/2305.11554)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/toolkengpt-augmenting-frozen-language-models)) |
| 5.19 | Apple Bans Employees From Using ChatGPT Amid Its Own AI Efforts ([news](https://www.macrumors.com/2023/05/19/apple-bans-employees-from-using-chatgpt/)) |
| 5.18 | A Framework for Critically Assessing ChatGPT and Other Large Language Artificial Intelligence Model Applications in Health Care ([https://doi.org/10.1016/j.mcpdig.2023.03.006](https://www.mcpdigitalhealth.org/article/S2949-7612(23)00022-6/fulltext)) |
| 5.18 | Brain-inspired learning in artificial neural networks: a review ([:x:](https://arxiv.org/abs/2305.11252)), ([:paperclip:](https://arxiv.org/pdf/2305.11252.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11252)), ([:house:](https://huggingface.co/papers/2305.11252)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/brain-inspired-learning-in-artificial-neural)) |
| 5.18 | ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities ([:x:](https://arxiv.org/abs/2305.11172)), ([:paperclip:](https://arxiv.org/pdf/2305.11172.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11172)), ([:house:](https://huggingface.co/papers/2305.11337)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/one-peace-exploring-one-general)) |
| 5.18 | RoomDreamer: Text-Driven 3D Indoor Scene Synthesis with Coherent Geometry and Texture  ([:x:](https://arxiv.org/abs/2305.11337)), ([:paperclip:](https://arxiv.org/pdf/2305.11337.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11337)), ([:house:](https://huggingface.co/papers/2305.11337)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/roomdreamer-text-driven-3d-indoor-scene)) |
| 5.18 | LIMA: Less Is More for Alignment ([:x:](https://arxiv.org/abs/2305.11206)), ([:paperclip:](https://arxiv.org/pdf/2305.11206.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11206)), ([:house:](https://huggingface.co/papers/2305.11206)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/lima-less-is-more-for-alignment)) |
| 5.18 | GETMusic: Generating Any Music Tracks with a Unified Representation and Diffusion Framework ([:x:](https://arxiv.org/abs/2305.10841)), ([:paperclip:](https://arxiv.org/pdf/2305.10841.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10841)), ([:house:](https://huggingface.co/papers/2305.10841)), ([project page](https://ai-muzic.github.io/getmusic/)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/getmusic-generating-any-music-tracks-with-a)), ([:octocat:](https://github.com/microsoft/muzic)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/muzic?style=social)), ([Star history](https://star-history.com/#microsoft/muzic&Date)) |
| 5.18 | SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities ([:x:](https://arxiv.org/abs/2305.11000)), ([:paperclip:](https://arxiv.org/pdf/2305.11000.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11000)), ([:house:](https://huggingface.co/papers/2305.11000)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/speechgpt-empowering-large-language-models)) |
| 5.18 | mLongT5: A Multilingual and Efficient Text-To-Text Transformer for Longer Sequences ([:x:](https://arxiv.org/abs/2305.11129)), ([:paperclip:](https://arxiv.org/pdf/2305.11129.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11129)), ([:house:](https://huggingface.co/papers/2305.11129)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/mlongt5-a-multilingual-and-efficient-text-to)) |
| 5.18 | Language Models Meet World Models: Embodied Experiences Enhance Language Models  ([:x:](https://arxiv.org/abs/2305.10626)), ([:paperclip:](https://arxiv.org/pdf/2305.10626.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10626)), ([:house:](https://huggingface.co/papers/2305.10626)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/language-models-meet-world-models-embodied)) |
| 5.18 | Roundhill Investments Launches Generative AI & Technology ETF (NYSE Arca: CHAT) ([news](https://www.prnewswire.com/news-releases/roundhill-investments-launches-generative-ai--technology-etf-nyse-arca-chat-301828049.html)), ([CHAT ETF](https://www.marketwatch.com/investing/fund/chat)) |
| 5.18 | VisionLLM: Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks ([:x:](https://arxiv.org/abs/2305.11175)), ([:paperclip:](https://arxiv.org/pdf/2305.11175.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11175)), ([:house:](https://huggingface.co/papers/2305.11175)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/visionllm-large-language-model-is-also-an)) |
| 5.18 | Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold ([:x:](https://arxiv.org/abs/2305.10973)), ([:paperclip:](https://arxiv.org/pdf/2305.10973.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10973)), ([:house:](https://huggingface.co/papers/2305.10973)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/drag-your-gan-interactive-point-based)), ([Huggingfae](https://huggingface.co/spaces/radames/UserControllableLT-Latent-Transformer)), ([Unofficial](https://github.com/Zeqiang-Lai/DragGAN)![GitHub Repo stars](https://img.shields.io/github/stars/Zeqiang-Lai/DragGAN?style=social)), ([colab](https://colab.research.google.com/github/Zeqiang-Lai/DragGAN/blob/master/colab.ipynb)), ([Official](https://github.com/XingangPan/DragGAN)![GitHub Repo stars](https://img.shields.io/github/stars/XingangPan/DragGAN?style=social)) |
| 5.18 | PyLLMs - a minimal Python library to connect to LLMs (OpenAI, Anthropic, Google, AI21, Cohere, Aleph Alpha, HuggingfaceHub) ([:octocat:](https://github.com/kagisearch/pyllms)![GitHub Repo stars](https://img.shields.io/github/stars/kagisearch/pyllms?style=social))
| 5.18 | Evidence of Meaning in Language Models Trained on Programs ([:x:](https://arxiv.org/abs/2305.11169)), ([:paperclip:](https://arxiv.org/pdf/2305.11169.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11169)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/evidence-of-meaning-in-language-models)) |
| 5.18 | Introducing the ChatGPT app for iOS ([blog](https://openai.com/blog/introducing-the-chatgpt-app-for-ios)), ([Download on the App Stor](https://apps.apple.com/app/openai-chatgpt/id6448311069)) |
| 5.18 | MTIA v1: Meta‚Äôs first-generation AI inference accelerator ([blog](https://ai.facebook.com/blog/meta-training-inference-accelerator-AI-MTIA/)) |
| 5.18 | Pursuing groundbreaking scale and accelerating research using Meta‚Äôs Research SuperCluster ([blog](https://ai.facebook.com/blog/supercomputer-meta-research-supercluster-2023/)) |
| 5.18 | Reimagining Meta‚Äôs infrastructure for the AI age ([blog](https://ai.facebook.com/blog/meta-ai-infrastructure-overview/)) |
| 5.17 | Evaluating Object Hallucination in Large Vision-Language Models ([:x:](https://arxiv.org/abs/2305.10355)), ([:paperclip:](https://arxiv.org/pdf/2305.10355.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10355)), ([:house:](https://huggingface.co/papers/2305.10355)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/evaluating-object-hallucination-in-large)) |
| 5.17 | Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models ([:x:](https://arxiv.org/abs/2305.10276)), ([:paperclip:](https://arxiv.org/pdf/2305.10276.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10276)), ([:house:](https://huggingface.co/papers/2305.10276)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/chain-of-symbol-prompting-elicits-planning-in)) |
| 5.17 | DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining ([:x:](https://arxiv.org/abs/2305.10429)), ([:paperclip:](https://arxiv.org/pdf/2305.10429.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10429)), ([:house:](https://huggingface.co/papers/2305.10429)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/doremi-optimizing-data-mixtures-speeds-up)) |
| 5.17 | Explaining black box text modules in natural language with language models ([:x:](https://arxiv.org/abs/2305.09863)), ([:paperclip:](https://arxiv.org/pdf/2305.09863.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.09863)), ([:house:](https://huggingface.co/papers/2305.09863)), ([project page](https://ai-muzic.github.io/getmusic/)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/explaining-black-box-text-modules-in-natural) |
| 5.17 | Tree of Thoughts: Deliberate Problem Solving with Large Language Models ([:x:](https://arxiv.org/abs/2305.10601)), ([:paperclip:](https://arxiv.org/pdf/2305.10601.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10601)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/tree-of-thoughts-deliberate-problem-solving)) |
| 5.17 | Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback  ([:x:](https://arxiv.org/abs/2305.10142)), ([:paperclip:](https://arxiv.org/pdf/2305.10142.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10142)), ([:eight_spoked_asterisk:](https://paperswithcode.com/search?q_meta=&q_type=&q=%09Improving%20Language%20Model%20Negotiation%20with%20Self-Play%20and%20In-Context%20Learning%20from%20AI%20Feedback)) |
| 5.17 | PMC-VQA: Visual Instruction Tuning for Medical Visual Question Answering ([:x:](https://arxiv.org/abs/2305.10415)), ([:paperclip:](https://arxiv.org/pdf/2305.10415.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10415)), ([:trophy:papers with code](https://paperswithcode.com/paper/pmc-vqa-visual-instruction-tuning-for-medical)) |
| 5.17 | What You See is What You Read? Improving Text-Image Alignment Evaluation ([:x:](https://arxiv.org/abs/2305.10400)), ([:paperclip:](https://arxiv.org/pdf/2305.10400.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10400)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/what-you-see-is-what-you-read-improving-text)) |
| 5.17 | PaLM 2 Technical Report  ([:x:](https://arxiv.org/abs/2305.10403)), ([:paperclip:](https://arxiv.org/pdf/2305.10403.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10403)), ([:trophy:papers with code](https://paperswithcode.com/paper/palm-2-technical-report)) |
| 5.17 | Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback ([:x:](https://arxiv.org/abs/2305.10142)), ([:paperclip:](https://arxiv.org/pdf/2305.10142.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10142)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/improving-language-model-negotiation-with)) |
| 5.17 | SoundStorm: Efficient Parallel Audio Generation ([:x:](https://arxiv.org/abs/2305.09636)), ([:paperclip:](https://arxiv.org/pdf/2305.09636.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.09636)), ([Project page](https://google-research.github.io/seanet/soundstorm/examples/)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/soundstorm-efficient-parallel-audio)) | 
| 5.16 | GPT-4 in Radiology: Improvements in Advanced Reasoning (RSNA Radiology, [https://doi.org/10.1148/radiol.230987](https://pubs.rsna.org/doi/10.1148/radiol.230987)) |
| 5.16 | Performance of ChatGPT on a Radiology Board-style Examination: Insights into Current Strengths and Limitations (RSNA Radiology, [https://doi.org/10.1148/radiol.230582](https://pubs.rsna.org/doi/10.1148/radiol.230582)) |
| 5.16 | AR-Diffusion: Auto-Regressive Diffusion Model for Text Generation ([:x:](https://arxiv.org/abs/2305.09515)), ([:paperclip:](https://arxiv.org/pdf/2305.09515.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.09515)) |
| 5.16 | Make-An-Animation: Large-Scale Text-conditional 3D Human Motion Generation ([:x:](https://arxiv.org/abs/2305.09662)), ([:paperclip:](https://arxiv.org/pdf/2305.09662.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.09662)) |
| 5.16 | ChatGPT versus human in generating medical graduate exam questions ‚Äì An international prospective study ([medRxiv](https://www.medrxiv.org/content/10.1101/2023.05.13.23289943v1)), ([:paperclip:](https://www.medrxiv.org/content/10.1101/2023.05.13.23289943v1.full.pdf)) |
| 5.16 | Understanding 3D Object Interaction from a Single Image ([:x:](https://arxiv.org/abs/2305.09664)), ([:paperclip:](https://arxiv.org/pdf/2305.09664.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.09664)), ([project page](https://jasonqsy.github.io/3DOI/)), ([demo](https://huggingface.co/spaces/shengyi-qian/3DOI)), ([video](https://www.youtube.com/watch?v=YDIL93XxHyk)), ([:octocat:](https://github.com/JasonQSY/3DOI)) |
| 5.16 | StructGPT: A General Framework for Large Language Model to Reason over Structured Data ([:x:](https://arxiv.org/abs/2305.09645)), ([:paperclip:](https://arxiv.org/pdf/2305.09645.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.09645)), ([:eight_spoked_asterisk:](https://paperswithcode.com/search?q_meta=&q_type=&q=%09StructGPT%3A%20A%20General%20Framework%20for%20Large%20Language%20Model%20to%20Reason%20over%20Structured%20Data)) |
| 5.16 | FitMe: Deep Photorealistic 3D Morphable Model Avatars ([:x:](https://arxiv.org/abs/2305.09641)), ([:paperclip:](https://arxiv.org/pdf/2305.09641.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.09641)), ([project page](https://alexlattas.com/fitme)) |
| 5.16 | Pre-Training to Learn in Context ([:x:](https://arxiv.org/abs/2305.09137)), ([:paperclip:](https://arxiv.org/pdf/2305.09137.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.09137)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/pre-training-to-learn-in-context)) |
| 5.16 | Towards Expert-Level Medical Question Answering with Large Language Models ([:x:](https://arxiv.org/abs/2305.09617)), ([:paperclip:](https://arxiv.org/pdf/2305.09617.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.09617)), ([:trophy:papers with code](https://paperswithcode.com/paper/towards-expert-level-medical-question)) |
| 5.16 | GPTeam: Collaborative AI Agents  ([:octocat:](https://github.com/101dotxyz/GPTeam)![GitHub Repo stars](https://img.shields.io/github/stars/101dotxyz/GPTeam?style=social)) |
| 5.16 | WATCH LIVE: OpenAI CEO Sam Altman testifies on artificial intelligence before Senate committee ([Youtube](https://www.youtube.com/watch?v=P_ACcQxJIsg)) |
| 5.16 | NYT - [Microsoft Says New A.I. Shows Signs of Human Reasoning](https://www.nytimes.com/2023/05/16/technology/microsoft-ai-human-reasoning.html) | 
| 5.15 | Common Diffusion Noise Schedules and Sample Steps are Flawed ([:x:](https://arxiv.org/abs/2305.08891)), ([:paperclip:](https://arxiv.org/pdf/2305.08891.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.08891)) |
| 5.15 | Symbol tuning improves in-context learning in language models ([:x:](https://arxiv.org/abs/2305.08298)), ([:paperclip:](https://arxiv.org/pdf/2305.08298.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.08298)) |
| 5.15 | Interpretability at Scale: Identifying Causal Mechanisms in Alpaca ([:x:](https://arxiv.org/abs/2305.08809)), ([:paperclip:](https://arxiv.org/pdf/2305.08809.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.08809)) |
| 5.15 | DarkBERT: A Language Model for the Dark Side of the Internet ([:x:](https://arxiv.org/abs/2305.08596)), ([:paperclip:](https://arxiv.org/pdf/2305.08596.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.08596)) | 
| 5.15 | AutoRecon: Automated 3D Object Discovery and Reconstruction ([:x:](https://arxiv.org/abs/2305.08810)), ([:paperclip:](https://arxiv.org/pdf/2305.08810.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.08810)), ([Project page](https://zju3dv.github.io/autorecon/)) | 
| 5.15 | RL4F: Generating Natural Language Feedback with Reinforcement Learning for Repairing Model Outputs ([:x:](https://arxiv.org/abs/2305.08844)), ([:paperclip:](https://arxiv.org/pdf/2305.08844.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.08844)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/rl4f-generating-natural-language-feedback)) | 
| 5.15 | Small Models are Valuable Plug-ins for Large Language Models ([:x:](https://arxiv.org/abs/2305.08848)), ([:paperclip:](https://arxiv.org/pdf/2305.08848.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.08848)) | 
| 5.15 | "ChatGPT can pick stocks better then top fund managers" - The ChatGPT Fund - ([tweet](https://twitter.com/chatgpttrader/status/1658193474708213760)), ([website](https://www.thechatgptfund.com/)) |
| 5.15 | officially launching the Poe API - ([Tweet](https://twitter.com/adamdangelo/status/1658121701077516291), ([:octocat:](https://github.com/poe-platform)): ([poe-protocol](https://github.com/poe-platform/poe-protocol)![GitHub Repo stars](https://img.shields.io/github/stars/poe-platform/poe-protocol?style=social)), ([api-bot-tutorial](https://github.com/poe-platform/api-bot-tutorial)![GitHub Repo stars](https://img.shields.io/github/stars/poe-platform/api-bot-tutorial?style=social)) | |
| 5.15 | Guidance - A guidance language for controlling large language models ([:octocat:](https://github.com/microsoft/guidance)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/guidance?style=social)) |
| 5.15 | BriefGPT - Locally hosted tool that connects documents to LLMs for summarization and querying, with a simple GUI ([:octocat:](https://github.com/e-johnstonn/BriefGPT)![GitHub Repo stars](https://img.shields.io/github/stars/e-johnstonn/BriefGPT?style=social)) |
| 5.15 | I‚Äôm an ER doctor. Here‚Äôs how I‚Äôm already using ChatGPT to help treat patients ([blog](https://www.fastcompany.com/90895618/how-a-doctor-uses-chat-gpt-to-treat-patients)) |
| 5.14 | A Comprehensive Survey on Segment Anything Model for Vision and Beyond ([:x:](https://arxiv.org/abs/2305.08196)), ([:paperclip:](https://arxiv.org/pdf/2305.08196.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.08196)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-comprehensive-survey-on-segment-anything)), ([:octocat:](https://github.com/liliu-avril/Awesome-Segment-Anything)![GitHub Repo stars](https://img.shields.io/github/stars/liliu-avril/Awesome-Segment-Anything?style=social)) |
| 5.14 | How to run Llama 13B with a 6GB graphics card ([Gist](https://gist.github.com/rain-1/8cc12b4b334052a21af8029aa9c4fafc)) |
| 5.13 | Leaked Copilot Chat's confidential rules ([tweet](https://twitter.com/marvinvonhagen/status/1657060506371346432)) |
| 5.13 | GPT-Sentinel: Distinguishing Human and ChatGPT Generated Content (arXiv](https://arxiv.org/abs/2305.07969)), ([:paperclip:](https://arxiv.org/pdf/2305.07969.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07969)) |
| 5.13 | Everything-LLMs-And-Robotics - The world's largest GitHub Repository for LLMs + Robotics ([:octocat:](https://github.com/jrin771/Everything-LLMs-And-Robotics)![GitHub Repo stars](https://img.shields.io/github/stars/jrin771/Everything-LLMs-And-Robotics?style=social)) | 
| 5.13 | CodeT5+: Open Code Large Language Models for Code Understanding and Generation ([:x:](https://arxiv.org/abs/2305.07922)), ([:paperclip:](https://arxiv.org/pdf/2305.07922.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07922)), ([:octocat:](https://github.com/salesforce/CodeT5/tree/main/CodeT5%2B)![GitHub Repo stars](https://img.shields.io/github/stars/salesforce/CodeT5?style=social)), ([:trophy:papers with code](https://paperswithcode.com/paper/codet5-open-code-large-language-models-for)) |
| 5.13 | EU AI Act To Target US Open Source Software ([Blog](https://technomancers.ai/eu-ai-act-to-target-us-open-source-software/#more-561)) |
| 5.13 | PCAST Working Group on Generative AI Invites Public Input ([Blog](https://terrytao.wordpress.com/2023/05/13/pcast-working-group-on-generative-ai-invites-public-input/)) | 
| 5.12 | A Survey on Segment Anything Model (SAM): Vision Foundation Model Meets Prompt Engineering ([:x:](https://arxiv.org/abs/2305.06211)), ([:paperclip:](https://arxiv.org/pdf/2305.06211.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06211)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-survey-on-segment-anything-model-sam-vision)) |
| 5.12 | spacy-llm, an extension for integrating LLMs into structured NLP pipelines! ([:octocat:](https://github.com/explosion/spacy-llm)![GitHub Repo stars](https://img.shields.io/github/stars/explosion/spacy-llm?style=social)), ([tweet](https://twitter.com/spacy_io/status/1656734286425255937)) |
| 5.12 | TinyStories: How Small Can Language Models Be and Still Speak Coherent English? ([:x:](https://arxiv.org/abs/2305.07759)), ([:paperclip:](https://arxiv.org/pdf/2305.07759.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07759)) | 
| 5.12 | Dr. LLaMA: Improving Small Language Models in Domain-Specific QA via Generative Data Augmentation  ([:x:](https://arxiv.org/abs/2305.07804)), ([:paperclip:](https://arxiv.org/pdf/2305.07804.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07804)), ([model](https://huggingface.co/Tyrannosaurus/ArtGPT-4)), ([:octocat:](https://github.com/zguo0525/Dr.llama)![GitHub Repo stars](https://img.shields.io/github/stars/zguo0525/Dr.llama?style=social))  |
| 5.12 | ArtGPT-4: Artistic Vision-Language Understanding with Adapter-enhanced MiniGPT-4 ([:x:](https://arxiv.org/abs/2305.07490)), ([:paperclip:](https://arxiv.org/pdf/2305.07490.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07490)), ([model](https://huggingface.co/Tyrannosaurus/ArtGPT-4)) |
| 5.12 | MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers ([:x:](https://arxiv.org/abs/2305.07185)), ([:paperclip:](https://arxiv.org/pdf/2305.07185.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07185)) |
| 5.12 | AI FILM -The Carnival of the Ages - Runway gen2 ([Youtube](https://www.youtube.com/watch?v=q0EDV1HGbrc)), ([Reddit](https://www.reddit.com/r/aivideo/comments/13eh1rq/carnival_of_ages_text_to_video_runway_gen2/)) | 
| 5.11 | The ConceptARC Benchmark: Evaluating Understanding and Generalization in the ARC Domain ([:x:](https://arxiv.org/abs/2305.07141)), ([:paperclip:](https://arxiv.org/pdf/2305.07141.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07141)), ([:house:](https://huggingface.co/papers/2305.07141)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/the-conceptarc-benchmark-evaluating)), ([:octocat:](https://github.com/victorvikram/conceptarc)![GitHub Repo stars](https://img.shields.io/github/stars/victorvikram/conceptarc?style=social)) |
| 5.11 | Large Language Models Can Be Used To Effectively Scale Spear Phishing Campaigns ([:x:](https://arxiv.org/abs/2305.06972)), ([:paperclip:](https://arxiv.org/pdf/2305.06972.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06972)) |
| 5.11 | Towards best practices in AGI safety and governance: A survey of expert opinion ([:x:](https://arxiv.org/abs/2305.07153)), ([:paperclip:](https://arxiv.org/pdf/2305.07153.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07153)) |
| 5.11 | Optimizing Memory Mapping Using Deep Reinforcement Learning ([:x:](https://arxiv.org/abs/2305.07440)), ([:paperclip:](https://arxiv.org/pdf/2305.07440.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07440)) |
| 5.11 | Universal Source Separation with Weakly Labelled Data ([:x:](https://arxiv.org/abs/2305.07447)), ([:paperclip:](https://arxiv.org/pdf/2305.07447.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07447)), ([:octocat:](https://github.com/bytedance/uss)![GitHub Repo stars](https://img.shields.io/github/stars/bytedance/uss?style=social)) |
| 5.11 | Active Retrieval Augmented Generation  ([:x:](https://arxiv.org/abs/2305.06983)), ([:paperclip:](https://arxiv.org/pdf/2305.06983.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06983)), ([:octocat:](https://github.com/jzbjyb/FLARE)![GitHub Repo stars](https://img.shields.io/github/stars/jzbjyb/FLARE?style=social)) |
| 5.11 | Anthropic - Introducing 100K Context Windows ([Blog](https://www.anthropic.com/index/100k-context-windows)) |
| 5.11 | CoMoSpeech: One-Step Speech and Singing Voice Synthesis via Consistency Model ([:x:](https://arxiv.org/abs/2305.06908)), ([:paperclip:](https://arxiv.org/pdf/2305.06908.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06908)) |
| 5.11 | Exploiting Diffusion Prior for Real-World Image Super-Resolution ([:x:](https://arxiv.org/abs/2305.07015)), ([:paperclip:](https://arxiv.org/pdf/2305.07015.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07015)), ([Project page](https://iceclear.github.io/projects/stablesr/)) |
| 5.11 | Domain Incremental Lifelong Learning in an Open World ([:x:](https://arxiv.org/abs/2305.06555)), ([:paperclip:](https://arxiv.org/pdf/2305.06555.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06555)) |
| 5.11 | Not All Languages Are Created Equal in LLMs: Improving Multilingual Capability by Cross-Lingual-Thought Prompting ([:x:](https://arxiv.org/abs/2305.07004)), ([:paperclip:](https://arxiv.org/pdf/2305.07004.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07004)) |
| 5.11 | Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers ([:x:](https://arxiv.org/abs/2305.07011)), ([:paperclip:](https://arxiv.org/pdf/2305.07011.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07011)) |
| 5.11 | EfficientViT: Memory Efficient Vision Transformer with Cascaded Group Attention ([:x:](https://arxiv.org/abs/2305.07027)), ([:paperclip:](https://arxiv.org/pdf/2305.07027.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07027)), ([:octocat:](https://github.com/microsoft/Cream/tree/main/EfficientViT)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/Cream?style=social)) |
| 5.11 | InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning ([:x:](https://arxiv.org/abs/2305.06500)), ([:paperclip:](https://arxiv.org/pdf/2305.06500.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06500)), ([:octocat:](https://github.com/salesforce/LAVIS/tree/main/projects/instructblip)![GitHub Repo stars](https://img.shields.io/github/stars/salesforce/LAVIS?style=social)) |
| 5.11 | Huggingface Transformers Agent ([API](https://huggingface.co/docs/transformers/transformers_agents)) |
| 5.11 | Google PaLM 2 Technical Report ([:paperclip:](https://ai.google/static/documents/palm2techreport.pdf)), ([Blog](https://ai.google/discover/palm2)) |
| 5.11 | Google MusicLM ([Demo](https://aitestkitchen.withgoogle.com/experiments/music-lm)), ([news](https://techcrunch.com/2023/05/10/google-makes-its-text-to-music-ai-public/)) |
| 5.10 | LMFlow Benchmark: An Automatic Evaluation Framework for Open-Source LLMs ([blog](https://blog.gopenai.com/lmflow-benchmark-an-automatic-evaluation-framework-for-open-source-llms-ef5c6f142418)) | 
| 5.10 | Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text Analytics? An Examination on Several Typical Tasks ([:x:](https://arxiv.org/abs/2305.05862)), ([:paperclip:](https://arxiv.org/pdf/2305.05862.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.05862)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/are-chatgpt-and-gpt-4-general-purpose-solvers)) |
| 5.10 | HumanRF: High-Fidelity Neural Radiance Fields for Humans in Motion ([:x:](https://arxiv.org/abs/2305.06356)), ([:paperclip:](https://arxiv.org/pdf/2305.06356.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06356)) |
| 5.10 | VideoChat: Chat-Centric Video Understanding ([:x:](https://arxiv.org/abs/2305.06355)), ([:paperclip:](https://arxiv.org/pdf/2305.06355.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06355)) |
| 5.10 | Bot or Human? Detecting ChatGPT Imposters with A Single Question ([:x:](https://arxiv.org/abs/2305.06424)), ([:paperclip:](https://arxiv.org/pdf/2305.06424.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06424)) |
| 5.10 | Do LLMs Understand User Preferences? Evaluating LLMs On User Rating Prediction ([:x:](https://arxiv.org/abs/2305.06474)), ([:paperclip:](https://arxiv.org/pdf/2305.06474.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06474)) |
| 5.10 | Relightify: Relightable 3D Faces from a Single Image via Diffusion Models ([:x:](https://arxiv.org/abs/2305.06077)), ([:paperclip:](https://arxiv.org/pdf/2305.06077.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06077)) |
| 5.10 | Similarity of Neural Network Models: A Survey of Functional and Representational Measures ([:x:](https://arxiv.org/abs/2305.06329)), ([:paperclip:](https://arxiv.org/pdf/2305.06329.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06329)) |
| 5.10 | Generative AI meets 3D: A Survey on Text-to-3D in AIGC Era  ([:x:](https://arxiv.org/abs/2305.06131)), ([:paperclip:](https://arxiv.org/pdf/2305.06131.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06131)) |
| 5.10 | MPT-7B StoryWriter- new open-source language model that can handle really long inputs ([Replicate](https://replicate.com/replicate/mpt-7b-storywriter)) |
| 5.10 | [Humata.ai](https://www.humata.ai/) - Ask AI anything about your files ([Tweet](https://twitter.com/hasantoxr/status/1655963736149045249)) |
| 5.10 | IMAGEBIND: One Embedding Space To Bind Them All ([:paperclip:](https://dl.fbaipublicfiles.com/imagebind/imagebind_final.pdf)), ([Blog](https://ai.facebook.com/blog/imagebind-six-modalities-binding-ai/)), ([:octocat:](https://github.com/facebookresearch/ImageBind)![GitHub Repo stars](https://img.shields.io/github/stars/facebookresearch/ImageBind?style=social)), ([:trophy:papers with code](https://paperswithcode.com/paper/imagebind-one-embedding-space-to-bind-them)), ([star history](https://star-history.com/#facebookresearch/ImageBind&Date)) |
| 5.9 | StarCoder: may the source be with you! ([:x:](https://arxiv.org/abs/2305.06161)), ([:paperclip:](https://arxiv.org/pdf/2305.06161.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06161)), ([:house:](https://huggingface.co/papers/2305.06161)) |
| 5.9 | Towards Building the Federated GPT: Federated Instruction Tuning ([:x:](https://arxiv.org/abs/2305.05644)), ([:paperclip:](https://arxiv.org/pdf/2305.05644.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.05644)), ([:octocat:](https://github.com/JayZhang42/FederatedGPT-Shepherd)![GitHub Repo stars](https://img.shields.io/github/stars/JayZhang42/FederatedGPT-Shepherd?style=social)) |
| 5.9 | Large Language Model Programs ([:x:](https://arxiv.org/abs/2305.05364)), ([:paperclip:](https://arxiv.org/pdf/2305.05364.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.05364)) |
| 5.9 | FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance ([:x:](https://arxiv.org/abs/2305.05176)), ([:paperclip:](https://arxiv.org/pdf/2305.05176.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.05176)) |
| 5.9 | OpenAI - Language models can explain neurons in language models ([Blog](https://openai.com/research/language-models-can-explain-neurons-in-language-models)), ([Paper](https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html)), ([:octocat:](https://github.com/openai/automated-interpretability)![GitHub Repo stars](https://img.shields.io/github/stars/openai/automated-interpretability?style=social)), ([Tweet](https://twitter.com/OpenAI/status/1655982364273831936)) |
| 5.9 | AvatarReX: Real-time Expressive Full-body Avatars ([:x:](https://arxiv.org/abs/2305.04789)), ([:paperclip:](https://arxiv.org/pdf/2305.04789.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.04789)) | 
| 5.8 | Augmented Large Language Models with Parametric Knowledge Guiding ([:x:](https://arxiv.org/abs/2305.04789)), ([:paperclip:](https://arxiv.org/pdf/2305.04789.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.04789)) | 
| 5.8 | We had ChatGPT take the CPA exam ‚Äî and it failed ([news](https://www.accountingtoday.com/news/we-ran-the-cpa-exam-through-chatgpt-and-it-failed-miserably)) |
| 5.8 | Comparison of GPT-3.5, GPT-4, and human user performance on a practice ophthalmology written examination ([Nature](https://www.nature.com/articles/s41433-023-02564-2)) |
| 5.8 | MultiModal-GPT: A Vision and Language Model for Dialogue with Humans  ([:x:](https://arxiv.org/abs/2305.04790)), ([:paperclip:](https://arxiv.org/pdf/2305.04790.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.04790)), ([:octocat:](https://github.com/open-mmlab/Multimodal-GPT)![GitHub Repo stars](https://img.shields.io/github/stars/open-mmlab/Multimodal-GPT?style=social)), ([:house:](https://huggingface.co/papers/2305.04790)), ([Star history](https://star-history.com/#open-mmlab/Multimodal-GPT&Date)) |
| 5.7 | SuperAgent - Deploy LLM Agents to production ([:octocat:](https://github.com/homanp/superagent)![GitHub Repo stars](https://img.shields.io/github/stars/homanp/superagent?style=social)) |
| 5.7 | Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models ([:x:](https://arxiv.org/abs/2305.04091)), ([:paperclip:](https://arxiv.org/pdf/2305.04091.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.04091)), ([:octocat:](https://github.com/AGI-Edgerunners/Plan-and-Solve-Prompting)![GitHub Repo stars](https://img.shields.io/github/stars/AGI-Edgerunners/Plan-and-Solve-Prompting?style=social)) |
| 5.7 | X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages ([:x:](https://arxiv.org/abs/2305.04160)), ([:paperclip:](https://arxiv.org/pdf/2305.04160.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.04160)) |
| 5.7 | Multi-Space Neural Radiance Fields ([:x:](https://arxiv.org/abs/2305.04268)), ([:paperclip:](https://arxiv.org/pdf/2305.04268.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.04268)), ([Project page](https://zx-yin.github.io/msnerf/)), ([Dataset](https://drive.google.com/drive/folders/1gqmonTlR8LbJkljtT28S47N_o_YoExFz)) |
| 5.7 | Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting ([:x:](https://arxiv.org/abs/2305.04388)), ([:paperclip:](https://arxiv.org/pdf/2305.04388.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.04388)) |
| 5.7 | Yoshua Bengio - AI Scientists: Safe and Useful AI? ([Blog](https://yoshuabengio.org/2023/05/07/ai-scientists-safe-and-useful-ai/)) |
| 5.5 | privateGPT - Interact privately with your documents using the power of GPT, 100% privately, no data leaks ([:octocat:](https://github.com/imartinez/privateGPT)![GitHub Repo stars](https://img.shields.io/github/stars/imartinez/privateGPT?style=social)), ([star history](https://star-history.com/#imartinez/privateGPT&Date)) |
| 5.5 | Open LLMs : A list of open LLMs available for commercial use - ([:octocat:](https://github.com/eugeneyan/open-llms)![GitHub Repo stars](https://img.shields.io/github/stars/eugeneyan/open-llms?style=social)) |
| 5.5 | A Suite of Generative Tasks for Multi-Level Multimodal Webpage Understanding ([:x:](https://arxiv.org/abs/2305.03668)), ([:paperclip:](https://arxiv.org/pdf/2305.03668.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.03668)), ([:house:](https://huggingface.co/papers/2305.03668)) |
| 5.5 | Otter: A Multi-Modal Model with In-Context Instruction Tuning  ([:x:](https://arxiv.org/abs/2305.03726)), ([:paperclip:](https://arxiv.org/pdf/2305.03726.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.03726)), ([:octocat:](https://github.com/Luodian/Otter)![GitHub Repo stars](https://img.shields.io/github/stars/Luodian/Otter?style=social)), ([:house:](https://huggingface.co/papers/2305.03726)) |
| 5.5 | Composite Motion Learning with Task Control ([:x:](https://arxiv.org/abs/2305.03286)), ([:paperclip:](https://arxiv.org/pdf/2305.03286.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.03286)), ([:octocat:](https://github.com/xupei0610/CompositeMotion)![GitHub Repo stars](https://img.shields.io/github/stars/xupei0610/CompositeMotion?style=social)), ([Papper page](https://huggingface.co/papers/2305.03286)) |
| 5.5 | StarCoderBase: trained on 1T tokens in 80+ programming languages ([Huggingface](https://huggingface.co/bigcode/starcoderbase)) |
| 5.5 | Dolphin: General video interaction platform based on LLMs ([Demo](https://da2c48f45ee053ef87.gradio.live/)), ([:octocat:](https://github.com/kaleido-lab/dolphin)![GitHub Repo stars](https://img.shields.io/github/stars/kaleido-lab/dolphin?style=social)), ([Tweet](https://twitter.com/_akhaliq)) | 
| 5.5 | MPT-7B: A New Standard for Open-Source, Commercially Usable LLMs ([Blog](https://www.mosaicml.com/blog/mpt-7b)), Commercially usable: ([MPT-7B](https://huggingface.co/mosaicml/mpt-7b))  ([MPT-7B-Instruct](https://huggingface.co/mosaicml/mpt-7b-instruct)), ([MPT-7B-StoryWriter](https://huggingface.co/mosaicml/mpt-7b-storywriter)), For non-commerical use: ([MPT-7B-Chat](https://huggingface.co/mosaicml/mpt-7b-chat)) |
| 5.5 | StarCoder: A State-of-the-Art LLM for Code ([Blog](https://huggingface.co/blog/starcoder)), ([:octocat:](https://github.com/bigcode-project/starcoder/)![GitHub Repo stars](https://img.shields.io/github/stars/bigcode-project/starcoder?style=social)), ([HuggingFace](https://huggingface.co/bigcode/starcoder)), ([Tweet](https://twitter.com/BigCodeProject/status/1654174941976068119)) |
| 5.5 | OpenAlpaca, an instruction-following model based on OpenLLaMA ([:octocat:](https://github.com/openlm-research/open_llama)![GitHub Repo stars](https://img.shields.io/github/stars/openlm-research/open_llama?style=social)), ([Huggingface](https://huggingface.co/openlm-research/open_llama_7b_preview_200bt)), ([Tweet](https://twitter.com/yixuan_su/status/1654234602003636226)) |
| 5.4 | Seeing is Believing: Brain-Inspired Modular Training for Mechanistic Interpretability  ([:x:](https://arxiv.org/abs/2305.08746)), ([:paperclip:](https://arxiv.org/pdf/2305.08746.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.08746)), ([:octocat:](https://github.com/KindXiaoming/BIMT)(https://img.shields.io/github/stars/KindXiaoming/BIMT?style=social)), ([demo](https://colab.research.google.com/drive/1hggc5Tae97BORVNdesLcwp9og3SmPtM7?usp=sharing)), ([Papper page](https://huggingface.co/papers/2305.08746)) |
| 5.4 | Evaluating the Performance of ChatGPT in Ophthalmology: An Analysis of its Successes and Shortcomings ([Ophthalmology Science](https://www.ophthalmologyscience.org/article/S2666-9145(23)00056-8/fulltext)) | 
| 5.4 | Cognitive Reframing of Negative Thoughts through Human-Language Model Interaction ([:x:](https://arxiv.org/abs/2305.02466)), ([:paperclip:](https://arxiv.org/pdf/2305.02466.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.02466)) |
| 5.4 | Governance of the AI, by the AI, and for the AI ([:x:](https://arxiv.org/abs/2305.03719)), ([:paperclip:](https://arxiv.org/pdf/2305.03719.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.03719)), ([Papper page](https://huggingface.co/papers/2305.03719)) |
| 5.4 | Can LLM Already Serve as A Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs  ([:x:](https://arxiv.org/abs/2305.03111)), ([:paperclip:](https://arxiv.org/pdf/2305.03111.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.03111)) |
| 5.4 | Diffusion Explainer: Visual Explanation for Text-to-image Stable Diffusion ([:x:](https://arxiv.org/abs/2305.03509)), ([:paperclip:](https://arxiv.org/pdf/2305.03509.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.03509)), ([Papper page](https://huggingface.co/papers/2305.03509)) |
| 5.4 | AttentionViz: A Global View of Transformer Attention ([:x:](https://arxiv.org/abs/2305.03210)), ([:paperclip:](https://arxiv.org/pdf/2305.03210.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.03210)), ([Papper page](https://huggingface.co/papers/2305.03210)) |
| 5.4 | Reddit - [OpenAI lost $540M in 2022, will need $100B more to develop AGI, says Altman. My breakdown on why this matters and what it means for other AI startups](https://www.reddit.com/r/ChatGPT/comments/1383obf/openai_lost_540m_in_2022_will_need_100b_more_to/) |
| 5.4 | FACT SHEET: Biden-‚Å†Harris Administration Announces New Actions to Promote Responsible AI Innovation that Protects Americans‚Äô Rights and Safety - ([White house](https://www.whitehouse.gov/briefing-room/statements-releases/2023/05/04/fact-sheet-biden-harris-administration-announces-new-actions-to-promote-responsible-ai-innovation-that-protects-americans-rights-and-safety/)) |
| 5.4 | Google "We Have No Moat, And Neither Does OpenAI" - ([Blog](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither)) |
| 5.4 | CNBC - [Britain launches probe into ChatGPT-style A.I. as regulators grow concerned by risks](https://www.cnbc.com/2023/05/04/chatgpt-britain-launches-competition-probe-into-ai-consumer-risks.html?utm_content=Main&utm_medium=Social&utm_source=Twitter) |
| 5.4 | Personalize Segment Anything Model with One Shot ([:x:](https://arxiv.org/abs/2305.03048)), ([:paperclip:](https://arxiv.org/pdf/2305.03048.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.03048)), ([:octocat:](https://github.com/ZrrSkywalker/Personalize-SAM)![GitHub Repo stars](https://img.shields.io/github/stars/ZrrSkywalker/Personalize-SAM?style=social)), ([:house:](https://huggingface.co/papers/2305.03048)) |
| 5.4 | AutoML-GPT: Automatic Machine Learning with GPT ([:x:](https://arxiv.org/abs/2305.02499)), ([:paperclip:](https://arxiv.org/pdf/2305.02499.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.02499)), ([:house:](https://huggingface.co/papers/2305.02499)) |
| 5.4 | NeRSemble: Multi-view Radiance Field Reconstruction of Human Heads ([:x:](https://arxiv.org/abs/2305.03027)), ([:paperclip:](https://arxiv.org/pdf/2305.03027.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.03027), ([Project page](https://tobias-kirschstein.github.io/nersemble/)), ([:house:](https://huggingface.co/papers/2305.03027)) |
| 5.4 | An automatically discovered chain-of-thought prompt generalizes to novel models and datasets ([:x:](https://arxiv.org/abs/2305.02897)), ([:paperclip:](https://arxiv.org/pdf/2305.02897.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.02897))
| 5.4 | NYT - [White House Pushes Tech C.E.O.s to Limit Risks of A.I.](https://www.nytimes.com/2023/05/04/technology/us-ai-research-regulation.html) |
| 5.4 | Microsoft Bing AI chatbot and Edge browser get massive AI upgrades. See the list. ([Blog](https://mashable.com/article/microsoft-bing-ai-chatbot-edge-browser-new-updates-features)) |
| 5.4 | Introducing Slack GPT ([Blog](https://slack.com/intl/ko-kr/blog/news/introducing-slack-gpt)) |
| 5.3 | Distinguishing GPT-4-generated Radiology Abstracts from Original Abstracts: Performance of Blinded Human Observers and AI Content Detector ([medRxiv](https://www.medrxiv.org/content/10.1101/2023.04.28.23289283v1)), ([:paperclip:](https://www.medrxiv.org/content/10.1101/2023.04.28.23289283v1.full.pdf)) |
| 5.3 | Chatbot Arena: Benchmarking LLMs in the Wild with Elo Ratings - ([Blog](https://lmsys.org/blog/2023-05-03-arena/)) |
| 5.3 | CodeGen2: Lessons for Training LLMs on Programming and Natural Languages ([:x:](https://arxiv.org/abs/2305.02309)), ([:paperclip:](https://arxiv.org/pdf/2305.02309.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.02309)), ([:octocat:](https://github.com/salesforce/CodeGen2)![GitHub Repo stars](https://img.shields.io/github/stars/salesforce/CodeGen2?style=social)) |
| 5.3 | Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes ([:x:](https://arxiv.org/abs/2305.02301)), ([:paperclip:](https://arxiv.org/pdf/2305.02301.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.02301)) |
| 5.3 | Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings ([:x:](https://arxiv.org/abs/2305.02317)), ([:paperclip:](https://arxiv.org/pdf/2305.02317.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.02317)) |
| 5.3 | AG3D: Learning to Generate 3D Avatars from 2D Image Collections ([:x:](https://arxiv.org/abs/2305.02312)), ([:paperclip:](https://arxiv.org/pdf/2305.02312.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.02312)), ([Project page](https://zj-dong.github.io/AG3D/)) |
| 5.3 | Shap-E: Generating Conditional 3D Implicit Functions ([:x:](https://arxiv.org/abs/2305.02463)), ([:paperclip:](https://arxiv.org/pdf/2305.02463.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.02463)), ([:octocat:](https://github.com/openai/shap-e)![GitHub Repo stars](https://img.shields.io/github/stars/openai/shap-e?style=social)), ([:house:](https://huggingface.co/papers/2305.02463)) |
| 5.3 | 100 Practical Applications and Use Cases of Generative AI - ([:paperclip:](https://ai.gov.ae/wp-content/uploads/2023/04/406.-Generative-AI-Guide_ver1-EN.pdf)), ([News](https://gulfnews.com/uae/uae-government-launches-guide-on-generative-ai-applications-such-as-chatgpt-1.95449467)) |  
| 5.3 | Comprehensive LLM model zoo - Ecosystem Graphs to track the foundation model ecosystem assets (datasets, models, and applications) and their relationship ([Table](https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=table)), ([Graph](https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=graph)), ([:octocat:](https://github.com/stanford-crfm/ecosystem-graphs)![GitHub Repo stars](https://img.shields.io/github/stars/stanford-crfm/ecosystem-graphs?style=social)) |
| 5.3 | GPTutor: a ChatGPT-powered programming tool for code explanation ([:x:](https://arxiv.org/abs/2305.01863)), ([:paperclip:](https://arxiv.org/pdf/2305.01863.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.01863)) |
| 5.3 | Midjourney 5.1 Arrives - And It‚Äôs Another Leap Forward For AI Art - ([Forbes](https://www.forbes.com/sites/barrycollins/2023/05/03/midjourney-51-arrivesand-its-another-leap-forward-for-ai-art/)) |
| 5.3 | Mojo üî• ‚Äî a new programming language for all AI developers ([Web](https://www.modular.com/mojo)), ([tweet](https://twitter.com/Modular_AI/status/1653436642248781825)), ([:octocat:](https://github.com/modularml/mojo)![GitHub Repo stars](https://img.shields.io/github/stars/modularml/mojo?style=social)) |
| 5.3 | #NeurIPS2023 Creative AI Track ([Blog](https://blog.neurips.cc/2023/05/02/call-for-neurips-creative-ai-track/)), ([Call for proposal](https://neurips.cc/Conferences/2023/CallForCreativeAI)) |
| 5.3 | [HeyPi](https://heypi.com/) - Personal AI |
| 5.2 | RadAdapt: Radiology Report Summarization via Lightweight Domain Adaptation of Large Language Models ([:x:](https://arxiv.org/abs/2305.01146)), ([:paperclip:](https://arxiv.org/pdf/2305.01146.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.01146)), ([:house:](https://huggingface.co/papers/2305.01146)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/radadapt-radiology-report-summarization-via)) |
| 5.2 | Interpretable Machine Learning for Science with PySR and SymbolicRegression.jl ([:x:](https://arxiv.org/abs/2305.01582)), ([:paperclip:](https://arxiv.org/pdf/2305.01582.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.01582)) |
| 5.2 | Andrew Ng - ChatGPT Prompt Engineering for Developers - ([online course](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)), ([Tweet](https://twitter.com/AndrewYNg/status/1653141408386260992)) |
| 5.2 | DreamPaint: Few-Shot Inpainting of E-Commerce Items for Virtual Try-On without 3D Modeling ([:x:](https://arxiv.org/abs/2305.01649)), ([:paperclip:](https://arxiv.org/pdf/2305.01649.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.01649)) |
| 5.2 | Generalizing Dataset Distillation via Deep Generative Prior ([:x:](https://arxiv.org/abs/2305.01257)), ([:paperclip:](https://arxiv.org/pdf/2305.01257.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.01257)) |
| 5.2 | Multimodal Procedural Planning via Dual Text-Image Prompting ([:x:](https://arxiv.org/abs/2305.01795)), ([:paperclip:](https://arxiv.org/pdf/2305.01795.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.01795)), ([:octocat:](https://github.com/YujieLu10/TIP)![GitHub Repo stars](https://img.shields.io/github/stars/YujieLu10/TIP?style=social)) |
| 5.2 | WSJ - [Google DeepMind CEO Says Some Form of AGI Possible in a Few Years](https://www.wsj.com/articles/google-deepmind-ceo-says-some-form-of-agi-possible-in-a-few-years-2705f452) |
| 5.2 | Latest NVIDIA Graphics Research Advances Generative AI‚Äôs Next Frontier ([Blog](https://blogs.nvidia.com/blog/2023/05/02/graphics-research-advances-generative-ai-next-frontier/)) |
| 5.2 | Pick-a-Pic: An Open Dataset of User Preferences for Text-to-Image Generation ([:x:](https://arxiv.org/abs/2305.01569)), ([:paperclip:](https://arxiv.org/pdf/2305.01569.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.01569)), ([:octocat:](https://github.com/yuvalkirstain/pickscore)![GitHub Repo stars](https://img.shields.io/github/stars/yuvalkirstain/pickscore?style=social)) |
| 5.2 | TMR: Text-to-Motion Retrieval Using Contrastive 3D Human Motion Synthesis ([:x:](https://arxiv.org/abs/2305.00976)), ([:paperclip:](https://arxiv.org/pdf/2305.00976.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.00976)), ([Project page](https://t.co/KH4w0442YP)), ([Demo](https://huggingface.co/spaces/Mathux/TMR)) |
| 5.2 | Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation ([:x:](https://arxiv.org/abs/2305.01210)), ([:paperclip:](https://arxiv.org/pdf/2305.01210.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.01210)), ([:octocat:](https://github.com/evalplus/evalplus)![GitHub Repo stars](https://img.shields.io/github/stars/evalplus/evalplus?style=social)) |
| 5.2 | Unlimiformer: Long-Range Transformers with Unlimited Length Input ([:x:](https://arxiv.org/abs/2305.01625)), ([:paperclip:](https://arxiv.org/pdf/2305.01625.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.01625)) |
| 5.2 | Bark - Text-Prompted Generative Audio Model ([:octocat:](https://github.com/suno-ai/bark)![GitHub Repo stars](https://img.shields.io/github/stars/suno-ai/bark?style=social)) |
| 5.2 | Jsonformer: A Bulletproof Way to Generate Structured JSON from Language Models ([:octocat:](https://github.com/1rgs/jsonformer)![GitHub Repo stars](https://img.shields.io/github/stars/1rgs/jsonformer?style=social)) |
| 5.1 | scGPT: Towards Building a Foundation Model for Single-Cell Multi-omics Using Generative AI ([bioXiv](https://www.biorxiv.org/content/10.1101/2023.04.30.538439v1)), ([:paperclip:](https://www.biorxiv.org/content/10.1101/2023.04.30.538439v1.full.pdf)) |
| 5.1 | The Guardian - [AI makes non-invasive mind-reading possible by turning thoughts into text](https://www.theguardian.com/technology/2023/may/01/ai-makes-non-invasive-mind-reading-possible-by-turning-thoughts-into-text) |
| 5.1 | Learning to Reason and Memorize with Self-Notes ([:x:](https://arxiv.org/abs/2305.00833)), ([:paperclip:](https://arxiv.org/pdf/2305.00833.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.00833)) |
| 5.1 | Poisoning Language Models During Instruction Tuning ([:x:](https://arxiv.org/abs/2305.00944)), ([:paperclip:](https://arxiv.org/pdf/2305.00944.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.00944)) |
| 5.1 | What Do Self-Supervised Vision Transformers Learn? ([:x:](https://arxiv.org/abs/2305.00729)), ([:paperclip:](https://arxiv.org/pdf/2305.00729.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.00729)) |
| 5.1 | [NYT](https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html) - ‚ÄòThe Godfather of A.I.‚Äô Leaves Google and Warns of Danger Ahead ([Archive](https://archive.is/TgPyC#selection-331.0-331.63)) |
| 4.30 | ChatGPT: Is this version good for healthcare and research? - ([ScienceDirect](https://www.sciencedirect.com/science/article/abs/pii/S1871402123000401)) |
| 4.30 | Understanding Parameter-Efficient LLM Finetuning: Prompt Tuning And Prefix Tuning ([Blog](https://magazine.sebastianraschka.com/p/understanding-parameter-efficient)) |
| 4.30 | A brief history of LLaMA models ([Blog](https://agi-sphere.com/llama-models/)) |
| 4.30 | BabyBeeAGI: Task Management and Functionality Expansion on top of BabyAGI ([blog](https://yoheinakajima.com/babybeeagi-task-management-and-functionality-expansion-on-top-of-babyagi/)), ([Replit](https://replit.com/@YoheiNakajima/BabyBeeAGI?v=1)), ([:octocat:](https://github.com/yoheinakajima/babyagi)![GitHub Repo stars](https://img.shields.io/github/stars/yoheinakajima/babyagi?style=social)), ([OG BaybyAGI](https://replit.com/@YoheiNakajima/babyagi)) |
| 4.30 | Results of G7 Digital and Tech Ministers‚Äô Meeting in Takasaki, Gunma - ([Summary](https://g7digital-tech-2023.go.jp/en/topics/topics_20230430.html)), ([Declaration](https://g7digital-tech-2023.go.jp/topics/pdf/pdf_20230430/ministerial_declaration_dtmm.pdf)), ([Annex1](https://g7digital-tech-2023.go.jp/topics/pdf/pdf_20230430/annex1.pdf)), ([Annex2](https://g7digital-tech-2023.go.jp/topics/pdf/pdf_20230430/annex2.pdf)), ([Annex3](https://g7digital-tech-2023.go.jp/topics/pdf/pdf_20230430/annex3.pdf)), ([Annex4](https://g7digital-tech-2023.go.jp/topics/pdf/pdf_20230430/annex4.pdf)), ([Annex5](https://g7digital-tech-2023.go.jp/topics/pdf/pdf_20230430/annex5.pdf)) |
| 4.30 | PandaLM: Reproducible and Automated Language Model Assessment ([:octocat:](https://github.com/WeOpenML/PandaLM)![GitHub Repo stars](https://img.shields.io/github/stars/WeOpenML/PandaLM?style=social)) |
| 4.29 | Can ChatGPT Pass An Introductory Level Functional Language Programming Course? ([:x:](https://arxiv.org/abs/2305.02230)), ([:paperclip:](https://arxiv.org/pdf/2305.02230.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.02230)) |
| 4.29 | A Review of ChatGPT Applications in Education, Marketing, Software Engineering, and Healthcare: Benefits, Drawbacks, and Research Directions ([:x:](https://arxiv.org/abs/2305.00237)), ([:paperclip:](https://arxiv.org/pdf/2305.00237.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.00237)) |
| 4.29 | ChatGPT-2D, which can generate mind maps with AI - ([Tweet](https://twitter.com/eyishazyer/status/1652215468005146626)), ([ChatGPT-2D](https://superusapp.com/chatgpt2d/)) |
| 4.29 | MLC LLM - an open framework that brings language models (LLMs) directly into a broad class of platforms (CUDA, Vulkan, Metal) with GPU acceleration ([Tweet](https://twitter.com/bohanhou1998/status/1652151502012837890)), ([Demo](https://mlc.ai/mlc-llm/)), ([:octocat:](https://github.com/mlc-ai/mlc-llm)![GitHub Repo stars](https://img.shields.io/github/stars/mlc-ai/mlc-llm?style=social)) |
| 4.29 | GenOs Index - The April (aka the Frenetic Pace) Edition - ([blog](https://www.decibel.vc/articles/genos-index-the-april-aka-the-frenetic-pace-edition)) |
| 4.29 | StableVicuna, the AI World‚Äôs First Open Source RLHF LLM Chatbot! - ([Blog](https://stability.ai/blog/stablevicuna-open-source-rlhf-chatbot)), ([Tweet](https://twitter.com/StabilityAI/status/1652026192193785856)) |
| 4.29 | DeepFloyd - a state-of-the-art text-to-image model ([Web](https://deepfloyd.ai/deepfloyd-if)), ([:octocat:](https://github.com/deep-floyd/IF)![GitHub Repo stars](https://img.shields.io/github/stars/deep-floyd/IF?style=social)), ([HuggingFace demo](https://huggingface.co/spaces/DeepFloyd/IF)), ([Tweet](https://twitter.com/deepfloydai/status/1651983493717532673)) |
| 4.29 | When Patient Questions Are Answered With Higher Quality and Empathy by ChatGPT than Physicians - ([Blog](https://erictopol.substack.com/p/when-patient-questions-are-answered)) |
| 4.29 | BMTools - Tool Learning for Big Models, Open-Source Solutions of ChatGPT-Plugins ([:octocat:](https://github.com/openbmb/bmtools)) |
| 4.29 | FastChat-T5 ([:octocat:](https://github.com/lm-sys/FastChat#FastChat-T5)![GitHub Repo stars](https://img.shields.io/github/stars/lm-sys/FastChat#FastChat-T5?style=social)), ([Tweet](https://twitter.com/lmsysorg/status/1652037026705985537)) |
| 4.29 | Lamini, the LLM Engine for Rapidly Customizing Models - ([Blog](https://lamini.ai/blog/introducing-lamini)) |
| 4.28 | SAM on Medical Images: A Comprehensive Study on Three Prompt Modes ([:x:](https://arxiv.org/abs/2305.00035)), ([:paperclip:](https://arxiv.org/pdf/2305.00035.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.00035)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/sam-on-medical-images-a-comprehensive-study)) |
| 4.28 | EU proposes new copyright rules for generative AI - ([Reuter](https://www.reuters.com/technology/eu-lawmakers-committee-reaches-deal-artificial-intelligence-act-2023-04-27/)), ([Economic times](https://www.reuters.com/technology/eu-lawmakers-committee-reaches-deal-artificial-intelligence-act-2023-04-27/)) | 
| 4.28 | PROMPTENGINEERING FORCHATGPTA QUICKGUIDE TOTECHNIQUES, TIPS,ANDBESTPRACTICES - ([:paperclip:](https://www.techrxiv.org/articles/preprint/Prompt_Engineering_For_ChatGPT_A_Quick_Guide_To_Techniques_Tips_And_Best_Practices/22683919)) |
| 4.28 | ResiDual: Transformer with Dual Residual Connections ([:x:](https://arxiv.org/abs/2304.14802)), ([:paperclip:](https://arxiv.org/pdf/2304.14802.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.14802)), ([:octocat:](https://github.com/microsoft/ResiDual)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/ResiDual?style=social)) |
| 4.28 | Causal Reasoning and Large Language Models: Opening a New Frontier for Causality ([:x:](https://arxiv.org/abs/2305.00050)), ([:paperclip:](https://arxiv.org/pdf/2305.00050.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.00050)) |
| 4.28 | We Interviewed the Engineer Google Fired for Saying Its AI Had Come to Life ([Futurism](https://futurism.com/blake-lemoine-google-interview)) |
| 4.28 | LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model ([:x:](https://arxiv.org/abs/2304.15010)), ([:paperclip:](https://arxiv.org/pdf/2304.15010.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.15010)), ([:octocat:](https://github.com/ZrrSkywalker/LLaMA-Adapter)![GitHub Repo stars](https://img.shields.io/github/stars/ZrrSkywalker/LLaMA-Adapter?style=social)) |
| 4.28 | MLCopilot: Unleashing the Power of Large Language Models in Solving Machine Learning Tasks ([:x:](https://arxiv.org/abs/2304.14979)), ([:paperclip:](https://arxiv.org/pdf/2304.14979.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.14979)) |
| 4.28 | Are Emergent Abilities of Large Language Models a Mirage? ([:x:](https://arxiv.org/abs/2304.15004)), ([:paperclip:](https://arxiv.org/pdf/2304.15004.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.15004)) |
| 4.28 | The Ultimate Battle of Language Models: Lit-LLaMA vs GPT3.5 vs Bloom vs ‚Ä¶. ([Blog](https://lightning.ai/pages/community/community-discussions/the-ultimate-battle-of-language-models-lit-llama-vs-gpt3.5-vs-bloom-vs/)) |
| 4.28 | Otter, a multi-modal in-context learning model with instruction tuning - ([:octocat:](https://github.com/Luodian/otter)![GitHub Repo stars](https://img.shields.io/github/stars/Luodian/otter?style=social)), ([Demo](https://otter.cliangyu.com/)), ([Youtube](https://www.youtube.com/watch?v=r-YM4DGGAdE)) |
| 4.28 | [Economist](https://www.economist.com/by-invitation/2023/04/28/yuval-noah-harari-argues-that-ai-has-hacked-the-operating-system-of-human-civilisation) - Yuval Noah Harari argues that AI has hacked the operating system of human civilisation ([Archive](https://archive.is/HGRsq#selection-1039.0-1039.86)) |
| 4.28 | Assessing the Potential of USMLE-Like Exam Questions Generated by GPT-4 ([medRxiv](https://www.medrxiv.org/content/10.1101/2023.04.25.23288588v1)), ([:paperclip:](https://www.medrxiv.org/content/10.1101/2023.04.25.23288588v1.full.pdf)) |
| 4.28 | JAMA - Comparing Physician and Artificial Intelligence Chatbot Responses to Patient Questions Posted to a Public Social Media Forum - ([paper](https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2804309?guestAccessKey=6d6e7fbf-54c1-49fc-8f5e-ae7ad3e02231&utm_source=For_The_Media&utm_medium=referral&utm_campaign=ftm_links&utm_content=tfl&utm_term=042823)) |
| 4.27 | Ethics of large language models in medicine and medical research (The Lancet, [https://doi.org/10.1016/S2589-7500(23)00083-3](https://www.thelancet.com/journals/landig/article/PIIS2589-7500(23)00083-3/fulltext)), ([PDF](https://www.thelancet.com/action/showPdf?pii=S2589-7500%2823%2900083-3)) |
| 4.27 | ChatGPT as an Attack Tool: Stealthy Textual Backdoor Attack via Blackbox Generative Model Trigger ([:x:](https://arxiv.org/abs/2304.14475)), ([:paperclip:](https://arxiv.org/pdf/2304.14475.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.14475)) |
| 4.27 | PMC-LLaMA: Further Finetuning LLaMA on Medical Papers ([:x:](https://arxiv.org/abs/2304.14454)), ([:paperclip:](https://arxiv.org/pdf/2304.14454.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.14454)), ([:octocat:](https://github.com/chaoyi-wu/PMC-LLaMA)![GitHub Repo stars](https://img.shields.io/github/stars/chaoyi-wu/PMC-LLaMA?style=social)) |
| 4.27 | "Can ChatGPT Diagnose Me?" How Large Language Models will Transform Clinical Care - ([Youtube](https://www.youtube.com/playlist?list=PLe6zdIMe5B7JWokb0Vvket4M3h-0KvBNn)) |
| 4.27 | Large Language Models Are State-of-the-Art Evaluators of Code Generation ([:x:](https://arxiv.org/abs/2304.14317)), ([:paperclip:](https://arxiv.org/pdf/2304.14317.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.14317)) |
| 4.27 | Controlled Text Generation with Natural Language Instructions  ([:x:](https://arxiv.org/abs/2303.14293)), ([:paperclip:](https://arxiv.org/pdf/2303.14293.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.14293)) |
| 4.27 | ‚≠ê A Survey of Large Language Models - version 8 ([:x:](https://arxiv.org/abs/2303.18223)), ([:paperclip:](https://arxiv.org/pdf/2303.18223.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.18223)) |
| 4.27 | LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions ([:x:](https://arxiv.org/abs/2304.14402)), ([:paperclip:](https://arxiv.org/pdf/2304.14402.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.14402)), ([:octocat:]([https://github.com/m](https://github.com/mbzuai-nlp/LaMini-LM)![GitHub Repo stars](https://img.shields.io/github/stars/mbzuai-nlp/LaMini-LM?style=social)) |
| 4.27 | DataComp: In search of the next generation of multimodal datasets ([:x:](https://arxiv.org/abs/2304.14108)), ([:paperclip:](https://arxiv.org/pdf/2304.14108.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.14108)), ([:octocat:](https://github.com/mlfoundations/datacomp)![GitHub Repo stars](https://img.shields.io/github/stars/mlfoundations/datacomp?style=social)), ([Project page](https://www.datacomp.ai/)) |
| 4.27 | We're Afraid Language Models Aren't Modeling Ambiguity ([:x:](https://arxiv.org/abs/2304.14399)), ([:paperclip:](https://arxiv.org/pdf/2304.14399.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.14399)) |
| 4.27 | Boston Dynamics robot dog can answer your questions now, thanks to ChatGPT - ([ZDNet](https://www.zdnet.com/article/boston-dynamics-robot-dog-can-answer-your-questions-now-thanks-to-chatgpt/)), ([YouTube](https://www.youtube.com/watch?v=Y1-s37zrm1M)) |
| 4.27 | LlamaIndex & Deep Lake for Financial Statement Analysis ([Blog](https://medium.com/@jerryjliu98/llamaindex-deep-lake-for-financial-statement-analysis-954f2b789c8e)) |
| 4.26 | Towards Medical Artificial General Intelligence via Knowledge-Enhanced Multimodal Pretraining ([:x:](https://arxiv.org/abs/2304.14204)), ([:paperclip:](https://arxiv.org/pdf/2304.14204.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.14204)),  ([:house:](https://huggingface.co/papers/2304.14204)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/towards-medical-artificial-general)) |
| 4.26 | Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement Learning ([:x:](https://arxiv.org/abs/2304.13653)), ([:paperclip:](https://arxiv.org/pdf/2304.13653.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13653)) |
| 4.26 | Multidimensional Evaluation for Text Style Transfer Using ChatGPT ([:x:](https://arxiv.org/abs/2304.13462)), ([:paperclip:](https://arxiv.org/pdf/2304.13462.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13462)) |
| 4.26 | NPJ - Comparing scientific abstracts generated by ChatGPT to real abstracts with detectors and blinded human reviewers ([Paper](https://www.nature.com/articles/s41746-023-00819-6)), ([:paperclip:](https://www.nature.com/articles/s41746-023-00819-6.pdf)) |
| 4.26 | [TopGPT](https://www.topgpt.io/) ‚Äî the world‚Äôs first Andrew Tate large language model |
| 4.26 | Multi-Party Chat: Conversational Agents in Group Settings with Humans and Models ([:x:](https://arxiv.org/abs/2304.13835)), ([:paperclip:](https://arxiv.org/pdf/2304.13835.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13835)) |
| 4.26 | MOSS, a 16B tool-augmented conversational language model ([Tweet](https://twitter.com/tianxiangsun/status/1650895260493705216)), ([:octocat:](https://github.com/OpenLMLab/MOSS)![GitHub Repo stars](https://img.shields.io/github/stars/OpenLMLab/MOSS?style=social)) |
| 4.26 | Exploring the Curious Case of Code Prompts ([:x:](https://arxiv.org/abs/2304.13250)), ([:paperclip:](https://arxiv.org/pdf/2304.13250.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13250)) |
| 4.26 | Controllable Image Generation via Collage Representations ([:x:](https://arxiv.org/abs/2304.13722)), ([:paperclip:](https://arxiv.org/pdf/2304.13722.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13722)) |
| 4.26 | Unleashing Infinite-Length Input Capacity for Large-scale Language Models with Self-Controlled Memory System ([:x:](https://arxiv.org/abs/2304.13343)), ([:paperclip:](https://arxiv.org/pdf/2304.13343.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13343)) |
| 4.26 | TextDeformer: Geometry Manipulation using Text Guidance ([:x:](https://arxiv.org/abs/2304.13348)), ([:paperclip:](https://arxiv.org/pdf/2304.13348.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13348)) |
| 4.26 | Evaluation of GPT-3.5 and GPT-4 for supporting real-world information needs in healthcare delivery ([:x:](https://arxiv.org/abs/2304.13714)), ([:paperclip:](https://arxiv.org/pdf/2304.13714.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13714)) |
| 4.26 | Ray Conditioning: Trading Photo-consistency for Photo-realism in Multi-view Image Generation ([:x:](https://arxiv.org/abs/2304.13681)), ([:paperclip:](https://arxiv.org/pdf/2304.13681.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13681)), ([Project page](https://ray-cond.github.io/)) |
| 4.26 | Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond ([:x:](https://arxiv.org/abs/2304.13712)), ([:paperclip:](https://arxiv.org/pdf/2304.13712.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13712)), ([:octocat:](https://github.com/Mooler0410/LLMsPracticalGuide)![GitHub Repo stars](https://img.shields.io/github/stars/Mooler0410/LLMsPracticalGuide?style=social)) |
| 4.26 | [HuggingChat](https://huggingface.co/chat/) - the first open source alternative to ChatGPT |
| 4.25 | [Time](https://time.com/6273743/thinking-that-could-doom-us-with-ai/) - The 'Don't Look Up' Thinking That Could Doom Us With AI ([Archive](https://archive.is/gMi8q)) |
| 4.25 | AI-assisted coding: Experiments with GPT-4 ([:x:](https://arxiv.org/abs/2304.13187)), ([:paperclip:](https://arxiv.org/pdf/2304.13187.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13187)) |
| 4.25 | NVIDIA NeMo Guardrails helps enterprises keep applications built on large language models aligned with their safety and security requirements ([Blog](https://blogs.nvidia.com/blog/2023/04/25/ai-chatbot-guardrails-nemo/)), ([:octocat:](https://github.com/NVIDIA/NeMo-Guardrails)![GitHub Repo stars](https://img.shields.io/github/stars/NVIDIA/NeMo-Guardrails?style=social)) |
| 4.25 | Stable and low-precision training for large-scale vision-language models ([:x:](https://arxiv.org/abs/2304.13013)), ([:paperclip:](https://arxiv.org/pdf/2304.13013.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13013)) |
| 4.25 | AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head ([:x:](https://arxiv.org/abs/2304.12995)), ([:paperclip:](https://arxiv.org/pdf/2304.12995.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12995)) |
| 4.25 | Answering Questions by Meta-Reasoning over Multiple Chains of Thought ([:x:](https://arxiv.org/abs/2304.13007)), ([:paperclip:](https://arxiv.org/pdf/2304.13007.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13007)) |
| 4.25 | Patch-based 3D Natural Scene Generation from a Single Example ([:x:](https://arxiv.org/abs/2304.12670)), ([:paperclip:](https://arxiv.org/pdf/2304.12670.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12670)), ([Project page](http://weiyuli.xyz/Sin3DGen/))  |
| 4.25 | Generative AI at Work - ([NBER](https://www.nber.org/papers/w31161)), ([:paperclip:](https://www.nber.org/system/files/working_papers/w31161/w31161.pdf)) | 
| 4.25 | [Chatbot Arena](https://chat.lmsys.org/?arena) |
| 4.24 | Text-to-Audio Generation using Instruction-Tuned LLM and Latent Diffusion Model ([:x:](https://arxiv.org/abs/2304.13731)), ([:paperclip:](https://arxiv.org/pdf/2304.13731.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13731)),([Project page](https://tango-web.github.io/)), ([:octocat:](https://github.com/declare-lab/tango)![GitHub Repo stars](https://img.shields.io/github/stars/declare-lab/tango?style=social)) |
| 4.24 | AI, write an essay for me: A large-scale comparison of human-written versus ChatGPT-generated essays ([:x:](https://arxiv.org/abs/2304.14276)), ([:paperclip:](https://arxiv.org/pdf/2304.14276.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.14276)) |
| 4.24 | Pointersect: Neural Rendering with Cloud-Ray Intersection ([:x:](https://arxiv.org/abs/2304.12390)), ([:paperclip:](https://arxiv.org/pdf/2304.12390.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12390)), ([web](https://machinelearning.apple.com/research/pointersect)) |
| 4.24 | A Cookbook of Self-Supervised Learning  ([:x:](https://arxiv.org/abs/2304.12210)), ([:paperclip:](https://arxiv.org/pdf/2304.12210.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12210)) |
| 4.24 | On the Challenges of Using Black-Box APIs for Toxicity Evaluation in Research ([:x:](https://arxiv.org/abs/2304.12397)), ([:paperclip:](https://arxiv.org/pdf/2304.12397.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12397)), ([:octocat:](https://github.com/for-ai/black-box-api-challenges)![GitHub Repo stars](https://img.shields.io/github/stars/for-ai/black-box-api-challenges?style=social)) |
| 4.24 | Towards Realistic Generative 3D Face Models ([:x:](https://arxiv.org/abs/2304.12483)), ([:paperclip:](https://arxiv.org/pdf/2304.12483.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12483)) |
| 4.24 | TextMesh: Generation of Realistic 3D Meshes From Text Prompts ([:x:](https://arxiv.org/abs/2304.12439)), ([:paperclip:](https://arxiv.org/pdf/2304.12439.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12439)) |
| 4.24 | Benchmarking ChatGPT-4 on ACR Radiation Oncology In-Training Exam (TXIT): Potentials and Challenges for AI-Assisted Medical Education and Decision Making in Radiation Oncology ([:x:](https://arxiv.org/abs/2304.11957)), ([:paperclip:](https://arxiv.org/pdf/2304.11957.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11957)), ([:octocat:](https://github.com/yixinghuang/chatgpt-benchmark-on-radiation-oncology)![GitHub Repo stars](https://img.shields.io/github/stars/yixinghuang/chatgpt-benchmark-on-radiation-oncology?style=social)) |
| 4.24 | Social AGI - SAMANTHA (Self-Reflective Artificial Mind Attuned to Naturalistic Thought and Human Adaptability) ([:octocat:](https://github.com/Methexis-Inc/SocialAGI)![GitHub Repo stars](https://img.shields.io/github/stars/Methexis-Inc/SocialAGI?style=social)) |
| 4.24 | Segment Anything in Medical Images ([:x:](https://arxiv.org/abs/2304.12306)), ([:paperclip:](https://arxiv.org/pdf/2304.12306.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12306)), ([:octocat:](https://github.com/bowang-lab/MedSAM)![GitHub Repo stars](https://img.shields.io/github/stars/bowang-lab/MedSAM?style=social)) |
| 4.24 | Segment Anything in 3D with NeRFs  ([:x:](https://arxiv.org/abs/2304.12308)), ([:paperclip:](https://arxiv.org/pdf/2304.12308.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12308)), ([project page](https://jumpat.github.io/SA3D/)) |
| 4.24 | WizardLM: Empowering Large Language Models to Follow Complex Instructions ([:x:](https://arxiv.org/abs/2304.12244)), ([:paperclip:](https://arxiv.org/pdf/2304.12244.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12244)) |
| 4.24 | Track Anything: Segment Anything Meets Videos ([:x:](https://arxiv.org/abs/2304.11968)), ([:paperclip:](https://arxiv.org/pdf/2304.11968.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11968)) |
| 4.24 | OpenAI Brand guidelines - ([blog](https://openai.com/brand)) |
| 4.24 | GPT4Tools: Teaching LLM to Use Tools via Self-instruction - ([Project page](https://gpt4tools.github.io/)), ([:octocat:](https://github.com/StevenGrove/GPT4Tools)), ([Video](https://www.youtube.com/watch?v=Qrj94ibQIT8)),  |
| 4.24 | RAM: Relate-Anything-Model ([:octocat:](https://github.com/Luodian/RelateAnything)![GitHub Repo stars](https://img.shields.io/github/stars/Luodian/RelateAnything?style=social)), ([Demo](https://huggingface.co/spaces/mmlab-ntu/relate-anything-model)) |
| 4.24 | [Chart-GPT 1.0](https://www.chartgpt.dev/) |
| 4.23 | Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models ([:x:](https://arxiv.org/abs/2304.11657)), ([:paperclip:](https://arxiv.org/pdf/2304.11657.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11657)), ([:octocat:](https://github.com/GasolSun36/Iter-CoT)![GitHub Repo stars](https://img.shields.io/github/stars/GasolSun36/Iter-CoT?style=social)) |
| 4.23 | Evaluating ChatGPT's Information Extraction Capabilities: An Assessment of Performance, Explainability, Calibration, and Faithfulness ([:x:](https://arxiv.org/abs/2304.11633)), ([:paperclip:](https://arxiv.org/pdf/2304.11633.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11633)) |
| 4.22 | Boosting Theory-of-Mind Performance in Large Language Models via Prompting  ([:x:](https://arxiv.org/abs/2304.11490)), ([:paperclip:](https://arxiv.org/pdf/2304.11490.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11490)) |
| 4.22 | LaMP: When Large Language Models Meet Personalization ([:x:](https://arxiv.org/abs/2304.11406)), ([:paperclip:](https://arxiv.org/pdf/2304.11406.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11406)), ([Project page](https://lamp-benchmark.github.io/index.html)), ([Download](https://lamp-benchmark.github.io/download)), ([Leaderboard](https://lamp-benchmark.github.io/leaderboard)), ([:octocat:](https://github.com/LaMP-Benchmark/LaMP)![GitHub Repo stars](https://img.shields.io/github/stars/LaMP-Benchmark/LaMP?style=social)) |
| 4.22 | Finetuning Large Language Models ([Blog](https://magazine.sebastianraschka.com/p/finetuning-large-language-models)) |
| 4.21 | Can GPT-4 Perform Neural Architecture Search? ([:x:](https://arxiv.org/abs/2304.10970)), ([:paperclip:](https://arxiv.org/pdf/2304.10970.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.10970)) |
| 4.21 | Evaluating Transformer Language Models on Arithmetic Operations Using Number Decomposition ([:x:](https://arxiv.org/abs/2304.10977)), ([:paperclip:](https://arxiv.org/pdf/2304.10977.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.10977)) |
| 4.21 | Emergent and Predictable Memorization in Large Language Models  ([:x:](https://arxiv.org/abs/2304.11158)), ([:paperclip:](https://arxiv.org/pdf/2304.11158.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11158)) |
| 4.21 | CLaMP: Contrastive Language-Music Pre-training for Cross-Modal Symbolic Music Information Retrieval  ([:x:](https://arxiv.org/abs/2304.11029)), ([:paperclip:](https://arxiv.org/pdf/2304.11029.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11029)) |
| 4.21 | Bard now helps you code with support for 20+ langs (Python, C++, JS, Go, etc.). ([Blog](https://blog.google/technology/ai/code-with-bard/)) |
| 4.21 | Inducing anxiety in large language models increases exploration and bias ([:x:](https://arxiv.org/abs/2304.11111)), ([:paperclip:](https://arxiv.org/pdf/2304.11111.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11111)) |
| 4.20 | Is ChatGPT a Good Recommender? A Preliminary Study ([:x:](https://arxiv.org/abs/2304.10149)), ([:paperclip:](https://arxiv.org/pdf/2304.10149.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.10149)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/is-chatgpt-a-good-recommender-a-preliminary)) |
| 4.20 | Why Does ChatGPT Fall Short in Answering Questions Faithfully? ([:x:](https://arxiv.org/abs/2304.10513)), ([:paperclip:](https://arxiv.org/pdf/2304.10513.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.10513)) |
| 4.20 | [FinChat.io](https://finchat.io/chats/) - The Chat GPT for Finance |
| 4.20 | LlamaAcademy: Teaching Llamas How to Code ([:octocat:](https://github.com/danielgross/LlamaAcademy)![GitHub Repo stars](https://img.shields.io/github/stars/danielgross/LlamaAcademy?style=social)) |
| 4.20 | Announcing Google DeepMind: DeepMind + Brain = Google DeepMind ([Blog](https://www.deepmind.com/blog/announcing-google-deepmind)) |
| 4.20 | "Can ChatGPT Diagnose Me?" How Large Language Models will Transform Clinical Care. Thursday, April 27th, 2023 ([RSVP](https://aimi.stanford.edu/events/can-chatgpt-diagnose-me-how-large-language-models-will-transform-clinical-care)) |
| 4.20 | StableLM: Stability AI Language Models ([:octocat:](https://github.com/stability-AI/stableLM/)![GitHub Repo stars](https://img.shields.io/github/stars/stability-AI/stableLM?style=social)), ([Blog](https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models)) |
| 4.19 | Large Language Models in Medical Education: Opportunities, Challenges, and Future Directions (JMIR [doi:10.2196/48291](https://mededu.jmir.org/2023/1/e48291)), ([PDF](https://mededu.jmir.org/2023/1/e48291/PDF)) |
| 4.19 | Fundamental Limitations of Alignment in Large Language Models ([:x:](https://arxiv.org/abs/2304.11082)), ([:paperclip:](https://arxiv.org/pdf/2304.11082.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11082)) |
| 4.19 | Scaling Transformer to 1M tokens and beyond with RMT ([:x:](https://arxiv.org/abs/2304.11062)), ([:paperclip:](https://arxiv.org/pdf/2304.11062.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11062)), ([:octocat:](https://github.com/booydar/t5-experiments/tree/scaling-report)) |
| 4.19 | Occupational Heterogeneity in Exposure to Generative AI - ([paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4414065)), ([:paperclip:](https://papers.ssrn.com/sol3/Delivery.cfm/SSRN_ID4414065_code2763040.pdf?abstractid=4414065&mirid=1)) |
| 4.19 | The Unintended Consequences of Censoring Digital Technology -- Evidence from Italy's ChatGPT Ban ([:x:](https://arxiv.org/abs/2304.09339)), ([:paperclip:](https://arxiv.org/pdf/2304.09339.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09339)) |
| 4.19 | CompressGPT: Decrease Token Usage by ~70% ([blog](https://musings.yasyf.com/compressgpt-decrease-token-usage-by-70/)) |
| 4.19 | Language Models Enable Simple Systems for Generating Structured Views of Heterogeneous Data Lakes ([:x:](https://arxiv.org/abs/2304.09433)), ([:paperclip:](https://arxiv.org/pdf/2304.09433.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09433)), ([:octocat:](https://github.com/HazyResearch/evaporate)(https://img.shields.io/github/stars/HazyResearch/evaporate?style=social)) |
| 4.19 | LLM as A Robotic Brain: Unifying Egocentric Memory and Control ([:x:](https://arxiv.org/abs/2304.09349)), ([:paperclip:](https://arxiv.org/pdf/2304.09349.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09349)) |
| 4.19 | Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agent ([:x:](https://arxiv.org/abs/2304.09542)), ([:paperclip:](https://arxiv.org/pdf/2304.09542.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09542)) |
| 4.19 | Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models ([:x:](https://arxiv.org/abs/2304.09842)), ([:paperclip:](https://arxiv.org/pdf/2304.09842.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09842)), ([project page](https://chameleon-llm.github.io/)), ([:octocat:](https://github.com/lupantech/chameleon-llm)![GitHub Repo stars](https://img.shields.io/github/stars/lupantech/chameleon-llm?style=social)) |
| 4.19 | h2oai's LLM repositories - ([h2ogpt](https://github.com/h2oai/h2ogpt)), ([h2o-llmstudio](https://github.com/h2oai/h2o-llmstudio)), ([Huggingface](https://huggingface.co/h2oai)) | 
| 4.19 | Evaluating Verifiability in Generative Search Engines ([:x:](https://arxiv.org/abs/2304.09848)), ([:paperclip:](https://arxiv.org/pdf/2304.09848.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09848)) |
| 4.19 | How to train your own Large Language Models ([Blog](https://blog.replit.com/llm-training)) |
| 4.19 | [AI Playground](https://play.vercel.ai/r/mWjP5Dt) from Vercel Labs ([tweet](https://twitter.com/vercel/status/1648451494440742917)) |
| 4.19 | StanfordBDHG HealthGPT ([tweet](https://twitter.com/varunshenoy_/status/1648374949537775616)), ([:octocat:](https://github.com/StanfordBDHG/HealthGPT)![GitHub Repo stars](https://img.shields.io/github/stars/StanfordBDHG/HealthGPT?style=social)) |
| 4.19 | GPT4All-J : the first Apache-2 Licensed Chatbot that runs locally on your machine ([:octocat:](https://github.com/nomic-ai/gpt4all)![GitHub Repo stars](https://img.shields.io/github/stars/nomic-ai/gpt4all?style=social)), ([:paperclip:](https://static.nomic.ai/gpt4all/2023_GPT4All-J_Technical_Report_2.pdf)) | 
| 4.19 | PersonalPrivate.AI - system to advise on new patent ideas ([tweet](https://twitter.com/BrianRoemmele/status/1648378237633073152)) |
| 4.18 | Computer-Vision Benchmark Segment-Anything Model (SAM) in Medical Images: Accuracy in 12 Datasets ([:x:](https://arxiv.org/abs/2304.09324)), ([:paperclip:](https://arxiv.org/pdf/2304.09324.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09324)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/accuracy-of-segment-anything-model-sam-in)) |
| 4.18 | Exploring the Trade-Offs: Unified Large Language Models vs Local Fine-Tuned Models for Highly-Specific Radiology NLI Task ([:x:](https://arxiv.org/abs/2304.09138)), ([:paperclip:](https://arxiv.org/pdf/2304.09138.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09138)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/exploring-the-trade-offs-unified-large)) |
| 4.18 | [Economist](https://www.economist.com/by-invitation/2023/04/18/the-world-needs-an-international-agency-for-artificial-intelligence-say-two-ai-experts) - The world needs an international agency for artificial intelligence, say two AI experts ([Archive](https://archive.is/jWEJ8#selection-1039.0-1039.87)) |
| 4.18 | CancerGPT: Few-shot Drug Pair Synergy Prediction using Large Pre-trained Language Models ([:x:](https://arxiv.org/abs/2304.10946)), ([:paperclip:](https://arxiv.org/pdf/2304.10946.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.10946)) |
| 4.18 | Think Before You Act: Unified Policy for Interleaving Language Reasoning with Actions ([:x:](https://arxiv.org/abs/2304.11063)), ([:paperclip:](https://arxiv.org/pdf/2304.11063.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11063)) |
| 4.18 | Nature - [Why open-source generative AI models are an ethical way forward for science](https://www.nature.com/articles/d41586-023-01295-4) |
| 4.18 | Autonomous Agents(BabyAGI, AutoGPT) & Agent Simulations(CAMEL, Generative Agents) ([Blog](https://blog.langchain.dev/agents-round/)) |
| 4.18 | AutoTaskFormer: Searching Vision Transformers for Multi-task Learning ([:x:](https://arxiv.org/abs/2304.08756)), ([:paperclip:](https://arxiv.org/pdf/2304.08756.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08756)) |
| 4.18 | SAM Fails to Segment Anything? -- SAM-Adapter: Adapting SAM in Underperformed Scenes: Camouflage, Shadow, and More ([:x:](https://arxiv.org/abs/2304.09148)), ([:paperclip:](https://arxiv.org/pdf/2304.09148.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09148)), ([Project page](https://tianrun-chen.github.io/SAM-Adaptor/)) |
| 4.18 | Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models ([:x:](https://arxiv.org/abs/2304.08818)), ([:paperclip:](https://arxiv.org/pdf/2304.08818.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08818)), ([Project page](https://research.nvidia.com/labs/toronto-ai/VideoLDM/)) | 
| 4.18 | Google - Differentially private heatmaps ([Blog](https://ai.googleblog.com/2023/04/differentially-private-heatmaps.html)) |
| 4.18 | [The Complete Beginners Guide To Autonomous Agents](https://www.mattprd.com/p/the-complete-beginners-guide-to-autonomous-agents) |
| 4.18 | Llama Lab - A repo dedicated to building cutting-edge AGI projects: llama_agi (inspired by babyagi) and auto_llama (inspired by autogpt) ([:octocat:](https://github.com/run-llama/llama-lab)![GitHub Repo stars](https://img.shields.io/github/stars/run-llama/llama-lab?style=social)), ([Llama Hub](https://llamahub.ai/)) |
| 4.18 | Elon Musk to start ChatGPT rival called ‚ÄúTruthGPT‚Äù ([tweet](https://twitter.com/theLionary/status/1648088563874156545)) |
| 4.17 | MasaCtrl: Tuning-Free Mutual Self-Attention Control for Consistent Image Synthesis and Editing ([:x:](https://arxiv.org/abs/2304.08465)), ([:paperclip:](https://arxiv.org/pdf/2304.08465.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08465)), ([:house:](https://huggingface.co/papers/2304.08465)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/masactrl-tuning-free-mutual-self-attention)), ([:octocat:](https://github.com/tencentarc/masactrl)![GitHub Repo stars](https://img.shields.io/github/stars/tencentarc/masactrl?style=social)) |
| 4.17 | Notice of the Cyberspace Administration of China on Public Comments on the "Administrative Measures for Generative Artificial Intelligence Services (Draft for Comment)" ([Announcement](http://www.cac.gov.cn/2023-04/11/c_1682854275475410.htm)) |
| 4.17 | Pretrained Language Models as Visual Planners for Human Assistance ([:x:](https://arxiv.org/abs/2304.09179)), ([:paperclip:](https://arxiv.org/pdf/2304.09179.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09179)) |
| 4.17 | An Evaluation on Large Language Model Outputs: Discourse and Memorization ([:x:](https://arxiv.org/abs/2304.08637)), ([:paperclip:](https://arxiv.org/pdf/2304.08637.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08637)) |
| 4.17 | [Epic, Microsoft bring generative AI to EHRs](https://digitalhealth.modernhealthcare.com/digital-health/himss23-epic-microsoft-bring-openais-gpt-4-ehrs) - ([Microsoft announcement](Microsoft and Epic expand strategic collaboration with integration of Azure OpenAI Service)) |
| 4.17 | BenchMD: A Benchmark for Modality-Agnostic Learning on Medical Images and Sensors ([:x:](https://arxiv.org/abs/2304.08486)), ([:paperclip:](https://arxiv.org/pdf/2304.08486.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08486)) | 
| 4.17 | Towards Robust Prompts on Vision-Language Models ([:x:](https://arxiv.org/abs/2304.08479)), ([:paperclip:](https://arxiv.org/pdf/2304.08479.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08479)) | 
| 4.17 | Tool Learning with Foundation Models ([:x:](https://arxiv.org/abs/2304.08354)), ([:paperclip:](https://arxiv.org/pdf/2304.08354.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08354)), ([:octocat:](https://github.com/OpenBMB/BMTools)![GitHub Repo stars](https://img.shields.io/github/stars/OpenBMB/BMTools?style=social)) | 
| 4.17 | Low-code LLM: Visual Programming over LLMs ([:x:](https://arxiv.org/abs/2304.08103)), ([:paperclip:](https://arxiv.org/pdf/2304.08103.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08103)) |
| 4.17 | Wired - [OpenAI‚Äôs CEO Says the Age of Giant AI Models Is Already Over](https://www.wired.com/story/openai-ceo-sam-altman-the-age-of-giant-ai-models-is-already-over/) |
| 4.17 | Synthetic Data from Diffusion Models Improves ImageNet Classification ([:x:](https://arxiv.org/abs/2304.08466)), ([:paperclip:](https://arxiv.org/pdf/2304.08466.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08466)) |
| 4.17 | RedPajama-Data: An Open Source Recipe to Reproduce LLaMA training dataset ([GitHib](https://github.com/togethercomputer/RedPajama-Data)) |
| 4.17 | Visual Instruction Tuning  ([:x:](https://arxiv.org/abs/2304.08485)), ([:paperclip:](https://arxiv.org/pdf/2304.08485.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08485)), ([:octocat:](https://github.com/haotian-liu/LLaVA)![GitHub Repo stars](https://img.shields.io/github/stars/haotian-liu/LLaVA?style=social)), ([Dataset](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K)), ([Model](https://huggingface.co/liuhaotian/LLaVA-13b-delta-v0)), ([Project page](https://llava-vl.github.io/)), ([Demo](https://llava.hliu.cc/)) |
| 4.17 | Learning to Compress Prompts with Gist Tokens ([:x:](https://arxiv.org/abs/2304.08467)), ([:paperclip:](https://arxiv.org/pdf/2304.08467.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08467)) |
| 4.17 | ImpressionGPT: An Iterative Optimizing Framework for Radiology Report Summarization with ChatGPT ([:x:](https://arxiv.org/abs/2304.08448)), ([:paperclip:](https://arxiv.org/pdf/2304.08448.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08448)) |
| 4.17 | Meta - DINOv2: State-of-the-art computer vision models with self-supervised learning ([blog](https://ai.facebook.com/blog/dino-v2-computer-vision-self-supervised-learning/)), ([:octocat:](https://github.com/facebookresearch/dinov2)![GitHub Repo stars](https://img.shields.io/github/stars/facebookresearch/dinov2?style=social)), ([Demo](https://dinov2.metademolab.com/)), ([:x:](https://arxiv.org/abs/2304.07193)), ([:paperclip:](https://arxiv.org/pdf/2304.07193.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.07193)) |
| 4.17 | [TypingMind](https://www.typingmind.com/) - A better UI for ChatGPT ([tweet](https://twitter.com/tdinh_me/status/1647820035820523523)) |
| 4.16 | Understanding Large Language Models ([Blog](https://magazine.sebastianraschka.com/p/understanding-large-language-models)) |
| 4.16 | INSIGHT - an autonomous AI that can do medical research ([:octocat:](https://github.com/oneil512/INSIGHT)![GitHub Repo stars](https://img.shields.io/github/stars/oneil512/INSIGHT?style=social)) |
| 4.16 | GPT4free - use ChatGPT, for free!! - ([:octocat:](https://github.com/xtekky/gpt4free)![GitHub Repo stars](https://img.shields.io/github/stars/xtekky/gpt4free?style=social)) | 
| 4.16 | Solving Math Word Problems by Combining Language Models With Symbolic Solvers ([:x:](https://arxiv.org/abs/2304.09102)), ([:paperclip:](https://arxiv.org/pdf/2304.09102.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09102)) |
| 4.16 | ChatPLUG: Open-Domain Generative Dialogue System with Internet-Augmented Instruction Tuning for Digital Human ([:x:](https://arxiv.org/abs/2304.07849)), ([:paperclip:](https://arxiv.org/pdf/2304.07849.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.07849)) |
| 4.16 | Driving and suppressing the human language network using large language models ([bioRxiv](https://www.biorxiv.org/content/10.1101/2023.04.16.537080v1)), ([:paperclip:](https://www.biorxiv.org/content/10.1101/2023.04.16.537080v1.full.pdf)) |
| 4.16 | MultiGPT ([:octocat:](https://github.com/rumpfmax/Multi-GPT)![GitHub Repo stars](https://img.shields.io/github/stars/rumpfmax/Multi-GPT?style=social)). ([tweet](https://twitter.com/md_rumpf/status/1647911393796956162)) |
| 4.16 | OpenAssistant Conversations - Democratizing Large Language Model Alignment ([:paperclip:](https://drive.google.com/file/d/10iR5hKwFqAKhL3umx8muOWSRm7hs5FqX/view)), ([YouTube](https://www.youtube.com/watch?v=Ft9_RsKxrG4)), ([hacker news](https://news.ycombinator.com/item?id=35582417)) |
| 4.16 | Auto-evaluator - lightweight evaluation tool for question-answering using Langchain ([:octocat:](https://github.com/PineappleExpress808/auto-evaluator)![GitHub Repo stars](https://img.shields.io/github/stars/PineappleExpress808/auto-evaluator?style=social)) | 
| 4.16 | NYT - [Google Devising Radical Search Changes to Beat Back A.I. Rivals](https://www.nytimes.com/2023/04/16/technology/google-search-engine-ai.html) ([Archive](https://archive.is/ti9Ns)) |
| 4.15 | Brex's Prompt Engineering Guide ([:octocat:](https://github.com/brexhq/prompt-engineering)![GitHub Repo stars](https://img.shields.io/github/stars/brexhq/prompt-engineering?style=social)) |
| 4.15 | [Graphologue](https://twitter.com/HaijunXia/status/1646917869115166720) and [Sensecape](https://twitter.com/HaijunXia/status/1646919380704559104) by [UCSD Creativity Lab](https://creativity.ucsd.edu/ai) |
| 4.15 | Tractable Control for Autoregressive Language Generation ([:x:](https://arxiv.org/abs/2304.07438)), ([:paperclip:](https://arxiv.org/pdf/2304.07438.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.07438)) |
| 4.15 | Web LLM - language model chats directly onto web browsers ([Site](https://mlc.ai/web-llm/)), ([:octocat:](https://github.com/mlc-ai/web-llm#how)![GitHub Repo stars](https://img.shields.io/github/stars/mlc-ai/web-llm#how?style=social)) |
| 4.15 | MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models ([Project page](https://minigpt-4.github.io/)). ([Paper]()), ([:octocat:](https://github.com/Vision-CAIR/MiniGPT-4)![GitHub Repo stars](https://img.shields.io/github/stars/Vision-CAIR/MiniGPT-4?style=social)), ([YouTube](https://www.youtube.com/watch?v=__tftoxpBAw)) |
| 4.15 | OpenAssistant - The world's largest open-source replication of ChatGPT ([site](https://open-assistant.io/)), ([:octocat:](https://github.com/LAION-AI/Open-Assistant)![GitHub Repo stars](https://img.shields.io/github/stars/LAION-AI/Open-Assistant?style=social)), ([Dataset - OASST1](https://huggingface.co/datasets/OpenAssistant/oasst1)), ([Paper](https://ykilcher.com/oa-paper)), ([YouTube](https://www.youtube.com/watch?v=ddG2fM9i4Kk&feature=youtu.be)), ([Reddit](https://www.reddit.com/r/OpenAssistant/)) |
| 4.14 | MedAlpaca -- An Open-Source Collection of Medical Conversational AI Models and Training Data ([:x:](https://arxiv.org/abs/2304.08247)), ([:paperclip:](https://arxiv.org/pdf/2304.08247.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08247)), ([:trophy:papers with code](https://paperswithcode.com/paper/medalpaca-an-open-source-collection-of)) |
| 4.14 | HuaTuo: Tuning LLaMA Model with Chinese Medical Knowledge ([:x:](https://arxiv.org/abs/2304.06975)), ([:paperclip:](https://arxiv.org/pdf/2304.06975.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06975)), ([:trophy:papers with code](https://paperswithcode.com/paper/huatuo-tuning-llama-model-with-chinese)) |
| 4.14 | ChatGPT: Applications, Opportunities, and Threats ([:x:](https://arxiv.org/abs/2304.09103)), ([:paperclip:](https://arxiv.org/pdf/2304.09103.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09103)) |
| 4.14 | Swin3D: A Pretrained Transformer Backbone for 3D Indoor Scene Understanding ([:x:](https://arxiv.org/abs/2304.06906)), ([:paperclip:](https://arxiv.org/pdf/2304.06906.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06906)) |
| 4.14 | OpenBB Terminal V3.0.0rc2 - ([:octocat:](https://github.com/OpenBB-finance/OpenBBTerminal/releases/tag/v3.0.0rc2)![GitHub Repo stars](https://img.shields.io/github/stars/OpenBB-finance/OpenBBTerminal?style=social)) |
| 4.14 | Delta Denoising Score  ([:x:](https://arxiv.org/abs/2304.07090)), ([:paperclip:](https://arxiv.org/pdf/2304.07090.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.07090)), ([Project page](https://delta-denoising-score.github.io/)) |
| 4.14 | DINOv2: Learning Robust Visual Features without Supervision ([:x:](https://arxiv.org/abs/2304.07193)), ([:paperclip:](https://arxiv.org/pdf/2304.07193.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.07193)) |
| 4.14 | Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved With Text  ([:x:](https://arxiv.org/abs/2304.06939)), ([:paperclip:](https://arxiv.org/pdf/2304.06939.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06939)), ([:octocat:](https://github.com/allenai/mmc4)![GitHub Repo stars](https://img.shields.io/github/stars/allenai/mmc4?style=social)) |
| 4.14 | WSJ - [Elon Musk Creates New Artificial Intelligence Company X.AI](https://www.wsj.com/articles/elon-musks-new-artificial-intelligence-business-x-ai-incorporates-in-nevada-962c7c2f) ([archive](https://archive.is/qzbbb)), ([FT](https://www.ft.com/content/2a96995b-c799-4281-8b60-b235e84aefe4)) |
| 4.14 | Google Med-PaLM 2 - [A responsible path to generative AI in healthcare](https://cloud.google.com/blog/topics/healthcare-life-sciences/sharing-google-med-palm-2-medical-large-language-model?hl=en) |
| 4.14 | Meta's open source Animated Drawings - ([Blog](https://developers.facebook.com/blog/post/2023/04/13/meta-os-animated-drawings/)) |
| 4.14 | ControlNet v1.1 nightly - ([:octocat:](https://github.com/lllyasviel/ControlNet-v1-1-nightly)![GitHub Repo stars](https://img.shields.io/github/stars/lllyasviel/ControlNet-v1-1-nightly?style=social)) |
| 4.13 | Teenage-AGI ([:octocat:](https://github.com/seanpixel/Teenage-AGI)![GitHub Repo stars](https://img.shields.io/github/stars/seanpixel/Teenage-AGI?style=social)) |
| 4.13 | Boosted Prompt Ensembles for Large Language Models ([:x:](https://arxiv.org/abs/2304.05970)), ([:paperclip:](https://arxiv.org/pdf/2304.05970.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.05970)) |
| 4.13 | ChatGPT-4 Outperforms Experts and Crowd Workers in Annotating Political Twitter Messages with Zero-Shot Learning ([:x:](https://arxiv.org/abs/2304.06588)), ([:paperclip:](https://arxiv.org/pdf/2304.06588.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06588)) |
| 4.13 | Soundini: Sound-Guided Diffusion for Natural Video Editing ([:x:](https://arxiv.org/abs/2304.06818)), ([:paperclip:](https://arxiv.org/pdf/2304.06818.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06818)), ([Project page](https://kuai-lab.github.io/soundini-gallery/)) |
| 4.13 | Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study ([:x:](https://arxiv.org/abs/2304.06762)), ([:paperclip:](https://arxiv.org/pdf/2304.06762.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06762)), ([:octocat:](https://github.com/geekyutao/Inpaint-Anything)![GitHub Repo stars](https://img.shields.io/github/stars/geekyutao/Inpaint-Anything?style=social)) |
| 4.13 | Inpaint Anything: Segment Anything Meets Image Inpainting ([:x:](https://arxiv.org/abs/2304.06790)), ([:paperclip:](https://arxiv.org/pdf/2304.06790.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06790)), ([:octocat:](https://github.com/NVIDIA/Megatron-LM#retro)![GitHub Repo stars](https://img.shields.io/github/stars/NVIDIA/Megatron-LM?style=social)) |
| 4.13 | [GoalGPT](https://beta.nando.ai/goalgpt.php) by Nando.ai |
| 4.13 | Power-seeking can be probable and predictive for trained agents ([:x:](https://arxiv.org/abs/2304.06528)), ([:paperclip:](https://arxiv.org/pdf/2304.06528.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06528)) |
| 4.13 | [GoalGPT](https://beta.nando.ai/goalgpt.php) by Nando.ai |
| 4.13 | [Stable Diffusion XL Beta Available for API Customers and DreamStudio Users](https://stability.ai/blog/stable-diffusion-xl-beta-available-for-api-customers-and-dreamstudio-users) |
| 4.13 | [NAB 2023: Introducing Text-Based Editing in Premiere Pro, Properties panel in After Effects, and much more](https://blog.adobe.com/en/publish/2023/04/13/nab-2023-introducing-text-based-editing-premiere-pro-properties-panel-after-effects-more) |
| 4.13 | [Announcing New Tools for Building with Generative AI on AWS](https://aws.amazon.com/ko/blogs/machine-learning/announcing-new-tools-for-building-with-generative-ai-on-aws/) - Amazon LLM (Titan), AWS fine-tuning model (Bedrock), Amazon copilot competitor (Code whisperer) |
| 4.13 | FT - [We must slow down the race to God-like AI](https://www.ft.com/content/03895dc4-a3b7-481e-95cc-336a524f2ac2) ([archive](https://archive.is/jFfBQ#selection-1443.0-1443.41)) |
| 4.13 | Segment Everything Everywhere All at Once ([:x:](https://arxiv.org/abs/2304.06718)), ([:paperclip:](https://arxiv.org/pdf/2304.06718.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06718)) |
| 4.13 | Expressive Text-to-Image Generation with Rich Text ([:x:](https://arxiv.org/abs/2304.06720)), ([:paperclip:](https://arxiv.org/pdf/2304.06720.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06720)), ([Project page](https://rich-text-to-image.github.io/)) |
| 4.13 | AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models ([:x:](https://arxiv.org/abs/2304.06364)), ([:paperclip:](https://arxiv.org/pdf/2304.06364.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06364)), ([:octocat:](https://github.com/microsoft/AGIEval)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/AGIEval?style=social)) |
| 4.12 | Can Large Language Models Transform Computational Social Science? ([:x:](https://arxiv.org/abs/2305.03514)), ([:paperclip:](https://arxiv.org/pdf/2305.03514.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.03514)) | 
| 4.12 | Galactic ChitChat: Using Large Language Models to Converse with Astronomy Literature ([:x:](https://arxiv.org/abs/2304.05406)), ([:paperclip:](https://arxiv.org/pdf/2304.05406.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.05406)) | 
| 4.12 | Performance of ChatGPT, GPT-4, and Google Bard on a Neurosurgery Oral Boards Preparation Question Bank ([medRxiv](https://www.medrxiv.org/content/10.1101/2023.04.06.23288265v1)), ([:paperclip:](https://www.medrxiv.org/content/10.1101/2023.04.06.23288265v1.full.pdf)) |
| 4.12 | ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning ([:x:](https://arxiv.org/abs/2304.05613)), ([:paperclip:](https://arxiv.org/pdf/2304.05613.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.05613)) |
| 4.12 | Foundation models for generalist medical artificial intelligence (Nature [https://doi.org/10.1038/s41586-023-05881-4](https://www.nature.com/articles/s41586-023-05881-4)), ([:paperclip:](https://www.nature.com/articles/s41586-023-05881-4.pdf)), ([SS](https://www.semanticscholar.org/paper/Foundation-models-for-generalist-medical-artificial-Moor-Banerjee/9faa2b0e5cb93f20df0555c3c350fab0b2eccf3a)) |
| 4.12 | Dolly v2 - 12B parameter language model ([Model weight](https://huggingface.co/databricks/dolly-v2-12b)), ([:octocat:](https://github.com/databrickslabs/dolly/tree/master/data)![GitHub Repo stars](https://img.shields.io/github/stars/databrickslabs/dolly?style=social)), ([Blog](https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm)) | 
| 4.11 | Re-imagine the Negative Prompt Algorithm: Transform 2D Diffusion into 3D, alleviate Janus problem and Beyond ([:x:](https://arxiv.org/abs/2304.04968)), ([:paperclip:](https://arxiv.org/pdf/2304.04968.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.04968)), ([Project page](https://perp-neg.github.io/)), ([:octocat:](https://github.com/Perp-Neg/Perp-Neg-stablediffusion)![GitHub Repo stars](https://img.shields.io/github/stars/Perp-Neg/Perp-Neg-stablediffusion?style=social)), ([Colab](https://github.com/Perp-Neg/Perp-Neg-stablediffusion/blob/main/notebooks/demo.ipynb)), ([Hugging face](https://huggingface.co/spaces/rezaarmand/Perp-Neg)) | 
| 4.11 | Toxicity in ChatGPT: Analyzing Persona-assigned Language Models ([:x:](https://arxiv.org/abs/2304.05335)), ([:paperclip:](https://arxiv.org/pdf/2304.05335.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.05335)) | 
| 4.11 | Multi-step Jailbreaking Privacy Attacks on ChatGPT ([:x:](https://arxiv.org/abs/2304.05197)), ([:paperclip:](https://arxiv.org/pdf/2304.05197.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.05197)) | 
| 4.11 | [Building LLM applications for production](https://huyenchip.com/2023/04/11/llm-engineering.html) |
| 4.11 | Emergent autonomous scientific research capabilities of large language models ([:x:](https://arxiv.org/abs/2304.05332)), ([:paperclip:](https://arxiv.org/pdf/2304.05332.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.05332)) |
| 4.11 | [OpenAI‚Äôs Bug Bounty Program](https://openai.com/blog/bug-bounty-program) |
| 4.11 | [NTIA‚Äôs ‚ÄúAI Accountability Policy Request for Comment‚Äù](https://ntia.gov/issues/artificial-intelligence/request-for-comments) |
| 4.11 | WSJ - [Biden Administration Weighs Possible Rules for AI Tools Like ChatGPT](https://www.wsj.com/amp/articles/biden-administration-weighs-possible-rules-for-ai-tools-like-chatgpt-46f8257b?fbclid=IwAR1GauvAq8cuHIQQlZ8dlxiKkYuszBMPHqr_K6iZiAeTz2yCjGu9vP_S3cc), ([archive](https://archive.is/6phfS)) |
| 4.11 | ChemCrow: Augmenting large-language models with chemistry tools ([:x:](https://arxiv.org/abs/2304.05376)), ([:paperclip:](https://arxiv.org/pdf/2304.05376.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.05376)) |
| 4.11 | [LangChainJS Support for Multiple JS Environments](https://blog.langchain.dev/js-envs/) ([tweet](https://twitter.com/LangChainAI/status/1645831073358815232)) |
| 4.11 | Teaching Large Language Models to Self-Debug ([:x:](https://arxiv.org/abs/2304.05128)), ([:paperclip:](https://arxiv.org/pdf/2304.05128.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.05128)) |
| 4.10 | Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models ([Paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4412788)), ([:paperclip:](https://papers.ssrn.com/sol3/Delivery.cfm/SSRN_ID4429709_code2675263.pdf?abstractid=4412788&mirid=1)) |
| 4.10 | On the Possibilities of AI-Generated Text Detection ([:x:](https://arxiv.org/abs/2304.04736)), ([:paperclip:](https://arxiv.org/pdf/2304.04736.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.04736)) |
| 4.10 | OpenAGI: When LLM Meets Domain Experts ([:x:](https://arxiv.org/abs/2304.04370)), ([:paperclip:](https://arxiv.org/pdf/2304.04370.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.04370)), ([:octocat:](https://github.com/agiresearch/OpenAGI)![GitHub Repo stars](https://img.shields.io/github/stars/agiresearch/OpenAGI?style=social)) |
| 4.9 | ChatAll - oncurrently chat with ChatGPT, Bing Chat, bard, Alpaca, Vincuna, Claude, ChatGLM, MOSS, iFlytek Spark, ERNIE and more, discover the best answers ([:octocat:](https://github.com/sunner/ChatALL)![GitHub Repo stars](https://img.shields.io/github/stars/sunner/ChatALL?style=social)) |
| 4.9 | BabyAGI JS - ([:octocat:](https://github.com/ericciarla/babyagijs)![GitHub Repo stars](https://img.shields.io/github/stars/ericciarla/babyagijs?style=social)) |
| 4.9 | AgentGPT - Auto-GPT directly in the browser ([tweet](https://twitter.com/asimdotshrestha/status/1644883727707959296)), ([:octocat:](https://github.com/reworkd/AgentGPT)![GitHub Repo stars](https://img.shields.io/github/stars/reworkd/AgentGPT?style=social)), ([demo](https://agentgpt.reworkd.ai/)) |
| 4.8 | [A Recipe for Training Large Models](https://wandb.ai/craiyon/report/reports/Recipe-Training-Large-Models--VmlldzozNjc4MzQz) |
| 4.7 | [SuperPrompt Engineer Encourages ChatGPT Hallucinations](https://metanews.com/superprompt-engineer-encourages-chatgpt-hallucinations/) |
| 4.7 | Cerebras-GPT: Open Compute-Optimal Language Models Trained on the Cerebras Wafer-Scale Cluster ([:x:](https://arxiv.org/abs/2304.03208)), ([:paperclip:](https://arxiv.org/pdf/2304.03208.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.03208)) |
| 4.7 | Why think step-by-step? Reasoning emerges from the locality of experience ([:x:](https://arxiv.org/abs/2304.03843)), ([:paperclip:](https://arxiv.org/pdf/2304.03843.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.03843)) |
| 4.7 | Generative Agents: Interactive Simulacra of Human Behavior ([:x:](https://arxiv.org/abs/2304.03442)), ([:paperclip:](https://arxiv.org/pdf/2304.03442.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.03442)), ([Project](https://reverie.herokuapp.com/arXiv_Demo/)) | 
| 4.7 | Vicuna-7B: small, efficient, yet capable ([:octocat:](https://github.com/lm-sys/FastChat)![GitHub Repo stars](https://img.shields.io/github/stars/lm-sys/FastChat?style=social)), ([Weight](https://huggingface.co/lmsys/vicuna-7b-delta-v0)) |
| 4.7 | StackLlama ([Blog](https://huggingface.co/blog/stackllama)), ([Demo](https://huggingface.co/spaces/trl-lib/stack-llama)), ([:octocat:](https://github.com/lvwerra/trl/tree/main/examples/stack_llama/scripts)![GitHub Repo stars](https://img.shields.io/github/stars/lvwerra/trl?style=social)) |
| 4.7 | SegGPT: Segmenting Everything In Context ([:x:](https://arxiv.org/abs/2304.03284)), ([:paperclip:](https://arxiv.org/pdf/2304.03284.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.03284)), ([:octocat:](https://github.com/baaivision/Painter)![GitHub Repo stars](https://img.shields.io/github/stars/baaivision/Painter?style=social)), ([Demo](https://huggingface.co/spaces/BAAI/SegGPT)) |
| 4.6 | Synthetic Data in Healthcare ([:x:](https://arxiv.org/abs/2304.03243)), ([:paperclip:](https://arxiv.org/pdf/2304.03243.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.03243)), ([:house:](https://huggingface.co/papers/2304.03243)), ([:eight_spoked_asterisk:]()) |
| 4.6 | Chrome ships WebGPU ([Blog](https://developer.chrome.com/blog/webgpu-release/)) |
| 4.6 | GPT detectors are biased against non-native English writers ([:x:](https://arxiv.org/abs/2304.02819)), ([:paperclip:](https://arxiv.org/pdf/2304.02819.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/02819.03411)) |
| 4.6 | ChaosGPT: Empowering GPT with Internet and Memory to Destroy Humanity ([YouTube](https://www.youtube.com/watch?v=g7YJIpkk7KM&t=912s)) |
| 4.6 | InstantBooth: Personalized Text-to-Image Generation without Test-Time Finetuning ([:x:](https://arxiv.org/abs/2304.03411)), ([:paperclip:](https://arxiv.org/pdf/2304.03411.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.03411)), ([Project](https://jshi31.github.io/InstantBooth/)) | 
| 4.6 | Wired - [AI Desperately Needs Global Oversight](https://www.wired.com/story/ai-desperately-needs-global-oversight/) |
| 4.6 | Instruction Tuning with GPT-4 ([:x:](https://arxiv.org/abs/2304.03277)), ([:paperclip:](https://arxiv.org/pdf/2304.03277.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.03277)), ([:octocat:](https://instruction-tuning-with-gpt-4.github.io/)) |
| 4.6 | GeNVS: Generative Novel View Synthesis with 3D-Aware Diffusion Models ([:x:](https://arxiv.org/abs/2304.02602)), ([:paperclip:](https://arxiv.org/pdf/2304.02602.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.02602)), ([:octocat:](https://nvlabs.github.io/genvs/)) |
| 4.6 | Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark ([:x:](https://arxiv.org/abs/2304.03279)), ([:paperclip:](https://arxiv.org/pdf/2304.03279.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.03279)) |
| 4.5 | Yoshua Bengio - [Slowing down development of AI systems passing the Turing test](https://yoshuabengio.org/2023/04/05/slowing-down-development-of-ai-systems-passing-the-turing-test/) | 
| 4.5 | Language models are on Replicate - FLAN-T5, GPT-J, and LLaMA ([Blog](https://replicate.com/blog/language-models)) |
| 4.5 | [Meta's  Segment Anything Model (SAM)](https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/?utm_source=twitter&utm_medium=organic_social&utm_campaign=segmentanything&utm_content=gif) ([Paper](https://ai.facebook.com/research/publications/segment-anything/)), ([:paperclip:](https://scontent-ssn1-1.xx.fbcdn.net/v/t39.2365-6/10000000_6331779526880473_6748528980292947838_n.pdf?_nc_cat=102&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=lnYqcLNTtLQAX80UVfV&_nc_ht=scontent-ssn1-1.xx&oh=00_AfAAtzQrBx242Tl4miOfzWrYrJAhLw3VCm1FeWuMs319zw&oe=6432ACEA)), ([:octocat:](https://github.com/facebookresearch/segment-anything)![GitHub Repo stars](https://img.shields.io/github/stars/facebookresearch/segment-anything?style=social)), ([Demo](https://segment-anything.com/)), ([:x:](https://arxiv.org/abs/2304.02643)), ([:paperclip:](https://arxiv.org/pdf/2304.02643.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.02643)) | 
| 4.4 | Leveraging GPT-4 for Post Hoc Transformation of Free-text Radiology Reports into Structured Reporting: A Multilingual Feasibility Study (RSNA Radiology, [https://doi.org/10.1148/radiol.230725](https://pubs.rsna.org/doi/10.1148/radiol.230725)) |
| 4.4 | Calibrated Chaos: Variance Between Runs of Neural Network Training is Harmless and Inevitable ([:x:](https://arxiv.org/abs/2304.01910)), ([:paperclip:](https://arxiv.org/pdf/2304.01910.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.01910)) |
| 4.4 | One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era ([:x:](https://arxiv.org/abs/2304.06488)), ([:paperclip:](https://arxiv.org/pdf/2304.06488.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06488)) |
| 4.4 | [LangCahin raised $10 million in seed funding](https://blog.langchain.dev/announcing-our-10m-seed-round-led-by-benchmark/) |
| 4.4 | Kandinsky 2.1 ([:octocat:](https://github.com/ai-forever/Kandinsky-2)![GitHub Repo stars](https://img.shields.io/github/stars/ai-forever/Kandinsky-2?style=social)), ([HuggingFace](https://huggingface.co/ai-forever/Kandinsky_2.1)) |
| 4.4 | The weights of Vicuna-13B released ([WebUI demo](https://chat.lmsys.org/)) ([:octocat:](https://github.com/lm-sys/FastChat/#vicuna-weights)![GitHub Repo stars](https://img.shields.io/github/stars/lm-sys/FastChat?style=social)) |
| 4.4 | LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models ([:x:](https://arxiv.org/abs/2304.01933)), ([:paperclip:](https://arxiv.org/pdf/2304.01933.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.01933)), ([:octocat:](https://github.com/AGI-Edgerunners/LLM-Adapters)![GitHub Repo stars](https://img.shields.io/github/stars/AGI-Edgerunners/LLM-Adapters?style=social)) |
| 4.4 | Summary of ChatGPT/GPT-4 Research and Perspective Towards the Future of Large Language Models ([:x:](https://arxiv.org/abs/2304.01852)), ([:paperclip:](https://arxiv.org/pdf/2304.01852.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.01852)) |
| 4.3 | Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling ([:x:](https://arxiv.org/abs/2304.01373)), ([:paperclip:](https://arxiv.org/pdf/2304.01373.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.01373)) |
| 4.3 | Vicuna-13B: An Open-Source ChatGPT Alternative That Impresses GPT-4 ([Blog](https://docs.kanaries.net/articles/vicuna-chatgpt-alternative)), ([:octocat:](https://github.com/lm-sys/FastChat)![GitHub Repo stars](https://img.shields.io/github/stars/lm-sys/FastChat?style=social)) |
| 4.3 | Baby AGI ([:octocat:](https://github.com/yoheinakajima/babyagi)![GitHub Repo stars](https://img.shields.io/github/stars/yoheinakajima/babyagi?style=social)) |
| 4.3 | [Berkley just released Koala-13B!](https://bair.berkeley.edu/blog/2023/04/03/koala/) ([Demo](https://chat.lmsys.org/?model=koala-13b)) |
| 4.3 | [2023 Artificial Intelligence (AI) Index Report](https://aiindex.stanford.edu/report/) Published by Stanford Institute for Human-Centered Artificial Intelligence (HAI) |
| 4.3 | The LLM playground - open source ([:octocat:](https://github.com/nat/openplayground)) |
| 4.3 | Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data ([:x:](https://arxiv.org/abs/2304.01196)), ([:paperclip:](https://arxiv.org/pdf/2304.01196.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.01196)), ([:octocat:](https://github.com/project-baize/baize)![GitHub Repo stars](https://img.shields.io/github/stars/project-baize/baize?style=social)) |
| 4.2 | GPTCache : A Library for Creating Semantic Cache for LLM Queries - ([:octocat:]()) |
| 4.2 | Better Language Models of Code through Self-Improvement ([:x:](https://arxiv.org/abs/2304.01228)), ([:paperclip:](https://arxiv.org/pdf/2304.01228.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.01228)) |
| 4.2 | Eight Things to Know about Large Language Models ([:x:](https://arxiv.org/abs/2304.00612)), ([:paperclip:](https://arxiv.org/pdf/2304.00612.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.00612)) |
| 4.2 | LLMMaps -- A Visual Metaphor for Stratified Evaluation of Large Language Models ([:x:](https://arxiv.org/abs/2304.00457)), ([:paperclip:](https://arxiv.org/pdf/2304.00457.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.00457)) |
| 4.1 | Evaluating Large Language Models on a Highly-specialized Topic, Radiation Oncology Physics ([:x:](https://arxiv.org/abs/2304.01938)),  ([:paperclip:](https://arxiv.org/pdf/2304.01938.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.01938)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/evaluating-large-language-models-on-a-highly))	|
| 4.1 | [Italy curbs ChatGPT, starts probe over privacy concerns](https://www.cnbc.com/2023/04/01/italy-curbs-chatgpt-starts-probe-over-privacy-concerns.html) |
| 3.31 | Evaluating GPT-4 and ChatGPT on Japanese Medical Licensing Examinations ([:x:](https://arxiv.org/abs/2303.18027)), ([:paperclip:](https://arxiv.org/pdf/2303.18027.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.18027)), ([:house:](https://huggingface.co/papers/2303.18027)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/evaluating-gpt-4-and-chatgpt-on-japanese)), ([:octocat:](https://github.com/jungokasai/igakuqa)![GitHub Repo stars](https://img.shields.io/github/stars/jungokasai/igakuqa?style=social))  |
| 3.31 | Choose Your Weapon: Survival Strategies for Depressed AI Academics ([:x:](https://arxiv.org/abs/2304.06035)), ([:paperclip:](https://arxiv.org/pdf/2304.06035.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06035)) |
| 3.31 | CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society ([:x:](https://arxiv.org/abs/2303.17760)), ([:paperclip:](https://arxiv.org/pdf/2303.17760.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.17760)), ([:octocat:](https://github.com/lightaime/camel))![GitHub Repo stars](https://img.shields.io/github/stars/lightaime/camel?style=social) |
| 3.31 | ‚≠ê A Survey of Large Language Models - Version 1 ([:x:](https://arxiv.org/abs/2303.18223v1)), ([:paperclip:](https://arxiv.org/pdf/2303.18223v1.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.18223v1)) |
| 3.31 | (SCIENTIFIC AMERICAN) [AI Chatbots Can Diagnose Medical Conditions at Home. How Good Are They?](https://www.scientificamerican.com/article/ai-chatbots-can-diagnose-medical-conditions-at-home-how-good-are-they/) |
| 3.30 | ChatGPT in Healthcare: A Taxonomy and Systematic Review ([medRxiv](https://www.medrxiv.org/content/10.1101/2023.03.30.23287899v1.full)), ([:paperclip:](https://www.medrxiv.org/content/10.1101/2023.03.30.23287899v1.full.pdf)) |
| 3.30 | Launching the Generative AI Open Source (GenOS) Index - ([Index](https://www.decibel.vc/articles/launching-the-generative-ai-open-source-genos-index)), ([Tweet](https://twitter.com/chakrabartis/status/1641447121042964482)) |
| 3.30 | Whose Opinions Do Language Models Reflect? ([:x:](https://arxiv.org/abs/2303.17548)), ([:paperclip:](https://arxiv.org/pdf/2303.17548.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.17548)), ([:octocat:](https://github.com/tatsu-lab/opinions_qa)![GitHub Repo stars](https://img.shields.io/github/stars/tatsu-lab/opinions_qa?style=social)) |
| 3.30 | Language Models can Solve Computer Tasks ([:x:](https://arxiv.org/abs/2303.17491)), ([:paperclip:](https://arxiv.org/pdf/2303.17491.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.17491)) |
| 3.30 | Self-Refine: Iterative Refinement with Self-Feedback ([:x:](https://arxiv.org/abs/2303.17651)), ([:paperclip:](https://arxiv.org/pdf/2303.17651.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.17651)) |
| 3.30 | Humans in Humans Out: On GPT Converging Toward Common Sense in both Success and Failure ([:x:](https://arxiv.org/abs/2303.17276)), ([:paperclip:](https://arxiv.org/pdf/2303.17276.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.17276)) |
| 3.30 | [List of Open Sourced Fine-Tuned Large Language Models (LLM)](https://medium.com/geekculture/list-of-open-sourced-fine-tuned-large-language-models-llm-8d95a2e0dc76) |
| 3.30 | [NEJM - Benefits, Limits, and Risks of GPT-4 as an AI Chatbot for Medicine](https://www.nejm.org/doi/pdf/10.1056/NEJMsr2214184) |
| 3.30 | BloombergGPT: A Large Language Model for Finance ([:x:](https://arxiv.org/abs/2303.17564)), ([:paperclip:](https://arxiv.org/pdf/2303.17564.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.17564)) |
| 3.30 | [Got It AI‚Äôs ELMAR challenges GPT-4 and LLaMa, scores well on hallucination benchmarks](https://venturebeat.com/ai/got-it-ai-elmar-challenges-gpt-4-and-llama) |
| 3.30 | HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace ([:x:](https://arxiv.org/abs/2303.17580)), ([:paperclip:](https://arxiv.org/pdf/2303.17580.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.17580)) |
| 3.30 | [CAIDP claims "The FTC should investigate OpenAI and block GPT over ‚Äòdeceptive‚Äô behavior"](https://edition.cnn.com/2023/03/30/tech/ftc-openai-gpt-ai-think-tank/index.html) |
| 3.30 | [Epic to use Microsoft's GPT-4 in EHRs](https://www.beckershospitalreview.com/ehrs/epic-to-use-microsofts-open-ai-in-ehrs.html) |
| 3.30 | Auto-GPT: An Autonomous GPT-4 Experiment ([:octocat:](https://github.com/Torantulino/Auto-GPT)![GitHub Repo stars](https://img.shields.io/github/stars/Torantulino/Auto-GPT?style=social)) |
| 3.29 | HyperDiffusion: Generating Implicit Neural Fields with Weight-Space Diffusion
 ([project](https://llm-attacks.org/)), ([:x:](https://arxiv.org/abs/2303.17015)), ([:paperclip:](https://arxiv.org/pdf/2303.17015.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.17015)), ([:house:](https://huggingface.co/papers/2303.17015)), ([:eight_spoked_asterisk:]([https://paperswithcode.com/paper/universal-and-transferable-adversarial](https://paperswithcode.com/paper/hyperdiffusion-generating-implicit-neural)) |
| 3.29 | AnnoLLM: Making Large Language Models to Be Better Crowdsourced Annotators ([:x:](https://arxiv.org/abs/2303.16854)), ([:paperclip:](https://arxiv.org/pdf/2303.16854.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.16854)) |
| 3.29 | [nucleotide transformers - genomics LLM, ranging from 500M to 2.5B parameters](https://twitter.com/instadeepai/status/1641075963051012097) - ([:octocat:](https://github.com/instadeepai/nucleotide-transformer)![GitHub Repo stars](https://img.shields.io/github/stars/nucleotide-transformer?style=social)) |
| 3.29 | [GeoV-9b - 9 billion parameter causal language model](https://twitter.com/labmlai/status/1641357802009395201) ([code](https://github.com/geov-ai/geov), [weights](https://huggingface.co/GeoV/GeoV-9b), [colab](https://colab.research.google.com/github/geov-ai/geov/blob/master/notebooks/generate.ipynb)) |
|	3.29	|	[GPT4All - 7B param language model finetuned from a curated set of 400k GPT-Turbo-3.5](https://twitter.com/andriy_mulyar/status/1640836003194630144)  	|
|	3.29	|	[LLaMA-Adapter!: Efficient Fine-tuning of Language Models with Zero-init Attention](https://twitter.com/lupantech/status/1640899600281395200)	|
|	3.29	|	[MacGPT 3.2](https://www.macgpt.com/)	|
| 3.29 | GPTEval: NLG Evaluation using GPT-4 with Better Human Alignment ([:x:](https://arxiv.org/abs/2303.16634)), ([:paperclip:](https://arxiv.org/pdf/2303.16634.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.16634)) |
| 3.29 | TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs  ([:x:](https://arxiv.org/abs/2303.16434)), ([:paperclip:](https://arxiv.org/pdf/2303.16434.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.16434)) |
| 3.28 | Natural Selection Favors AIs over Humans [:x:](https://arxiv.org/abs/2303.16200)), ([:paperclip:](https://arxiv.org/pdf/2303.16200.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.16200)) |
| 3.28 | ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks ([:x:](https://arxiv.org/abs/2303.15056)), ([:paperclip:](https://arxiv.org/pdf/2303.15056.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.15056)) |
|	3.28	|	[LLaMA voice chat + Siri TTS](https://twitter.com/ggerganov/status/1640416314773700608)	|
|	3.28	|	[Cerebras-GPT - 111M to 13B parameters trained using the Chinchilla formula](https://twitter.com/CerebrasSystems/status/1640725880711569408)	|
|	3.28	|	[Microsoft Security Copilot: Empowering defenders at the speed of AI](https://blogs.microsoft.com/blog/2023/03/28/introducing-microsoft-security-copilot-empowering-defenders-at-the-speed-of-ai/)	|
| 3.28 | [Google pix2struct launched today, a multimodal model specializing in screenshot data](https://twitter.com/danielgross/status/1640515851014004737) |
|	3.28	|	[OpenFlamingo - a framework that enables training and evaluation of large multimodal models (LMMs)](https://laion.ai/blog/open-flamingo/)	|
| 3.27 | Microsoft JARVIS ([:octocat:](https://github.com/microsoft/JARVIS)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/JARVIS?style=social)) |
| 3.27 | [ChatGPT Survey: Performance on NLP datasets](http://opensamizdat.com/posts/chatgpt_survey/) |
| 3.27 | GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models ([:x:](https://arxiv.org/abs/2303.10130)), ([:paperclip:](https://arxiv.org/pdf/2303.10130.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.10130)) |
| 3.26 | AI-Generated Content (AIGC): A Survey ([:x:](https://arxiv.org/abs/2304.06632)), ([:paperclip:](https://arxiv.org/pdf/2304.06632.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06632)), ([:house:](https://huggingface.co/papers/2304.06632)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/ai-generated-content-aigc-a-survey) |
| 3.26 | Nature Language Reasoning, A Survey ([:x:](https://arxiv.org/abs/2303.14725)), ([:paperclip:](https://arxiv.org/pdf/2303.14725.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.14725)) |
|	3.26	|	[Sam Altman: OpenAI CEO on GPT-4, ChatGPT, and the Future of AI - Lex Fridman Podcast #367](https://www.youtube.com/watch?v=L_Guz73e6fw)	|
|	3.26	|	[LLaMA voice chat](https://twitter.com/ggerganov/status/1640022482307502085)	|
|	3.26	|	[Japanese Alpaca LoRA](https://twitter.com/kun1em0n/status/1639965140429963264)	|
| 3.24 | LLM for Patient-Trial Matching: Privacy-Aware Data Augmentation Towards Better Performance and Generalizability ([:x:](https://arxiv.org/abs/2303.16756)),  ([:paperclip:](https://arxiv.org/pdf/2303.16756.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.16756)), ([:house:](https://huggingface.co/papers/2303.16756)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/llm-for-patient-trial-matching-privacy-aware)) |
| 3.24 | Progressively Optimized Local Radiance Fields for Robust View Synthesis ([:x:](https://arxiv.org/abs/2303.13791)),  ([:paperclip:](https://arxiv.org/pdf/2303.13791.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.13791)), ([:house:](https://huggingface.co/papers/2303.13791)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/progressively-optimized-local-radiance-fields)), (CVPR 2023)	|
| 3.24 | Efficient Methods for Natural Language Processing: A Survey ([:x:](https://arxiv.org/abs/2209.00099)),  ([:paperclip:](https://arxiv.org/pdf/2209.00099.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2209.00099)) |
|	3.24	|	[NYT OPINION - You Can Have the Blue Pill or the Red Pill, and We‚Äôre Out of Blue Pills](https://www.nytimes.com/2023/03/24/opinion/yuval-harari-ai-chatgpt.html)	([archive](https://archive.is/AUKPm)) |
|	3.24	|	[Dolly - open source LLM](https://twitter.com/databricks/status/1639239800145465344) 	|
|	3.24	|	[Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators](https://twitter.com/_akhaliq/status/1639062868850266112)	|
|	3.24	|	ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge ([:x:](https://arxiv.org/abs/2303.14070v1)),  ([:paperclip:](https://arxiv.org/pdf/2303.14070v1.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.14070v1)), ([:octocat:](https://github.com/Kent0n-Li/ChatDoctor)![GitHub Repo stars](https://img.shields.io/github/stars/Kent0n-Li/ChatDoctor?style=social))	|
| 3.24 | Do large language models need sensory grounding for meaning and understanding? @YannLeCun |
|	3.23	|	[OpenAI: ChatGPT Plugins](https://openai.com/blog/chatgpt-plugins)	|
|	3.23	|	[Opera brings AI ChatGPT bot sidebar to browsers](https://www.deccanherald.com/business/technology/opera-brings-ai-chatgpt-bot-sidebar-to-browsers-1202781.html)	|
| 3.22 | The Shaky Foundations of Clinical Foundation Models: A Survey of Large Language Models and Foundation Models for EMRs ([:x:](https://arxiv.org/abs/2303.12961)), ([:paperclip:](https://arxiv.org/pdf/2303.12961.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.12961)), ([:house:](https://huggingface.co/papers/2303.12961)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/the-shaky-foundations-of-clinical-foundation)), ([:octocat:](https://github.com/som-shahlab/ehrshot-benchmark)![GitHub Repo stars](https://img.shields.io/github/stars/som-shahlab/ehrshot-benchmark?style=social)), ([SS](https://www.semanticscholar.org/paper/The-Shaky-Foundations-of-Clinical-Foundation-A-of-Wornow-Xu/f8e7e8f5d00ffea4535c4bb548f572a21122ff78) |
| 3.22 | Artificial muses: Generative Artificial Intelligence Chatbots Have Risen to Human-Level Creativity ([:x:](https://arxiv.org/abs/2303.12003)), ([:paperclip:](https://arxiv.org/pdf/2303.12003.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.12003)), ([:house:](https://huggingface.co/papers/2303.12003)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/sparks-of-artificial-general-intelligence)) |	
|	3.22	|	[GitHub: Copilot X](https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience)	|
|	3.22	|	Sparks of Artificial General Intelligence: Early experiments with GPT-4 ([:x:](https://arxiv.org/abs/2303.12712)), ([:paperclip:](https://arxiv.org/pdf/2303.12712.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.12712)), ([YouTube](https://www.youtube.com/watch?v=qbIk7-JPB2c)) |
|	3.22	|	[Pause Giant AI Experiments: An Open Letter](https://futureoflife.org/open-letter/pause-giant-ai-experiments/)	|
| 3.21 | WSJ - [Generative AI Makes Headway in Healthcare](https://www.wsj.com/articles/generative-ai-makes-headway-in-healthcare-cb5d4ee2) |
|	3.21	|	[NVIDIA Brings Generative AI to World‚Äôs Enterprises](https://nvidianews.nvidia.com/news/nvidia-brings-generative-ai-to-worlds-enterprises-with-cloud-services-for-creating-large-language-and-visual-models)	|
|	3.21	|	[Adobe launches Firefly](https://www.cnbc.com/2023/03/21/adobe-firefly-generative-ai-lets-you-type-to-edit-images.html)	|
|	3.21	|	[Google launches Bard in the US and UK](https://blog.google/technology/ai/try-bard)	|
|	3.21	|	[Microsoft: Bing Image Creator](https://blogs.microsoft.com/blog/2023/03/21/create-images-with-your-words-bing-image-creator-comes-to-the-new-bing)	|
|	3.21	|	[Stability AI Launches Stable Diffusion Reimagine](https://stability.ai/blog/stable-diffusion-reimagine)	|
| 3.20 | Reflexion: an autonomous agent with dynamic memory and self-reflection ([:x:](https://arxiv.org/abs/2303.11366)), ([:paperclip:](https://arxiv.org/pdf/2303.11366.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.11366)), ([:octocat:](https://github.com/noahshinn024/reflexion)![GitHub Repo stars](https://img.shields.io/github/stars/noahshinn024/reflexion?style=social)) |
|	3.20	|	[March 20 ChatGPT outage: Here‚Äôs what happened](https://openai.com/blog/march-20-chatgpt-outage)	|
|	3.20	|	[Runway Gen-2](https://research.runwayml.com/gen2)	|
|	3.20	|	Capabilities of GPT-4 on Medical Challenge Problems ([:x:](https://arxiv.org/abs/2303.13375)), ([:paperclip:](https://arxiv.org/pdf/2303.13375.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.13375)), ([:house:](https://huggingface.co/papers/2303.13375)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/capabilities-of-gpt-4-on-medical-challenge)) |
| 3.20 | [Making Music with GPT 4](https://www.youtube.com/watch?v=Cvl30rn03Hg) by [(Wavtool)](https://wavtool.com/) |
| 3.19 | Simple LLM Finetuner ([:octocat:](https://github.com/lxe/simple-llm-finetuner)![GitHub Repo stars](https://img.shields.io/github/stars/lxe/simple-llm-finetuner?style=social)) |
| 3.18 | Data-centric Artificial Intelligence: A Survey ([:x:](https://arxiv.org/abs/2303.10158)), ([:paperclip:](https://arxiv.org/pdf/2303.10158.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.10158)), ([:octocat:](https://github.com/daochenzha/data-centric-AI)![GitHub Repo stars](https://img.shields.io/github/stars/data-centric-AI?style=social)) |
| 3.17 | Can AI-Generated Text be Reliably Detected? ([:x:](https://arxiv.org/abs/2303.11156)), ([:paperclip:](https://arxiv.org/pdf/2303.11156.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.11156)) |
| 3.17 | GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models  ([:x:](https://arxiv.org/abs/2303.10130)), ([:paperclip:](https://arxiv.org/pdf/2303.10130.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.10130)) |
| 3.16 | WebSHAP: Towards Explaining Any Machine Learning Models Anywhere ([:x:](https://arxiv.org/abs/2303.09545)), ([:paperclip:](https://arxiv.org/pdf/2303.09545.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.09545)), ([:octocat:](https://poloclub.github.io/webshap/)) |
| 3.16 | LERF: Language Embedded Radiance Fields ([:x:](https://arxiv.org/abs/2303.09553)), ([:paperclip:](https://arxiv.org/pdf/2303.09553.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.09553)), ([:octocat:](https://www.lerf.io/)) |
|	3.16	|	[Microsoft: Microsoft 365 Copilot](https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work)	|
|	3.16	|	[Alpaca LoRA: instruct tune LLAMA on consumer hardware](https://twitter.com/_akhaliq/status/1636416647518097408)	|
|	3.16	|	[OpenAI CEO Sam Altman says AI will reshape society, acknowledges risks: 'A little bit scared of this'](https://abcnews.go.com/Technology/openai-ceo-sam-altman-ai-reshape-society-acknowledges/story?id=97897122)	|
|	3.15	|	[A new era for AI and Google Workspace](https://workspace.google.com/blog/product-announcements/generative-ai?hl=en)	|
|	3.15	|	[PyTorch 2.0: Our next generation release](https://pytorch.org/blog/pytorch-2.0-release/)	|
|	3.15	|	[Baidu: ERNIE Bot](https://www.youtube.com/watch?v=ukvEUI3x0vI)	|
|	3.15	|	[Midjourney: Midjourney V5](https://twitter.com/midjourney/status/1636130389365497857)	|
|	3.15	|	[arXiv - GPT-4 Technical report](https://arxiv.org/abs/2303.08774)	|
| 3.14 | Text-to-image Diffusion Models in Generative AI: A Survey ([:x:](https://arxiv.org/abs/2303.07909)), ([:paperclip:](https://arxiv.org/pdf/2303.07909.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.07909)), ([:house:](https://huggingface.co/papers/2303.07909)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/text-to-image-diffusion-model-in-generative)) |
| 3.14 | The Lancet - [Attention is not all you need: the complicated case of ethically using large language models in healthcare and medicine](https://www.thelancet.com/journals/ebiom/article/PIIS2352-3964(23)00077-4/fulltext) |
|	3.14	|	THUDM releases ChatGLM-6B	|
| 3.14 | Langflow - a UI for LangChain ([:octocat:](https://github.com/logspace-ai/langflow)![GitHub Repo stars](https://img.shields.io/github/stars/logspace-ai/langflow?style=social)) |
|	3.14	|	[Anthropic: Claude](https://www.anthropic.com/index/introducing-claude)	|
|	3.14	|	[Google: PaLM API & Workspace](https://blog.google/technology/ai/ai-developers-google-cloud-workspace)	|
|	3.14	|	[OpenAI: GPT-4](https://openai.com/research/gpt-4)	|
|	3.13	|	[Stanford Alpaca 7B](https://crfm.stanford.edu/2023/03/13/alpaca.html)	|
|	3.13	|	[Microsoft lays off team that taught employees how to make AI tools responsibly](https://www.theverge.com/2023/3/13/23638823/microsoft-ethics-society-team-responsible-ai-layoffs)	|
|	3.13	|	[MiniLLM: Large Language Models on Consumer GPUs](https://github.com/kuleshov/minillm)	|
| 3.13 | Chatbot UI ([:octocat:](https://github.com/mckaywrigley/chatbot-ui)(https://img.shields.io/github/stars/mckaywrigley/chatbot-ui?style=social)) |
| 3.12 | Towards General Purpose Medical AI: Continual Learning Medical Foundation Model ([:x:](https://arxiv.org/abs/2303.06580)), ([:paperclip:](https://arxiv.org/pdf/2303.06580.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.06580)), ([:house:](https://huggingface.co/papers/2303.06580)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/towards-general-purpose-medical-ai-continual)) |
|	3.12	|	[GM explores using ChatGPT in vehicles](https://europe.autonews.com/automakers/gm-explores-using-chatgpt-vehicles)	|
|	3.10	|	[Google: PaLM-E](https://ai.googleblog.com/2023/03/palm-e-embodied-multimodal-language.html)	|
|	3.9	|	[multi-model playground - https://nat.dev](https://nat.dev/)	|
|	3.9	|	[GPT-4 is coming next week](https://www.heise.de/news/GPT-4-is-coming-next-week-and-it-will-be-multimodal-says-Microsoft-Germany-7540972.html)	|
| 3.8 | Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models ([:x:](https://arxiv.org/abs/2303.04671)), ([:paperclip:](https://arxiv.org/pdf/2303.04671.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.04671)) |
|	3.8	|	[NYT, Opinion - Noam Chomsky: The False Promise of ChatGPT](https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html)	([archive](https://archive.is/qvR3Q))|
| 3.7 | A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT ([:x:](https://arxiv.org/abs/2303.04226)), ([:paperclip:](https://arxiv.org/pdf/2303.04226.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.04226)) |
| 3.7 | Radiology - [The Role and Limitations of Large Language Models Such as ChatGPT in Clinical Settings and Medical Journalism](https://pubs.rsna.org/doi/10.1148/radiol.230276) |
|	3.7	|	[Stability AI Acquires Image Editing App Clipdrop](https://stability.ai/blog/stability-ai-acquires-init-ml-makers-of-clipdrop-application)	|
|	3.6	|	[Google: Universal Speech Model](https://ai.googleblog.com/2023/03/universal-speech-model-usm-state-of-art.html)	|
|	3.5	|	[Generative AI: Perspectives from Stanford HAI](https://hai.stanford.edu/generative-ai-perspectives-stanford-hai)	|
|	3.5	|	[UpStage, ChatGPT bot (Askup) on Line](https://github.com/hunkim/line-gpt)	|
|	3.5	|	[UpStage, ChatGPT bot (Askup) on KakaoTalk](https://github.com/hunkim/kakao-gpt)	|
| 3.2 | Consistency Models  ([:x:](https://arxiv.org/abs/2303.01469)), ([:paperclip:](https://arxiv.org/pdf/2303.01469.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.01469)), ([:octocat:](https://github.com/openai/consistency_models)![GitHub Repo stars](https://img.shields.io/github/stars/openai/consistency_models?style=social)) |
| 3.1 | Almanac: Retrieval-Augmented Language Models for Clinical Medicine ([:x:](https://arxiv.org/abs/2303.01229)), ([:paperclip:](https://arxiv.org/pdf/2303.01229.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.01229)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/almanac-knowledge-grounded-language-models)) |
|	3.1	|	[OpenAI: ChatGPT and Whisper API](https://openai.com/blog/introducing-chatgpt-and-whisper-apis)	|
| 2.28 | Large Language Models Are State-of-the-Art Evaluators of Translation Quality ([:x:](https://arxiv.org/abs/2302.14520)), ([:paperclip:](https://arxiv.org/pdf/2302.14520.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2302.14520)) |
| 2.27 | Best Practices for Using AI When Writing Scientific Manuscripts ([ACS Nano 2023, 17, 5, 4091‚Äì4093](https://doi.org/10.1021/acsnano.3c01544)) |
|	2.27	|	[Fighting ‚ÄòWoke AI,‚Äô Musk Recruits Team to Develop OpenAI Rival](https://www.theinformation.com/articles/fighting-woke-ai-musk-recruits-team-to-develop-openai-rival)	|
| 2.25 | The Lancet - [The promise of large language models in health care](https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(23)00216-7/fulltext) |
| 2.25 | AugGPT: Leveraging ChatGPT for Text Data Augmentation ([:x:](https://arxiv.org/abs/2302.13007)), ([:paperclip:](https://arxiv.org/pdf/2302.13007.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2302.13007)) |
|	2.24	|	[Sam Altman, Planning for AGI and beyond](https://openai.com/blog/planning-for-agi-and-beyond)	|
|	2.24	|	[Meta: LLaMA](https://ai.facebook.com/blog/large-language-model-llama-meta-ai)	|
| 2.23 | Radiology - [ChatGPT and the Future of Medical Writing](https://pubs.rsna.org/doi/10.1148/radiol.223312) |
|	2.23	|	[Instagram co-founders launch AI-powered news app Artifact on Android, iOS](https://www.thehindubusinessline.com/info-tech/social-media/instagram-co-founders-launch-ai-powered-news-app-artifact-on-android-ios/article66543779.ece)	|
|	2.23	|	[Notion.AI launch](http://notion.ai/)	|
| 2.22 | The alignment problem from a deep learning perspective ([:x:](https://arxiv.org/abs/2209.00626)), ([:paperclip:](https://arxiv.org/pdf/2209.00626.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2209.00626))	|
|	2.22	|	[Microsoft: Bing announcement on mobile and Skype](https://blogs.microsoft.com/blog/2023/02/22/the-new-bing-preview-experience-arrives-on-bing-and-edge-mobile-apps-introducing-bing-now-in-skype)	|
|	2.22	|	Science - [As scientists explore AI-written text, journals hammer out policies](https://www.science.org/content/article/scientists-explore-ai-written-text-journals-hammer-policies)	|
| 2.21 | BadGPT: Exploring Security Vulnerabilities of ChatGPT via Backdoor Attacks to InstructGPT ([:x:](https://arxiv.org/abs/2304.12298)), ([:paperclip:](https://arxiv.org/pdf/2304.12298.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12298))	|
| 2.21 | Hyena Hierarchy: Towards Larger Convolutional Language Models ([:x:](https://arxiv.org/abs/2302.10866)), ([:paperclip:](https://arxiv.org/pdf/2302.10866.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2302.10866))	|
|	2.21	|	[The PNAS Journals Outline Their Policies for ChatGPT and Generative AI](https://www.pnas.org/post/update/pnas-policy-for-chatgpt-generative-ai)	|
|	2.21	|	ChatGPT: Jack of all trades, master of none ([:x:](https://arxiv.org/abs/2302.10724)), ([:paperclip:](https://arxiv.org/pdf/2302.10724.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2302.10724))	|
| 2.20 | ChatGPT for Robotics: Design Principles and Model Abilities ([:x:](https://arxiv.org/abs/2306.17582)), ([:paperclip:](https://arxiv.org/pdf/2306.17582.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.17582)),  ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-survey-on-generative-diffusion-model)),  ([:octocat:](https://github.com/chq1155/A-Survey-on-Generative-Diffusion-Model)![GitHub Repo stars](https://img.shields.io/github/stars/chq1155/A-Survey-on-Generative-Diffusion-Model?style=social)) |
| 2.17 | Complex QA and language models hybrid architectures, Survey ([:x:](https://arxiv.org/abs/2302.09051)), ([:paperclip:](https://arxiv.org/pdf/2302.09051.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2302.09051)), ([:house:](https://huggingface.co/papers/2302.09051)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/complex-qa-and-language-models-hybrid)), ([SS](https://www.semanticscholar.org/paper/Complex-QA-and-language-models-hybrid-Survey-Daull-Bellot/681cee58cf7e54199191cf9e0baf6851d8356704)) |
|	2.17	|	[Time, ChatGPT cover](https://time.com/6255952/ai-impact-chatgpt-microsoft-google/)	|
|	2.17	|	OpenAI, Foundry Product Brief	|
|	2.17	|	[Generative AI on Roblox: Our Vision for the Future of Creation](https://blog.roblox.com/2023/02/generative-ai-roblox-vision-future-creation/)	|
| 2.16 | Do We Still Need Clinical Language Models? ([:x:](https://arxiv.org/abs/2302.08091)), ([:paperclip:](https://arxiv.org/pdf/2302.08091.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2302.08091)) |
|	2.16	|	[Startup Replit launches a ChatGPT-like bot for coders](https://www.semafor.com/article/02/15/2023/startup-replit-launches-a-chatgpt-like-bot-for-coders)	|
|	2.15	|	[A&O announces exclusive launch partnership with Harvey](https://www.allenovery.com/en-gb/global/news-and-insights/news/ao-announces-exclusive-launch-partnership-with-harvey)	|
| 2.14 | ChatCAD: Interactive Computer-Aided Diagnosis on Medical Image using Large Language Models ([:x:](https://arxiv.org/abs/2302.07257)), ([:paperclip:](https://arxiv.org/pdf/2302.07257.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2302.07257)), ([:house:](https://huggingface.co/papers/2302.07257)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/chatcad-interactive-computer-aided-diagnosis)), ([:octocat:](https://github.com/zhaozh10/ChatCAD)![GitHub Repo stars](https://img.shields.io/github/stars/zhaozh10/ChatCAD?style=social)) |
| 2.14 | What Is ChatGPT Doing ‚Ä¶ and Why Does It Work? ([Stephen Wolfram Writings](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)) |
|	2.14	|	1M ChatGPT plus user 	|
|	2.14	|	[The Gen AI Conference Hosted by Jasper](https://www.joingen.ai/)	|
|	2.13	|	[Google: Vision Transformer 22B](https://twitter.com/m__dehghani/status/1625186144001396737)	|
| 2.12 | Transformer models: an introduction and catalog ([:x:](https://arxiv.org/abs/2302.07730)), ([:paperclip:](https://arxiv.org/pdf/2302.07730.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2302.07730)), ([Blog](https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/)) |
|	2.10	|	[arXivGPT launches](https://news.ycombinator.com/item?id=34770108)	|
|	2.10	|	[OpenAI, ChatGPT plus announce (20$)](https://openai.com/blog/chatgpt-plus)	|
|	2.9	|	[Disastrous Chatbot Demo Costs Google $140 Billion](https://www.channelnews.com.au/google-shares-tank-after-disastrous-chatbot-demo/)	|
|	2.9	|	[Meta: Toolformer](https://arxiv.org/abs/2302.04761)	|
| 2.8 | A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity ([:x:](https://arxiv.org/abs/2302.04023)), ([:paperclip:](https://arxiv.org/pdf/2302.04023.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2302.04023)) | 
|	2.8	|	[Runway launches ground-breaking Gen-1 video generation AI system](https://www.ghacks.net/2023/02/08/runway-launches-ground-breaking-gen-1-video-generation-ai-system/)	|
|	2.7	|	[Microsoft: Bing ChatGPT](https://blogs.microsoft.com/blog/2023/02/07/reinventing-search-with-a-new-ai-powered-microsoft-bing-and-edge-your-copilot-for-the-web/)	|
|	2.7	|	[Getty Images sues AI art generator Stable Diffusion in the US for copyright infringement](https://www.theverge.com/2023/2/6/23587393/ai-art-copyright-lawsuit-getty-images-stable-diffusion)	|
| 2.6 | The Lancet - [ChatGPT: friend or foe?](https://www.thelancet.com/journals/landig/article/PIIS2589-7500%2823%2900023-7/fulltext) |
|	2.6	|	[Google: Bard announcement](https://blog.google/technology/ai/bard-google-ai-search-updates)	|
| 2.4 | Theory of Mind May Have Spontaneously Emerged in Large Language Models  ([:x:](https://arxiv.org/abs/2302.02083)), ([:paperclip:](https://arxiv.org/pdf/2302.02083.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2302.02083)) |
|	2.4	|	[POE.com open](http://poe.com/)	|
|	2.3	|	[Google invests in Anthropic, maker of ChatGPT rival](https://fortune.com/2023/02/04/google-invests-300m-anthropic-openai-rival-making-chatgpt-challenger-claude-ai-chatbot-battle/) 	|
|	2.3	|	Naver, SearchGPT announcement	|
| 2.2 | Creating a Large Language Model of a Philosopher ([:x:](https://arxiv.org/abs/2302.01339)), ([:paperclip:](https://arxiv.org/pdf/2302.01339.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2302.01339)) |
|	2.2	|	[ChatGPT reaches 100 million users two months after launch](https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-fastest-growing-app)	|
| 2.1 | The Diagnostic and Triage Accuracy of the GPT-3 Artificial Intelligence Model ([medrXiv](https://www.medrxiv.org/content/10.1101/2023.01.30.23285067v1 )|
|	2.1	|	[OpenAI, released a software tool to help identify text generated by AI](https://eandt.theiet.org/content/articles/2023/02/chatgpt-owner-launches-imperfect-tool-to-detect-ai-generated-text/)	|
|	1.31	|	[JAMA Network - Nonhuman ‚ÄúAuthors‚Äù and Implications for the Integrity of Scientific Publication and Medical Knowledge](https://jamanetwork.com/journals/jama/fullarticle/2801170)	|
| 1.30 | SingSong: Generating musical accompaniments from singing ([:x:](https://arxiv.org/abs/2301.12662)), ([:paperclip:](https://arxiv.org/pdf/2301.12662.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2301.12662)), ([:octocat:](https://storage.googleapis.com/sing-song/index.html)) |
|	1.30	|	[China's biggest search engine is to set launch a ChatGPT rival in March](https://www.engadget.com/chinas-baidu-is-adding-a-chatgpt-type-bot-to-its-search-engine-110452638.html)	|
|	1.26	|	[Science Journal - ChatGPT is fun, but not an author](https://www.science.org/doi/10.1126/science.adg7879)	|
|	1.26	|	DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature ([:x:](https://arxiv.org/abs/2301.11305)), ([:paperclip:](https://arxiv.org/pdf/2301.11305.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2301.11305))	|
|	1.26	|	[ChatGPT Is Coming for Classrooms. Don't Panic](https://www.wired.com/story/chatgpt-is-coming-for-classrooms-dont-panic/)	|
|	1.26	|	[ChatGPT passes exams from law and business schools](https://edition.cnn.com/2023/01/26/tech/chatgpt-passes-exams/index.html)	|
|	1.26	|	[Google‚Äôs new AI turns text into music - MusicLM](https://google-research.github.io/seanet/musiclm/examples/)	|
| 1.24 | Putting ChatGPT's Medical Advice to the (Turing) Test ([:x:](https://arxiv.org/abs/2301.10035)), ([:paperclip:](https://arxiv.org/pdf/2301.10035.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2301.10035)) |
|	1.24	|	[Nature policy - Tools such as ChatGPT threaten transparent science; here are our ground rules for their use](https://www.nature.com/articles/d41586-023-00191-1)	|
|	1.20	|	[WAME policy - Chatbots, ChatGPT, and Scholarly Manuscripts](https://wame.org/page3.php?id=106)	|
|	1.17	|	[Meet Claude: Anthropic‚Äôs Rival to ChatGPT](https://scale.com/blog/chatgpt-vs-claude)	|
|	1.14	|	[Microsoft in talks to acquire a 49% stake in ChatGPT owner OpenAI](https://watcher.guru/news/microsoft-plans-to-acquire-a-49-stake-in-chatgpt-owner-openai)	|
| 1.12 | Multimodal Deep Learning ([:x:](https://arxiv.org/abs/2301.04856)), ([:paperclip:](https://arxiv.org/pdf/2301.04856.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2301.04856)) |
|	1.11	|	[This Voice Doesn't Exist - Generative Voice AI](https://blog.elevenlabs.io/enter-the-new-year-with-a-bang/)	|
|	1.9	|	[Microsoft is looking at OpenAI‚Äôs GPT for Word, Outlook, and PowerPoint](https://www.theverge.com/2023/1/9/23546144/microsoft-openai-word-powerpoint-outlook-gpt-integration-rumor)	|
|	1.5	|	[Apple launches AI-powered book narrations](https://techcrunch.com/2023/01/05/apple-launches-ai-powered-book-narrations/)	|
|	1.5	|	[Microsoft, VALL-E](https://valle-demo.github.io/)	|
|	1.4	|	[ICML conference responds to LLM ethics rule](https://venturebeat.com/ai/thats-so-meta-ml-conference-debates-use-of-chatgpt-in-papers/)	|
|	1.3	|	[Enter GPTZeo](https://twitter.com/edward_the6/status/1610067688449007618?ref_src=twsrc%5Etfw)	|
|	2023.01.01	|	Collected by Jonghong Jeon (hollobit@etri.re.kr)	|
|	12.29	|	GPT Takes the Bar Exam ([:x:](https://arxiv.org/abs/2212.14402)), ([:paperclip:](https://arxiv.org/pdf/2212.14402.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2212.14402)), ([SS](https://www.semanticscholar.org/paper/How-Well-Does-ChatGPT-Do-When-Taking-the-Medical-of-Gilson-Safranek/7d4867e28b02059eef4cb25bfcd304b2071b30a9))	|
|	12.27	|	[bioarXiv - Comparing scientific abstracts generated by ChatGPT to original abstracts using an artificial intelligence output detector, plagiarism detector, and blinded human reviewers](https://www.biorxiv.org/content/10.1101/2022.12.23.521610v1)	|
| 12.26 | A large language model for electronic health records (Nature [https://doi.org/10.1038/s41746-022-00742-2](https://www.nature.com/articles/s41746-022-00742-2)), ([PDF](https://www.nature.com/articles/s41746-022-00742-2.pdf?pdf=button%20sticky)) |
| 12.26 | How Well Does ChatGPT Do When Taking the Medical Licensing Exams? The Implications of Large Language Models for Medical Education and Knowledge Assessment ([medRxiv](https://www.medrxiv.org/content/10.1101/2022.12.23.22283901v1)), ([PDF](https://www.medrxiv.org/content/10.1101/2022.12.23.22283901v1.full.pdf)) |
| 12.20 | Towards Reasoning in Large Language Models: A Survey ([:x:](https://arxiv.org/abs/2212.10403)), ([:paperclip:](https://arxiv.org/pdf/2212.10403.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2212.10403)), ([:house:](https://huggingface.co/papers/2212.10403)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/towards-reasoning-in-large-language-models-a)), ([:octocat:](https://github.com/jeffhj/lm-reasoning)![GitHub Repo stars](https://img.shields.io/github/stars/jeffhj/lm-reasoning?style=social)), ([SS](https://www.semanticscholar.org/paper/Towards-Reasoning-in-Large-Language-Models%3A-A-Huang-Chang/db4ab91d5675c37795e719e997a2827d3d83cd45)) |
| 12.15 | Constitutional AI: Harmlessness from AI Feedback ([:x:](https://arxiv.org/abs/2212.08073)), ([:paperclip:](https://arxiv.org/pdf/2212.08073.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2212.08073)), ([:house:](https://huggingface.co/papers/2212.08073)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/constitutional-ai-harmlessness-from-ai)), ([:octocat:](https://github.com/anthropics/constitutionalharmlessnesspaper)![GitHub Repo stars](https://img.shields.io/github/stars/anthropics/constitutionalharmlessnesspaper?style=social)) |
| 12.3 | The Role of Generative Adversarial Network in Medical Image Analysis: An In-depth Survey (ACM, [https://doi.org/10.1145/3527849](https://dl.acm.org/doi/10.1145/3527849)), ([PDF](https://dl.acm.org/doi/pdf/10.1145/3527849)) |
|	11.30	|	[OpenAI, ChatGPT service](https://openai.com/blog/chatgpt)	|
| 11.28 | Fine-tuning language models to find agreement among humans with diverse preferences ([:x:](https://arxiv.org/abs/2211.15006)), ([:paperclip:](https://arxiv.org/pdf/2211.15006.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2211.15006)), ([:house:](https://huggingface.co/papers/2211.15006)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/fine-tuning-language-models-to-find-agreement)) |
|	11.28	|	[NeurIPS 2022 conference](https://nips.cc/Conferences/2022)	|
| 11.21 | VectorFusion: Text-to-SVG by Abstracting Pixel-Based Diffusion Models ([:x:](https://arxiv.org/abs/2211.11319)), ([:paperclip:](https://arxiv.org/pdf/2211.11319.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2211.11319)), ([:house:](https://huggingface.co/papers/2211.11319)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/vectorfusion-text-to-svg-by-abstracting-pixel)), (CVPR 2023) |
|	11.17	|	[InstructPix2Pix: Learning to Follow Image Editing Instructions](https://arxiv.org/abs/2211.09800)	|
| 11.16 | Holistic Evaluation of Language Models ([:x:](https://arxiv.org/abs/2211.09110)), ([:paperclip:](https://arxiv.org/pdf/2211.09110.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2211.09110)), ([:house:](https://huggingface.co/papers/2211.09110)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/holistic-evaluation-of-language-models)), ([:octocat:](https://github.com/stanford-crfm/helm)![GitHub Repo stars](https://img.shields.io/github/stars/stanford-crfm/helm?style=social)), ([SS](https://www.semanticscholar.org/paper/Holistic-Evaluation-of-Language-Models-Liang-Bommasani/5032c0946ee96ff11a292762f23e6377a6cf2731))	|
| 11.14 | Diffusion Models for Medical Image Analysis: A Comprehensive Survey ([:x:](https://arxiv.org/abs/2211.07804)), ([:paperclip:](https://arxiv.org/pdf/2211.07804.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2211.07804)),  ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/diffusion-models-for-medical-image-analysis-a)),  ([:octocat:](https://github.com/amirhossein-kz/awesome-diffusion-models-in-medical-imaging)![GitHub Repo stars](https://img.shields.io/github/stars/amirhossein-kz/awesome-diffusion-models-in-medical-imaging?style=social)) |
| 11.1 | MedSegDiff: Medical Image Segmentation with Diffusion Probabilistic Model ([:x:](https://arxiv.org/abs/2211.00611)), ([:paperclip:](https://arxiv.org/pdf/2211.00611.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2211.00611)),  ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/medsegdiff-medical-image-segmentation-with)),  ([:octocat:](https://github.com/wujunde/medsegdiff)![GitHub Repo stars](https://img.shields.io/github/stars/wujunde/medsegdiff?style=social)) |
|	10.30	|	[LlamaIndex (GPT Index) GitHub project](https://github.com/jerryjliu/llama_index)![GitHub Repo stars](https://img.shields.io/github/stars/jerryjliu/llama_index?style=social)	|
|	10.23	|	[LangChain GitHub project](https://github.com/hwchase17/langchain)![GitHub Repo stars](https://img.shields.io/github/stars/hwchase17/langchain?style=social)	|
| 9.27 | What Does DALL-E 2 Know About Radiology? ([JMIR](https://www.jmir.org/2023/1/e43110/)), ([:x:](https://arxiv.org/abs/2209.13696)), ([:paperclip:](https://arxiv.org/pdf/2209.13696.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2209.13696)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/what-does-dall-e-2-know-about-radiology)) |
|	9.19	|	[SEQUOIA - Generative AI: A Creative New World](https://www.sequoiacap.com/article/generative-ai-a-creative-new-world/)	|
| 9.15 | Brain Imaging Generation with Latent Diffusion Models [:x:](https://arxiv.org/abs/2209.07162)), ([:paperclip:](https://arxiv.org/pdf/2209.07162.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2209.07162)),  ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/brain-imaging-generation-with-latent)) |
| 9.6 | A Survey on Generative Diffusion Model ([:x:](https://arxiv.org/abs/2209.02646)), ([:paperclip:](https://arxiv.org/pdf/2209.02646.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2209.02646)),  ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-survey-on-generative-diffusion-model)),  ([:octocat:](https://github.com/chq1155/A-Survey-on-Generative-Diffusion-Model)![GitHub Repo stars](https://img.shields.io/github/stars/chq1155/A-Survey-on-Generative-Diffusion-Model?style=social)) |
| 8.25 | Understanding Diffusion Models: A Unified Perspective ([:x:](https://arxiv.org/abs/2208.11970)), ([:paperclip:](https://arxiv.org/pdf/2208.11970.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2208.11970)), ([Blog](https://calvinyluo.com/2022/08/26/diffusion-tutorial.html)) |
| 7.4 | Shifting machine learning for healthcare from development to deployment and from models to data (nature biomedical engineering, [https://doi.org/10.1038/s41551-022-00898-y](https://www.nature.com/articles/s41551-022-00898-y)), ([PDF](https://www.nature.com/articles/s41551-022-00898-y.pdf)) |
| 3.29 | Training Compute-Optimal Large Language Models  ([:x:](https://arxiv.org/abs/2303.15556)), ([:paperclip:](https://arxiv.org/pdf/2303.15556.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.15556)), ([:house:](https://huggingface.co/papers/2303.15556)) |
|	3.15	|	OpenAI, GPT 3.5 announce	|
| 2.11 | Compute Trends Across Three Eras of Machine Learning ([:x:](https://arxiv.org/abs/2202.05924)), ([:paperclip:](https://arxiv.org/pdf/2202.05924.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2202.05924)) |
| 2.8 | ‚≠ê Survey of Hallucination in Natural Language Generation ([:x:](https://arxiv.org/abs/2202.03629)), ([:paperclip:](https://arxiv.org/pdf/2202.03629.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2202.03629)),  ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/survey-of-hallucination-in-natural-language)), ([SS](https://www.semanticscholar.org/paper/Survey-of-Hallucination-in-Natural-Language-Ji-Lee/3c9ba25baca64151af4e9d50c7947de28eb2a599)) |
| 1.28 | Chain-of-Thought Prompting Elicits Reasoning in Large Language Models ([:x:](https://arxiv.org/abs/2201.11903)), ([:paperclip:](https://arxiv.org/pdf/2201.11903.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2201.11903)),  ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/chain-of-thought-prompting-elicits-reasoning)), ([SS](https://www.semanticscholar.org/paper/Chain-of-Thought-Prompting-Elicits-Reasoning-in-Wei-Wang/1b6e810ce0afd0dd093f789d2b2742d047e316d5)) |
| 2022.01.01 | |
| 10.19 | Future directions for chatbot research: an interdisciplinary research agenda ([paper](https://link.springer.com/article/10.1007/s00607-021-01016-7)) |
| 8.16 | ‚≠ê On the Opportunities and Risks of Foundation Models ([:x:](https://arxiv.org/abs/2108.07258)), ([:paperclip:](https://arxiv.org/pdf/2108.07258.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2108.07258)),  ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/on-the-opportunities-and-risks-of-foundation)) |
| 6.15 | Synthetic data in machine learning for medicine and healthcare (nature biomedical engineering, [https://doi.org/10.1038/s41551-021-00751-8](https://www.nature.com/articles/s41551-021-00751-8)), ([PDF](https://www.nature.com/articles/s41551-021-00751-8.pdf?pdf=button%20sticky)) |
| 4.18 | The Power of Scale for Parameter-Efficient Prompt Tuning ([:x:](https://arxiv.org/abs/2104.08691)), ([:paperclip:](https://arxiv.org/pdf/2104.08691.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2104.08691))
| 2021.01.01 | | 
|		|	**Last Modified 2023/07/03 PM19:40** KST	|

## Additional Links
* [Language Model Evaluation Harness](https://github.com/EleutherAI/lm-evaluation-harness)![GitHub Repo stars](https://img.shields.io/github/stars/EleutherAI/lm-evaluation-harness?style=social)
* [A collection of papers and resources related to evaluations on large language models](https://github.com/MLGroupJLU/LLM-eval-survey)![GitHub Repo stars](https://img.shields.io/github/stars/Jianing-Qiu//MLGroupJLU/LLM-eval-survey?style=social)
* [Awesome-Healthcare-Foundation-Models](https://github.com/Jianing-Qiu/Awesome-Healthcare-Foundation-Models)![GitHub Repo stars](https://img.shields.io/github/stars/Jianing-Qiu/Awesome-Healthcare-Foundation-Models?style=social)
* [LLM-evaluation](https://github.com/Hannibal046/Awesome-LLM/blob/main/paper_list/evaluation.md)
* [Awesome-LLM](https://github.com/Hannibal046/Awesome-LLM)![GitHub Repo stars](https://img.shields.io/github/stars/Hannibal046/Awesome-LLM?style=social)
* [Examples and guides for using the OpenAI API](https://github.com/openai/openai-cookbook)![GitHub Repo stars](https://img.shields.io/github/stars/openai/openai-cookbook?style=social)
* [Ultimate-Awesome-Transformer-Attention](https://github.com/cmhungsteve/Awesome-Transformer-Attention)![GitHub Repo stars](https://img.shields.io/github/stars/cmhungsteve/Awesome-Transformer-Attention?style=social)
* [Awesome Segment Anything](https://github.com/Hedlen/awesome-segment-anything)![GitHub Repo stars](https://img.shields.io/github/stars/Hedlen/awesome-segment-anything?style=social)
* [Segment Anything Model (SAM) for Medical Image Segmentation](https://github.com/YichiZhang98/SAM4MIS)![GitHub Repo stars](https://img.shields.io/github/stars/YichiZhang98/SAM4MIS?style=social)
* [GPT-4ÁôªÂ†¥‰ª•Èôç„Å´Âá∫„Å¶„Åç„ÅüChatGPT/LLM„Å´Èñ¢„Åô„ÇãË´ñÊñá„ÇÑÊäÄË°ì„ÅÆÊåØ„ÇäËøî„Çä](https://blog.brainpad.co.jp/entry/2023/06/05/153034) 
* [LLM Collection](https://www.promptingguide.ai/models/collection)
* [ü§ó Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
* [AI Incident Database](https://incidentdatabase.ai/)
* [Daily papers by AK](https://huggingface.co/papers)
* [Awesome-Generative-RecSys](https://github.com/jihoo-kim/Awesome-Generative-RecSys)![GitHub Repo stars](https://img.shields.io/github/stars/jihoo-kim/Awesome-Generative-RecSys?style=social) - A curated list of Generative Recommender Systems (Paper & Code)
* [Prompt Engineering Guide](https://www.promptingguide.ai/) - [papers](https://www.promptingguide.ai/papers) - [:octocat:](https://github.com/dair-ai/Prompt-Engineering-Guide)![GitHub Repo stars](https://img.shields.io/github/stars/dair-ai/Prompt-Engineering-Guide?style=social)
* [awesome-ChatGPT-repositories](https://github.com/taishi-i/awesome-ChatGPT-repositories)![GitHub Repo stars](https://img.shields.io/github/stars/taishi-i/awesome-ChatGPT-repositories?style=social) 
* [The Rundown](https://www.therundown.ai/)
* [WEEKLY PAPERS](https://papers.labml.ai/papers/weekly)
* [Primo.ai LLM wiki](https://primo.ai/index.php?title=Large_Language_Model_(LLM))
* [ML Papers of the Week](https://github.com/dair-ai/ML-Papers-of-the-Week)![GitHub Repo stars](https://img.shields.io/github/stars/dair-ai/ML-Papers-of-the-Week?style=social)
* [CS 324 - Advances in Foundation Models](https://stanford-cs324.github.io/winter2023/)
* [ML timeline](https://github.com/osanseviero/ml_timeline)![GitHub Repo stars](https://img.shields.io/github/stars/osanseviero/ml_timeline?style=social)
* [ChatGPT Timeline](https://timelines.issarice.com/wiki/Timeline_of_ChatGPT)
* [OpenAI Timeline](https://www.jointjs.com/demos/chatgpt-timeline)
* [Major Updates on the LLM Survey üî•](https://github.com/RUCAIBox/LLMSurvey)![GitHub Repo stars](https://img.shields.io/github/stars/RUCAIBox/LLMSurvey?style=social)
<img src="https://pbs.twimg.com/media/F0Re2OiaYAU3p-l?format=jpg&name=large">
* [Generative Artificial Intelligence Stack Language](https://www.reddit.com/r/AILinksandTools/comments/126z1pd/the_generative_ai_tech_stack_for_language_march/)
<img src="https://i.redd.it/r2kr7trwwxqa1.png">
* [Awesome-Multimodal-Large-Language-Models](https://github.com/bradyfu/awesome-multimodal-large-language-models)
<img src="https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/blob/main/images/xmind.png?raw=true">
* [SEQUOIA - The New Language Model Stack](https://www.sequoiacap.com/article/llm-stack-perspective/)
<img src="https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/06/llm-landscape-9.png">
* The Rise and Rise of A.I. LLMs
<img src="https://pbs.twimg.com/media/FwTUtyKacAAgQbQ?format=jpg&name=large">
* [The Practical Guides for Large Language Models](https://github.com/Mooler0410/LLMsPracticalGuide)
<img src="https://github.com/Mooler0410/LLMsPracticalGuide/blob/main/imgs/survey-gif-test.gif">
* [AI / ML / LLM / Transformer Models Timeline](https://ai.v-gar.de/ml/transformer/timeline/) 
<img src="https://ai.v-gar.de/ml/transformer/timeline/timeline.png">
* [Transformer models: an introduction and catalog‚Ää‚Äî‚Ää2023 Edition](https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/)
<img src="https://amatriain.net/blog/images/02-05.png" bgcolor=white>
<img src="https://amatriain.net/blog/images/02-09.png">
* [open-source LLMs](https://twitter.com/theaievangelist/status/1645809824314298368)
<img src="https://pbs.twimg.com/media/FtZQSU3aMAI4BP1?format=jpg&name=4096x4096">
* Got It AI‚Äôs LLM hallucination rate comparison
<img src="https://lh5.googleusercontent.com/cgHE-XSe8AZBUuFIQw-Vu6XqYFxvKWj5BjCPsWAxkre2G8WLLkVLhp0DyDTlSTYFQiUyG_XUvZU2ZtM212SuU9rfbNxEtQI0kEpm8sSKF7CUsJZpu0pY9FaT2qHVpPgrBRLeJZdsdyBaKMw5Tac8M7Y">
* [A summary of large language models (A Survey of Large Language Models)](https://arxiv.org/abs/2303.18223)
 <img src="https://github.com/hollobit/GenAI_LLM_timeline/assets/998803/9a855dea-7223-4523-924e-3952b1f3734d">
* [A history of the most important ge![Uploading ·Ñâ·Ö≥·Ñè·Ö≥·ÑÖ·Öµ·Ü´·Ñâ·Ö£·Ü∫ 2023-05-18 ·Ñã·Ö©·Ñí·ÖÆ 5.58.51.png‚Ä¶]()
nerative AI models, from 2014 to 2023 @davidtfoster](https://www.linkedin.com/feed/update/urn:li:activity:7044233450295316480/)
 <img src="https://github.com/hollobit/GenAI_LLM_timeline/assets/998803/09140224-638f-448c-a990-1201741927c7">
